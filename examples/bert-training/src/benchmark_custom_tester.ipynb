{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e838aed8-1860-4a7b-ae96-6ca702cb3408",
   "metadata": {},
   "source": [
    "# How to benchmark using trainer\n",
    "\n",
    "It seems I can't get the Trainer class to work. Let's try on a dummy model and slowly refine below. \n",
    "\n",
    "Okay, it seems that I have figured this out. I was being dumb and using a bad model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffde561a-8d48-4fee-9a23-f8efb0acfa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0868728c-d44a-442a-8e89-a69a1085f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple, Union\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c36c002e-cf0f-446a-ae33-1d9dbc32f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "056e006e-eb96-4a90-9ab6-2c4daa05931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset('glue', 'sst2')\n",
    "\n",
    "# I believe this is the tokenizer I used... \n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['sentence'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac86c4d-b48b-45be-a052-b7df92638d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b41ddaf-b797-4d39-9540-d874cfe22479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a two attention neural network for binary classification\n",
    "class SimpleFeedForwardNN(BertPreTrainedModel):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        config = BertConfig()\n",
    "        super(SimpleFeedForwardNN, self).__init__(config)\n",
    "        \n",
    "        # super(SimpleFeedForwardNN, self).__init__()\n",
    "\n",
    "\n",
    "        # Use the same embeddings because i'm fucking lazy \n",
    "        self.embedding0 = nn.Embedding(30522, hidden_size, padding_idx=0)\n",
    "        self.embedding1 = nn.Embedding(2, hidden_size, padding_idx=0)\n",
    "        self.embedding2 = nn.Embedding(2, hidden_size, padding_idx=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_size, 4 * hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(4 * hidden_size, hidden_size)\n",
    "        self.fc5 = nn.Linear(hidden_size, 4 * hidden_size)\n",
    "        self.fc6 = nn.Linear(4 * hidden_size, hidden_size)\n",
    "\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        # Dummy attention \n",
    "        self.attention = nn.MultiheadAttention(embed_dim=hidden_size, num_heads=4, batch_first=True)\n",
    "        self.attention1 = nn.MultiheadAttention(embed_dim=hidden_size, num_heads=4, batch_first=True)\n",
    "\n",
    "        # Create loss\n",
    "        self.loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        # self.post_init()\n",
    "\n",
    "    \n",
    "    def forward(self, \n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        ):\n",
    "\n",
    "        \n",
    "        # Dummy embedding \n",
    "        out = self.embedding0(input_ids) #+ self.embedding1(attention_mask) + self.embedding2(token_type_ids)\n",
    "\n",
    "        # Simple attention \n",
    "        attention_output, _ = self.attention(out, out, out)\n",
    "        out = out + attention_output\n",
    "        ff = self.fc1(out)\n",
    "        ff = self.relu(ff)\n",
    "        ff = self.fc2(ff)\n",
    "        out = out + ff\n",
    "\n",
    "        # Second attention? \n",
    "        attention_output, _ = self.attention1(out, out, out)\n",
    "        out = out + attention_output\n",
    "        ff = self.fc5(out)\n",
    "        ff = self.relu(ff)\n",
    "        ff = self.fc6(ff)\n",
    "        out = out + ff\n",
    "\n",
    "        out = out[:, 0] # Sample \"pooler\"\n",
    "        # print(f'\\t Pooler: {out[:, 0:10]=}')\n",
    "\n",
    "        # \"Classifier\"\n",
    "        out = self.fc3(out)\n",
    "            \n",
    "        loss = self.loss_func(out.view(-1, 2), labels.view(-1))\n",
    "        \n",
    "        return (self.loss_func(out, labels), out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "656e7a8d-2da1-4a90-8675-fc9b0ec90a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "hidden_size = 256\n",
    "num_classes = 2\n",
    "model = SimpleFeedForwardNN(hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2120d4c7-352f-41c5-bce6-e9f81e70cf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_713163/2326431495.py:18: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\")\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1320' max='1320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1320/1320 06:46, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.649800</td>\n",
       "      <td>0.624788</td>\n",
       "      <td>0.660550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.585700</td>\n",
       "      <td>0.590841</td>\n",
       "      <td>0.682339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.555300</td>\n",
       "      <td>0.573673</td>\n",
       "      <td>0.701835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.538100</td>\n",
       "      <td>0.568584</td>\n",
       "      <td>0.705275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.515700</td>\n",
       "      <td>0.566843</td>\n",
       "      <td>0.713303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1320, training_loss=0.5809132323120579, metrics={'train_runtime': 407.1806, 'train_samples_per_second': 827.016, 'train_steps_per_second': 3.242, 'total_flos': 1632395967191040.0, 'train_loss': 0.5809132323120579, 'epoch': 5.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "import numpy as np\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=256,\n",
    "    per_device_eval_batch_size=256,\n",
    "    learning_rate=2e-5,\n",
    "    # warmup_steps=10,\n",
    "    # weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "# Load the accuracy metric\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "# Define the compute metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a12e761-4e86-4732-a71a-7a6ccf235f78",
   "metadata": {},
   "source": [
    "# Observations\n",
    "\n",
    "1. First epochs get's bad results; make sense\n",
    "2. But it slowly gets better in the third and reaches... at least decent stuff right? Need to be patient lmao. But training loss should slowly decrease.\n",
    "3. So I should be seeing something like this when doing it for my loaded model.. \n",
    "4. Is it the \"self.post_init()\" that's very important? test it out!\n",
    "5. Do I need to subclass? Don't need to. \n",
    "\n",
    "With self.post_init()\n",
    "```\n",
    "Epoch\tTraining Loss\tValidation Loss\tAccuracy\n",
    "1\t0.690600\t0.698000\t0.509174\n",
    "2\t0.685200\t0.696884\t0.509174\n",
    "3\t0.586300\t0.580936\t0.728211\n",
    "4\t0.439500\t0.515325\t0.755734\n",
    "5\t0.430200\t0.510323\t0.763761\n",
    "```\n",
    "\n",
    "With just nn.Module\n",
    "```\n",
    "Epoch\tTraining Loss\tValidation Loss\tAccuracy\n",
    "1\t0.662100\t0.644426\t0.626147\n",
    "2\t0.580900\t0.588855\t0.699541\n",
    "3\t0.543800\t0.551802\t0.723624\n",
    "4\t0.514000\t0.539427\t0.732798\n",
    "5\t0.498300\t0.536726\t0.739679\n",
    "```\n",
    "\n",
    "Subclasses, no self.post_init()\n",
    "```\n",
    "Epoch\tTraining Loss\tValidation Loss\tAccuracy\n",
    "1\t0.656900\t0.639153\t0.638761\n",
    "2\t0.583000\t0.596516\t0.675459\n",
    "3\t0.577400\t0.579494\t0.686927\n",
    "4\t0.539300\t0.568600\t0.699541\n",
    "5\t0.531300\t0.565805\t0.696101\n",
    "```\n",
    "\n",
    "Okay, so I don't need to do it. So what was wrong with before? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a078a50-a4de-4c9b-9fb3-937352df3a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "trainer.predict(tokenized_datasets['test'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a54dc3-8265-480c-8e87-70d1b2de75b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

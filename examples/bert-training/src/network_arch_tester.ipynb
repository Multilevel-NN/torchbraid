{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a219af-0242-49c9-9997-82b4847157b3",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This file is to just test the network_arch v2 file to see if it doesn't work in serial or not. \n",
    "\n",
    "We do some imports first, and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47135ae4-d41a-4233-823a-3ec304cebe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stats\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "from transformers import BertConfig\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a810112-a793-4848-98cf-e274ebe67325",
   "metadata": {},
   "source": [
    "# Grab data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba7e14b-7db0-4ffc-b75a-e9ffec0af81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278733c47dbe4aa1841a3a7968474c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjiang/braids/pip-test/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a81d06532b9541c8a52eff2386b8976e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/10934 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size=30522\n"
     ]
    }
   ],
   "source": [
    "from get_dataset import obtain_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds, vocab_size = obtain_dataset(percent_data = 1000, seq_len=64)\n",
    "train_size, test_size = int(len(ds) * 0.8), len(ds) - int(len(ds) * 0.8)  # 80/20 split by default\n",
    "train_ds, test_ds = torch.utils.data.random_split(ds, [train_size, test_size])\n",
    "print(f'{vocab_size=}')\n",
    "train_loader = DataLoader(\n",
    "train_ds, batch_size=32, shuffle=False, pin_memory=True, drop_last=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "test_ds, batch_size=32, shuffle=False, pin_memory=True, drop_last=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dc3c74-4864-4b22-8275-a491f7275992",
   "metadata": {},
   "source": [
    "# Import layers and test\n",
    "\n",
    "Use importlib to make sure change reload is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cddc5f7-1b74-47d4-9053-59f344592cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import network_architecture_v2\n",
    "\n",
    "# Reload the module to reflect any changes made\n",
    "importlib.reload(network_architecture_v2)\n",
    "\n",
    "# Now you can import the classes\n",
    "from network_architecture_v2 import OpenLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b16543-fda6-489b-a5a5-bd24d631f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig() # Creat simple config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b618acc9-bbcb-4004-a344-81a168628013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(config.type_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f635408-779a-4ab8-b75c-7a7b272ef938",
   "metadata": {},
   "outputs": [],
   "source": [
    "open = OpenLayer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d439763f-1884-46d9-b9bc-677f59180d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_iterator = iter(train_loader)  # Create an iterator from the DataLoader\n",
    "single_batch = next(batch_iterator)   # Get a single batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84c31a9f-c32a-42f1-b224-d98b076758a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101, 16087,  2620,  1516,  4216, 21893,  5221, 17184,  3119,  2090,\n",
       "        17491, 11365, 23212,  1998,  3072,  1997, 17768,   103,  1999, 16087,\n",
       "         2620,  1012,   102,   103,  2721, 18069,  5462,  2000, 17768,   103,\n",
       "          103,  2935,  3419,  2080, 21122,  2594,  1010,  2008,  2027,  2097,\n",
       "         2007,   103,  5194,   103, 10347, 16913,  4173,  1997,  5474,  1012,\n",
       "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_batch['bert_input'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f26332dc-6a2f-4211-8676-e88a9e3a73a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_batch['segment_label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3f82093-679b-42f9-81ec-74e712457e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_batch['attention_mask'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7bc4af4-8321-459f-9437-09213b39bfea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0, 18176,  2003,     0,  2028,     0,     0,     0,  2000,     0,\n",
       "            0,  6803, 29461,     0,     0,     0,     0,     0,     0,     0,\n",
       "         2088,     0,     0,     0,     0,  2161,     0,     0,     0,     0,\n",
       "            0,     0,  4719,     0,     0,     0,     0,  2027,     0,  1999,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_batch['bert_label'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9e03ee3-1c23-4103-886c-cd974a163bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = open(single_batch['bert_input'], single_batch['segment_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37c3c3e-242c-443b-a4b9-f064417555be",
   "metadata": {},
   "source": [
    "# After some tweaking, the open layer is done. \n",
    "\n",
    "The close layer is also good; now it's a matter of getting the steplayer to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22b7b087-5818-4ec7-b415-b4f044d13c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36f18539-e425-4b47-8c33-237d839e3551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import network_architecture_v2\n",
    "\n",
    "# Reload the module to reflect any changes made\n",
    "importlib.reload(network_architecture_v2)\n",
    "\n",
    "# Now you can import the classes\n",
    "from network_architecture_v2 import OpenLayer, StepLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7e94284-a338-472d-90ca-eca87520bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = StepLayer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3ca91bc-74ed-4679-8447-1a4cbe4d7414",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/braids/pip-test/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/torchbraid/examples/bert-training/src/network_architecture_v2.py:148\u001b[0m, in \u001b[0;36mStepLayer.forward\u001b[0;34m(self, x, dt)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, dt: \u001b[38;5;28mfloat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):    \u001b[38;5;66;03m# Default must be there for shape\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# TODO: look at \u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# self.comm_lp.bcast in MT2 code \u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m mask\n\u001b[0;32m--> 148\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer(x, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[43mmask\u001b[49m, dt\u001b[38;5;241m=\u001b[39mdt)\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# Need to use global mask; passing in stuff might be hard\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mask' is not defined"
     ]
    }
   ],
   "source": [
    "step(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172954a-52a2-40ec-9d70-fa4eb05e8ff2",
   "metadata": {},
   "source": [
    "# Okay after much tweaking, the model runs and trains a bit! \n",
    "\n",
    "Now for the post-processing: can we take our trained SerialNets, and then connect it back to Huggingface inference or benchmarking. \n",
    "\n",
    "Developed in parallel with bert-benchmark notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "258a48ab-aa58-466b-8798-d0f4a4ff061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, load_metric\n",
    "import numpy as np\n",
    "\n",
    "import importlib\n",
    "import network_architecture_v2\n",
    "\n",
    "# Reload the module to reflect any changes made\n",
    "importlib.reload(network_architecture_v2)\n",
    "\n",
    "# Now you can import the classes\n",
    "from network_architecture_v2 import OpenLayer, StepLayer, MyBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beeb9262-57a6-432c-a54e-d52efbb4d141",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"glue\", \"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f17342b-9df9-42a1-b652-d7bf3d468000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I believe this is the tokenizer I used... \n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['sentence'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12d421f9-5282-4a04-8de6-8df5b1204faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0323e+07\n"
     ]
    }
   ],
   "source": [
    "trained_model = torch.load(f'serial_net_hf_bert_12_epoch=1')\n",
    "\n",
    "print(f'{sum(p.numel() for p in trained_model.parameters() if p.requires_grad):.4e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a08b6ad1-b5cf-4566-85cc-b72b85235b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertPooler(\n",
       "  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (activation): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.close.pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "896036c1-2799-46ce-81c6-19e069a4543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.3689e+06\n"
     ]
    }
   ],
   "source": [
    "model = MyBertForSequenceClassification(trained_model)\n",
    "model = model.to('cuda')\n",
    "# model.train()\n",
    "print(f'{sum(p.numel() for p in model.parameters() if p.requires_grad):.4e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ca1157-6517-4135-b4be-df2e1b41b2d5",
   "metadata": {},
   "source": [
    "## Try with the SSTS... \n",
    "\n",
    "Okay.... this doesn't work in Jupyter because of namespace issues. \n",
    "\n",
    "Need to write individual file and use scripts. Ugh."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a064d2-6e94-4c48-a1cc-0b44a1ffc063",
   "metadata": {},
   "source": [
    "## Need to sub-out certain layers in model!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2aff86c-d9a5-4067-b34b-52845364969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=256,\n",
    "    per_device_eval_batch_size=256,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ea342-5e28-4231-b763-7aab07e872a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='819' max='2640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 819/2640 09:29 < 21:09, 1.43 it/s, Epoch 3.10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694164</td>\n",
       "      <td>0.509174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.679600</td>\n",
       "      <td>0.640456</td>\n",
       "      <td>0.611239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.679600</td>\n",
       "      <td>0.587521</td>\n",
       "      <td>0.678899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the compute metrics function\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    return {\"accuracy\": (preds == p.label_ids).astype(float).mean().item()}\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# # Load the accuracy metric\n",
    "# metric = load_metric(\"accuracy\")\n",
    "\n",
    "# # Define the compute metrics function\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# # Create a Trainer instance\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_datasets[\"train\"],\n",
    "#     eval_dataset=tokenized_datasets[\"validation\"],\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f555c-e9e1-4cac-8d75-058ce37f4113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

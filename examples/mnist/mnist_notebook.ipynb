{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98804907",
   "metadata": {},
   "source": [
    "### Apply layer-parallel Torchbraid to simple MNIST problem (fashion or digits)\n",
    "- See `start0_install_mpi_notebook.ipynb`, and `start1_simple_mpi_notebook.ipynb` for setting up MPI-compatible Jupyter installation\n",
    "- Recommended to start ipython cluster for default notebook settings with (assumes 4 cores)\n",
    "\n",
    "        $ ipcluster start --n=4 --engines=mpi --profile=mpi\n",
    "\n",
    "  or\n",
    "\n",
    "        $ ipcluster start --n=4 --engines=MPIEngineSetLauncher --profile=mpi\n",
    "        \n",
    "#### Layer-parallel runs most efficiently when the \n",
    "\n",
    "    (number of processors)*(coarsening factor) = k*(number of ResNet Layers)\n",
    "    \n",
    "where `k` is some integer. This experiment is designed to satisfy this with the default parameters and four processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59da843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to local ipython cluster.  Note, the ipcluster profile name must match the\n",
    "# below named profile. Here, we use 'mpi', but you can name the cluster profile anything\n",
    "from ipyparallel import Client, error\n",
    "cluster = Client(profile='mpi')\n",
    "print('profile:', cluster.profile)\n",
    "print(\"IDs:\", cluster.ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b0604",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Must point to your Torchbraid location, used for location to download MNIST dataset\n",
    "torchbraid_path = \"/path/to/torchbraid\"\n",
    "\n",
    "# If using Makefile Torchbraid install, must uncomment to update system path to Torchbraid \n",
    "#import sys\n",
    "#sys.path.append(torchbraid_path + \"/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018636b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "from __future__ import print_function\n",
    "\n",
    "import statistics as stats\n",
    "import sys\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from mpi4py import MPI\n",
    "\n",
    "import torchbraid\n",
    "import torchbraid.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f805aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Download the data\n",
    "rank = MPI.COMM_WORLD.Get_rank()\n",
    "if rank == 0:\n",
    "  datasets.MNIST(torchbraid_path + '/examples/mnist/digit-data', download=True)\n",
    "  datasets.FashionMNIST(torchbraid_path + '/examples/mnist/fashion-data', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f5ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Network architecture is Open + ResNet + Close\n",
    "# The StepLayer defines the ResNet (ODENet) \n",
    "class OpenFlatLayer(nn.Module):\n",
    "  ''' \n",
    "  Opening layer has no parameters, replicates image number of channels times\n",
    "  '''\n",
    "  def __init__(self, channels):\n",
    "    super(OpenFlatLayer, self).__init__()\n",
    "    self.channels = channels\n",
    "\n",
    "  def forward(self, x):\n",
    "    s = len(x.shape) * [1]\n",
    "    s[1] = self.channels\n",
    "    x = x.repeat(s)\n",
    "    return x\n",
    "\n",
    "class CloseLayer(nn.Module):\n",
    "  '''\n",
    "  Dense closing classification layer\n",
    "  '''\n",
    "  def __init__(self, channels):\n",
    "    super(CloseLayer, self).__init__()\n",
    "    self.fc1 = nn.Linear(channels * 28 * 28, 32)\n",
    "    self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.fc2(x)\n",
    "    return F.log_softmax(x, dim=1)\n",
    "\n",
    "class StepLayer(nn.Module):\n",
    "  '''\n",
    "  ResNet composed of convolutional layers\n",
    "  '''\n",
    "  def __init__(self, channels):\n",
    "    super(StepLayer, self).__init__()\n",
    "    ker_width = 3\n",
    "    self.conv1 = nn.Conv2d(channels, channels, ker_width, padding=1)\n",
    "    self.conv2 = nn.Conv2d(channels, channels, ker_width, padding=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return F.relu(self.conv2(F.relu(self.conv1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e775fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Parallel network class, primarily builds a LayerParallel network object\n",
    "# local_steps: number of ResNet layers per processor\n",
    "# all other parameter definitions are in params['...'] block below \n",
    "class ParallelNet(nn.Module):\n",
    "  def __init__(self, channels=12, local_steps=8, Tf=1.0, max_levels=1, bwd_max_iters=1, \n",
    "               fwd_max_iters=2, print_level=0, braid_print_level=0, cfactor=4, \n",
    "               fine_fcf=False, skip_downcycle=True, fmg=False, relax_only_cg=0,\n",
    "               user_mpi_buf=False):\n",
    "    super(ParallelNet, self).__init__()\n",
    "\n",
    "    step_layer = lambda: StepLayer(channels)\n",
    "    numprocs = MPI.COMM_WORLD.Get_size()\n",
    "    \n",
    "    self.parallel_nn = torchbraid.LayerParallel(MPI.COMM_WORLD, step_layer, local_steps*numprocs, Tf,\n",
    "                                                max_fwd_levels=max_levels, max_bwd_levels=max_levels,\n",
    "                                                max_iters=2, user_mpi_buf=user_mpi_buf)\n",
    "    self.parallel_nn.setBwdMaxIters(bwd_max_iters)\n",
    "    self.parallel_nn.setFwdMaxIters(fwd_max_iters)\n",
    "    self.parallel_nn.setPrintLevel(print_level, True)\n",
    "    self.parallel_nn.setPrintLevel(braid_print_level, False)\n",
    "    self.parallel_nn.setCFactor(cfactor)\n",
    "    self.parallel_nn.setSkipDowncycle(skip_downcycle)\n",
    "    self.parallel_nn.setBwdRelaxOnlyCG(relax_only_cg)\n",
    "    self.parallel_nn.setFwdRelaxOnlyCG(relax_only_cg)\n",
    "    if fmg:\n",
    "      self.parallel_nn.setFMG()\n",
    "    \n",
    "    self.parallel_nn.setNumRelax(1)  # FCF relaxation default on coarse levels\n",
    "    if not fine_fcf:\n",
    "      self.parallel_nn.setNumRelax(0, level=0)  # Set F-Relaxation only on the fine grid\n",
    "    else:\n",
    "      self.parallel_nn.setNumRelax(1, level=0)  # Set FCF-Relaxation on the fine grid\n",
    "\n",
    "    # this object ensures that only the LayerParallel code runs on ranks!=0\n",
    "    compose = self.compose = self.parallel_nn.comp_op()\n",
    "\n",
    "    # by passing this through 'compose' (mean composition: e.g. OpenFlatLayer o channels)\n",
    "    # on processors not equal to 0, these will be None (there are no parameters to train there)\n",
    "    self.open_nn = compose(OpenFlatLayer, channels)\n",
    "    self.close_nn = compose(CloseLayer, channels)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # by passing this through 'o' (mean composition: e.g. self.open_nn o x)\n",
    "    # this makes sure this is run on only processor 0\n",
    "\n",
    "    x = self.compose(self.open_nn, x)\n",
    "    x = self.parallel_nn(x)\n",
    "    x = self.compose(self.close_nn, x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b052424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Train model for one epoch\n",
    "# Return values: per batch losses and training times, model parameters updated in-place\n",
    "def train(rank, params, model, train_loader, optimizer, epoch, compose, device):\n",
    "  train_times = []\n",
    "  losses = []\n",
    "  model.train()\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  total_time = 0.0\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    start_time = timer()\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = compose(criterion, output, target)\n",
    "    loss.backward()\n",
    "    stop_time = timer()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_time += stop_time - start_time\n",
    "    train_times.append(stop_time - start_time)\n",
    "    losses.append(loss.item())\n",
    "    if batch_idx % params['log_interval'] == 0:\n",
    "      root_print(rank, 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTime Per Batch {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "               100. * batch_idx / len(train_loader), loss.item(), total_time / (batch_idx + 1.0)))\n",
    "\n",
    "  root_print(rank, 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTime Per Batch {:.6f}'.format(\n",
    "    epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "           100. * (batch_idx + 1) / len(train_loader), loss.item(), total_time / (batch_idx + 1.0)))\n",
    "  return losses, train_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb56f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Evaluate model on validation data\n",
    "# Return: number of correctly classified test items, total number of test items, loss on test data set\n",
    "def test(rank, model, test_loader, compose, device):\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      output = model(data)\n",
    "      test_loss += compose(criterion, output, target).item()\n",
    "\n",
    "      if rank == 0:\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "\n",
    "  root_print(rank, '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))\n",
    "  return correct, len(test_loader.dataset), test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed73439",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Parallel printing helper function\n",
    "def root_print(rank, s):\n",
    "  if rank == 0:\n",
    "    print(s)\n",
    "\n",
    "# Compute number of parallel-in-time multigrid levels\n",
    "def compute_levels(num_steps, min_coarse_size, cfactor):\n",
    "  from math import log, floor\n",
    "  # Find L such that ( max_L min_coarse_size*cfactor**L <= num_steps)\n",
    "  levels = floor(log(float(num_steps) / min_coarse_size, cfactor)) + 1\n",
    "\n",
    "  if levels < 1:\n",
    "    levels = 1\n",
    "  return levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17afb21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "#Set parameters for network architecture and layer-parallel \n",
    "params = {}\n",
    "params['seed'] = 1            # random seed\n",
    "params['log_interval'] = 10   # how many batches to wait before logging training status\n",
    "params['dataset'] = 'fashion'  # 'digits' or 'fashion' MNIST \n",
    "#\n",
    "params['steps'] = 32          # number of times steps in the resnet layer-parallel part\n",
    "params['channels'] = 3        # number of channels in resnet layer\n",
    "params['Tf'] = 1.0            # final time for resnet layer-parallel part\n",
    "#\n",
    "params['percent_data'] = 0.05 # how much of the data to read in and use for training/testing\n",
    "params['batch_size'] = 50     # input batch size for training\n",
    "params['epochs'] = 3          # number of epochs to train\n",
    "params['lr'] = 0.01           # learning rate\n",
    "#\n",
    "params['lp_max_levels'] = 3         # layer parallel max number levels \n",
    "params['lp_bwd_max_iters'] = 1      # layer parallel max backward iterations\n",
    "params['lp_fwd_max_iters'] = 2      # layer parallel max forward iterations\n",
    "params['lp_print_level'] = 0        # layer parallel internal print level: 0, 1, 2, 3 \n",
    "params['lp_braid_print_level'] = 0  # layer parallel braid print level: 0, 1, 2, 3 \n",
    "params['lp_cfactor'] = 4            # layer parallel coarsening factor\n",
    "params['lp_fine_fcf'] = False       # layer parallel fine FCF on or off \n",
    "params['no_cuda'] = False           # disables CUDA training\n",
    "params['warm_up'] = False           # warm up for GPU timings\n",
    "params['lp_user_mpi_buf'] = False   # layer parallel use user-defined mpi buffers \n",
    "params['lp_use_downcycle']= False   # layer parallel use downcycle on or off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a3e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Begin setting up run-time environment \n",
    "# MPI information\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "procs = comm.Get_size()\n",
    "\n",
    "# Use device or CPU?\n",
    "use_cuda = not params['no_cuda'] and torch.cuda.is_available()\n",
    "device, host = torchbraid.utils.getDevice(comm=comm)\n",
    "if not use_cuda:\n",
    "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f'Run info rank: {rank}: | Device: {device} | Host: {host}')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(params['seed'])\n",
    "\n",
    "# Compute max number of layer-parallel levels\n",
    "if params['lp_max_levels'] < 1:\n",
    "  min_coarse_size = 3\n",
    "  params['lp_max_levels'] = compute_levels(params['steps'], min_coarse_size, params['lp_cfactor'])\n",
    "\n",
    "# Compute number of steps in ResNet per processor\n",
    "local_steps = int(params['steps'] / procs)\n",
    "if params['steps'] % procs != 0:\n",
    "  root_print(rank, 'Steps must be an even multiple of the number of processors: %d %d' % (params['steps'], procs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b91cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# read in Digits MNIST or Fashion MNIST\n",
    "if params['dataset'] == 'digits':\n",
    "  root_print(rank, '-- Using Digit MNIST')\n",
    "  transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.1307,), (0.3081,)) ])\n",
    "  dataset = datasets.MNIST(torchbraid_path + '/examples/mnist/digit-data', download=False, transform=transform)\n",
    "else:\n",
    "  root_print(rank, '-- Using Fashion MNIST')\n",
    "  transform = transforms.Compose([transforms.ToTensor()])\n",
    "  dataset = datasets.FashionMNIST(torchbraid_path + '/examples/mnist/fashion-data', download=False, transform=transform)\n",
    "\n",
    "train_size = int(50000 * params['percent_data'])\n",
    "test_size = int(10000 * params['percent_data'])\n",
    "train_set = torch.utils.data.Subset(dataset, range(train_size))\n",
    "test_set = torch.utils.data.Subset(dataset, range(train_size, train_size + test_size))\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=params['batch_size'], shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=params['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc5308",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Create layer-parallel network\n",
    "# Note this can be done on only one processor, but will be slow\n",
    "model = ParallelNet(channels=params['channels'],\n",
    "                    local_steps=local_steps,\n",
    "                    max_levels=params['lp_max_levels'],\n",
    "                    bwd_max_iters=params['lp_bwd_max_iters'],\n",
    "                    fwd_max_iters=params['lp_fwd_max_iters'],\n",
    "                    print_level=params['lp_print_level'],\n",
    "                    braid_print_level=params['lp_braid_print_level'],\n",
    "                    cfactor=params['lp_cfactor'],\n",
    "                    fine_fcf=params['lp_fine_fcf'],\n",
    "                    skip_downcycle=not params['lp_use_downcycle'],\n",
    "                    fmg=False, \n",
    "                    Tf=params['Tf'],\n",
    "                    relax_only_cg=False,\n",
    "                    user_mpi_buf=params['lp_user_mpi_buf']).to(device)\n",
    "\n",
    "# Detailed XBraid timings are output to these files for the forward and backward phases\n",
    "model.parallel_nn.fwd_app.setTimerFile(\n",
    "  'b_fwd_s_%d_c_%d_bs_%d_p_%d'%(params['steps'], params['channels'], params['batch_size'], procs) )\n",
    "model.parallel_nn.bwd_app.setTimerFile( \n",
    "  'b_bwd_s_%d_c_%d_bs_%d_p_%d'%(params['steps'], params['channels'], params['batch_size'], procs) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17abf645",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Declare optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=params['lr'], momentum=0.9)\n",
    "\n",
    "# For better timings (especially with GPUs) do a little warm up\n",
    "if params['warm_up']:\n",
    "  warm_up_timer = timer()\n",
    "  train(rank=rank, params=params, model=model, train_loader=train_loader, optimizer=optimizer, \n",
    "        epoch=0, compose=model.compose, device=device)\n",
    "  \n",
    "  model.parallel_nn.timer_manager.resetTimers()\n",
    "  model.parallel_nn.fwd_app.resetBraidTimer()\n",
    "  model.parallel_nn.bwd_app.resetBraidTimer()\n",
    "  if use_cuda:\n",
    "    torch.cuda.synchronize()\n",
    "  root_print(rank, f'\\nWarm up timer {timer() - warm_up_timer}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba553705",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Carry out parallel training\n",
    "batch_losses = []; batch_times = []\n",
    "epoch_times = []; test_times = []\n",
    "validat_correct_counts = []\n",
    "\n",
    "for epoch in range(1, params['epochs'] + 1):\n",
    "  start_time = timer()\n",
    "  [losses, train_times] = train(rank=rank, params=params, model=model, train_loader=train_loader, \n",
    "                                optimizer=optimizer, epoch=epoch, compose=model.compose, device=device)\n",
    "  epoch_times += [timer() - start_time]\n",
    "  batch_losses += losses\n",
    "  batch_times += train_times\n",
    "\n",
    "  start_time = timer()\n",
    "  validat_correct, validat_size, validat_loss = test(rank=rank, model=model, test_loader=test_loader, \n",
    "                                                     compose=model.compose, device=device)\n",
    "  test_times += [timer() - start_time]\n",
    "  validat_correct_counts += [validat_correct]\n",
    "\n",
    "# Print out Braid internal timings, if desired\n",
    "#timer_str = model.parallel_nn.getTimersString()ll *\n",
    "#root_print(rank, timer_str)\n",
    "\n",
    "root_print(rank,\n",
    "           f'TIME PER EPOCH: {\"{:.2f}\".format(stats.mean(epoch_times))} '\n",
    "           f'{(\"(1 std dev \" + \"{:.2f})\".format(stats.mean(epoch_times))) if len(epoch_times) > 1 else \"\"}')\n",
    "root_print(rank,\n",
    "           f'TIME PER TEST:  {\"{:.2f}\".format(stats.mean(test_times))} '\n",
    "           f'{(\"(1 std dev \" + \"{:.2f})\".format(stats.mean(test_times))) if len(test_times) > 1 else \"\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576afc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the loss, validation \n",
    "root_print(rank, f'\\nMin batch time:   {\"{:.3f}\".format(np.min(batch_times))} ')\n",
    "root_print(rank, f'Mean batch time:  {\"{:.3f}\".format(stats.mean(batch_times))} ')\n",
    "\n",
    "\n",
    "if rank == 0:\n",
    "  fig, ax1 = plt.subplots()\n",
    "  plt.title('Layer-parallel run with %d processors\\n MNIST %s dataset'%(procs, params['dataset']), fontsize=15)\n",
    "  ax1.plot(batch_losses, color='b', linewidth=2)\n",
    "  ax1.grid(True, color='k', linestyle='-', linewidth=0.4)\n",
    "  ax1.set_xlabel(r\"Batch number\", fontsize=13)\n",
    "  ax1.set_ylabel(r\"Loss\", fontsize=13, color='b')\n",
    "  \n",
    "  ax2 = ax1.twinx()\n",
    "  epoch_points = np.arange(1, len(validat_correct_counts)+1) * len(train_loader)\n",
    "  validation_percentage = np.array(validat_correct_counts) / validat_size\n",
    "  ax2.plot( epoch_points, validation_percentage, color='r', linestyle='dashed', linewidth=2, marker='o')\n",
    "  ax2.set_ylabel(r\"Validation rate\", fontsize=13, color='r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53ac5fd",
   "metadata": {},
   "source": [
    "#### For comparison, we now repeat the above experiment, but with a sequential  Torchbraid network\n",
    "- That is, the gradient evaluations will now be exact (rather than approxmiated by parallel-in-time XBraid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d1125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Repeat above experiment, but with a sequential TorchBraid network, i.e., do only \n",
    "# sequential network evaluation (i.e., one level in XBraid) \n",
    "params['lp_max_levels'] = 1\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(params['seed'])\n",
    "\n",
    "# Re-load data set, so that the data loader ordering will be the same \n",
    "if params['dataset'] == 'digits':\n",
    "  root_print(rank, '-- Using Digit MNIST')\n",
    "  transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                  ])\n",
    "  dataset = datasets.MNIST(torchbraid_path + '/examples/mnist/digit-data', download=False, transform=transform)\n",
    "else:\n",
    "  root_print(rank, '-- Using Fashion MNIST')\n",
    "  transform = transforms.Compose([transforms.ToTensor()])\n",
    "  dataset = datasets.FashionMNIST(torchbraid_path + '/examples/mnist/fashion-data', download=False, transform=transform)\n",
    "\n",
    "train_size = int(50000 * params['percent_data'])\n",
    "test_size = int(10000 * params['percent_data'])\n",
    "train_set = torch.utils.data.Subset(dataset, range(train_size))\n",
    "test_set = torch.utils.data.Subset(dataset, range(train_size, train_size + test_size))\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=params['batch_size'], shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=params['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab9aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Create new network, but with sequential evaluation.  With max_levels==1, the \n",
    "# solver collapses to simple sequential evaluation\n",
    "model = ParallelNet(channels=params['channels'],\n",
    "                    local_steps=local_steps,\n",
    "                    max_levels=params['lp_max_levels'],\n",
    "                    bwd_max_iters=params['lp_bwd_max_iters'],\n",
    "                    fwd_max_iters=params['lp_fwd_max_iters'],\n",
    "                    print_level=params['lp_print_level'],\n",
    "                    braid_print_level=params['lp_braid_print_level'],\n",
    "                    cfactor=params['lp_cfactor'],\n",
    "                    fine_fcf=params['lp_fine_fcf'],\n",
    "                    skip_downcycle=not params['lp_use_downcycle'],\n",
    "                    fmg=False, \n",
    "                    Tf=params['Tf'],\n",
    "                    relax_only_cg=False,\n",
    "                    user_mpi_buf=params['lp_user_mpi_buf']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Declare optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=params['lr'], momentum=0.9)\n",
    "\n",
    "# For better timings (especially with GPUs) do a little warm up\n",
    "if params['warm_up']:\n",
    "  warm_up_timer = timer()\n",
    "  train(rank=rank, params=params, model=model, train_loader=train_loader, optimizer=optimizer, epoch=0,\n",
    "        compose=model.compose, device=device)\n",
    "  model.parallel_nn.timer_manager.resetTimers()\n",
    "  model.parallel_nn.fwd_app.resetBraidTimer()\n",
    "  model.parallel_nn.bwd_app.resetBraidTimer()\n",
    "  if use_cuda:\n",
    "    torch.cuda.synchronize()\n",
    "  root_print(rank, f'\\nWarm up timer {timer() - warm_up_timer}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb7f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# Carry out training\n",
    "batch_losses = []; batch_times = []\n",
    "epoch_times = []; test_times = []\n",
    "validat_correct_counts = []\n",
    "\n",
    "for epoch in range(1, params['epochs'] + 1):\n",
    "  start_time = timer()\n",
    "  [losses, train_times] = train(rank=rank, params=params, model=model, train_loader=train_loader, \n",
    "                                optimizer=optimizer, epoch=epoch, compose=model.compose, device=device)\n",
    "  epoch_times += [timer() - start_time]\n",
    "  batch_losses += losses\n",
    "  batch_times += train_times\n",
    "\n",
    "  start_time = timer()\n",
    "  validat_correct, validat_size, validat_loss = test(rank=rank, model=model, test_loader=test_loader, \n",
    "                                                     compose=model.compose, device=device)\n",
    "  test_times += [timer() - start_time]\n",
    "  validat_correct_counts += [validat_correct]\n",
    "\n",
    "\n",
    "root_print(rank,\n",
    "           f'TIME PER EPOCH: {\"{:.2f}\".format(stats.mean(epoch_times))} '\n",
    "           f'{(\"(1 std dev \" + \"{:.2f}\".format(stats.mean(epoch_times))) if len(epoch_times) > 1 else \"\"}')\n",
    "root_print(rank,\n",
    "           f'TIME PER TEST:  {\"{:.2f}\".format(stats.mean(test_times))} '\n",
    "           f'{(\"(1 std dev \" + \"{:.2f}\".format(stats.mean(test_times))) if len(test_times) > 1 else \"\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca5829",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the loss, validation \n",
    "root_print(rank, f'\\nMin batch time:   {\"{:.3f}\".format(np.min(batch_times))} ')\n",
    "root_print(rank, f'Mean batch time:  {\"{:.3f}\".format(stats.mean(batch_times))} ')\n",
    "\n",
    "\n",
    "if rank == 0:\n",
    "  fig, ax1 = plt.subplots()\n",
    "  plt.title('Layer-sequential run with %d processors\\n MNIST %s dataset'%(procs, params['dataset']), fontsize=15)\n",
    "  ax1.plot(batch_losses, color='b', linewidth=2)\n",
    "  ax1.grid(True, color='k', linestyle='-', linewidth=0.4)\n",
    "  ax1.set_xlabel(r\"Batch number\", fontsize=13)\n",
    "  ax1.set_ylabel(r\"Loss\", fontsize=13, color='b')\n",
    "  \n",
    "  ax2 = ax1.twinx()\n",
    "  epoch_points = np.arange(1, len(validat_correct_counts)+1) * len(train_loader)\n",
    "  validation_percentage = np.array(validat_correct_counts) / validat_size\n",
    "  ax2.plot( epoch_points, validation_percentage, color='r', linestyle='dashed', linewidth=2, marker='o')\n",
    "  ax2.set_ylabel(r\"Validation rate\", fontsize=13, color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71718e0",
   "metadata": {},
   "source": [
    "#### For an M1 Macbook Pro, with 32GB RAM, we see about a 1.33x speedup with layer-parallel over the layer-sequential.\n",
    "- Performance is *very* machine dependent, and software dependent.\n",
    "- For truly large speedups, *parallel clusters are needed*, and the command line interface is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5157f6de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

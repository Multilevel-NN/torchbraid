Using GPU Device
Run info rank: 0: Torch version: 2.1.2+cu121 | Device: cuda:0 | Host: cpu
Loading dataset; args.percent_data=0.2
Loaded tensor from ../data/wikipedia.data
1.4 Splitting data into training and validation data
len(train_data)=104035585, len(val_data)=11559510 percent_data=0.2
len(train_data)=20807117, len(val_data)=2311902
-- procs    = 1
-- Tf       = 1.0
-- steps    = 64
-- max_levels     = 1
-- max_bwd_iters  = 1
-- max_fwd_iters  = 3
-- cfactor        = 4
-- fine fcf       = False
-- skip down      = True

args.model_dimension=384 args.num_heads=6 args.batch_size=64
rank 0: len(list(model.parameters())) 1798
rank 0: 152238673
Train Epoch: 1 [0/81276 (0%)]	Loss: 11.000772 LR 5.00e-08
	 Magnitude of data 1.348e+06 output 1.660e+04 target 1.348e+06
Train Epoch: 1 [640/81276 (1%)]	Loss: 11.009435 LR 5.50e-07
	 Magnitude of data 1.314e+06 output 1.660e+04 target 1.314e+06
Train Epoch: 1 [1280/81276 (2%)]	Loss: 10.986696 LR 1.05e-06
	 Magnitude of data 1.495e+06 output 1.659e+04 target 1.495e+06
Train Epoch: 1 [1920/81276 (2%)]	Loss: 10.976248 LR 1.55e-06
	 Magnitude of data 1.218e+06 output 1.659e+04 target 1.218e+06
Train Epoch: 1 [2560/81276 (3%)]	Loss: 10.975123 LR 2.05e-06
	 Magnitude of data 1.281e+06 output 1.659e+04 target 1.281e+06
Train Epoch: 1 [3200/81276 (4%)]	Loss: 10.979345 LR 2.55e-06
	 Magnitude of data 1.317e+06 output 1.659e+04 target 1.317e+06
Train Epoch: 1 [3840/81276 (5%)]	Loss: 10.964023 LR 3.05e-06
	 Magnitude of data 1.281e+06 output 1.658e+04 target 1.281e+06
Train Epoch: 1 [4480/81276 (6%)]	Loss: 10.952149 LR 3.55e-06
	 Magnitude of data 1.306e+06 output 1.657e+04 target 1.306e+06
Train Epoch: 1 [5120/81276 (6%)]	Loss: 10.960439 LR 4.05e-06
	 Magnitude of data 1.360e+06 output 1.657e+04 target 1.360e+06
Train Epoch: 1 [5760/81276 (7%)]	Loss: 10.944418 LR 4.55e-06
	 Magnitude of data 1.349e+06 output 1.656e+04 target 1.350e+06
Train Epoch: 1 [6400/81276 (8%)]	Loss: 10.922575 LR 5.05e-06
	 Magnitude of data 1.285e+06 output 1.656e+04 target 1.286e+06
Train Epoch: 1 [7040/81276 (9%)]	Loss: 10.921886 LR 5.55e-06
	 Magnitude of data 1.278e+06 output 1.655e+04 target 1.278e+06
Train Epoch: 1 [7680/81276 (9%)]	Loss: 10.898433 LR 6.05e-06
	 Magnitude of data 1.419e+06 output 1.654e+04 target 1.419e+06
Train Epoch: 1 [8320/81276 (10%)]	Loss: 10.881657 LR 6.55e-06
	 Magnitude of data 1.234e+06 output 1.654e+04 target 1.234e+06
Train Epoch: 1 [8960/81276 (11%)]	Loss: 10.859171 LR 7.05e-06
	 Magnitude of data 1.348e+06 output 1.653e+04 target 1.348e+06
Train Epoch: 1 [9600/81276 (12%)]	Loss: 10.838159 LR 7.55e-06
	 Magnitude of data 1.364e+06 output 1.652e+04 target 1.364e+06
Train Epoch: 1 [10240/81276 (13%)]	Loss: 10.804186 LR 8.05e-06
	 Magnitude of data 1.276e+06 output 1.652e+04 target 1.276e+06
Train Epoch: 1 [10880/81276 (13%)]	Loss: 10.795131 LR 8.55e-06
	 Magnitude of data 1.240e+06 output 1.652e+04 target 1.240e+06
Train Epoch: 1 [11520/81276 (14%)]	Loss: 10.769133 LR 9.05e-06
	 Magnitude of data 1.342e+06 output 1.652e+04 target 1.342e+06
Train Epoch: 1 [12160/81276 (15%)]	Loss: 10.722316 LR 9.54e-06
	 Magnitude of data 1.359e+06 output 1.652e+04 target 1.359e+06
Train Epoch: 1 [12800/81276 (16%)]	Loss: 10.668314 LR 1.00e-05
	 Magnitude of data 1.366e+06 output 1.654e+04 target 1.366e+06
Train Epoch: 1 [13440/81276 (17%)]	Loss: 10.591027 LR 1.05e-05
	 Magnitude of data 1.241e+06 output 1.656e+04 target 1.241e+06
Train Epoch: 1 [14080/81276 (17%)]	Loss: 10.548623 LR 1.10e-05
	 Magnitude of data 1.396e+06 output 1.661e+04 target 1.396e+06
Train Epoch: 1 [14720/81276 (18%)]	Loss: 10.471497 LR 1.15e-05
	 Magnitude of data 1.450e+06 output 1.668e+04 target 1.450e+06
Train Epoch: 1 [15360/81276 (19%)]	Loss: 10.439885 LR 1.20e-05
	 Magnitude of data 1.387e+06 output 1.681e+04 target 1.387e+06
Train Epoch: 1 [16000/81276 (20%)]	Loss: 10.330172 LR 1.25e-05
	 Magnitude of data 1.371e+06 output 1.699e+04 target 1.371e+06
Train Epoch: 1 [16640/81276 (20%)]	Loss: 10.210578 LR 1.30e-05
	 Magnitude of data 1.274e+06 output 1.725e+04 target 1.274e+06
Train Epoch: 1 [17280/81276 (21%)]	Loss: 10.111966 LR 1.35e-05
	 Magnitude of data 1.443e+06 output 1.765e+04 target 1.442e+06
Train Epoch: 1 [17920/81276 (22%)]	Loss: 9.975654 LR 1.40e-05
	 Magnitude of data 1.267e+06 output 1.820e+04 target 1.266e+06
Train Epoch: 1 [18560/81276 (23%)]	Loss: 9.736710 LR 1.45e-05
	 Magnitude of data 1.246e+06 output 1.889e+04 target 1.246e+06
Train Epoch: 1 [19200/81276 (24%)]	Loss: 9.570976 LR 1.50e-05
	 Magnitude of data 1.254e+06 output 1.976e+04 target 1.254e+06
Train Epoch: 1 [19840/81276 (24%)]	Loss: 9.597686 LR 1.55e-05
	 Magnitude of data 1.331e+06 output 2.071e+04 target 1.331e+06
Train Epoch: 1 [20480/81276 (25%)]	Loss: 9.440349 LR 1.60e-05
	 Magnitude of data 1.190e+06 output 2.176e+04 target 1.190e+06
Train Epoch: 1 [21120/81276 (26%)]	Loss: 9.314984 LR 1.65e-05
	 Magnitude of data 1.290e+06 output 2.284e+04 target 1.290e+06
Train Epoch: 1 [21760/81276 (27%)]	Loss: 9.247430 LR 1.70e-05
	 Magnitude of data 1.386e+06 output 2.396e+04 target 1.385e+06
Train Epoch: 1 [22400/81276 (28%)]	Loss: 9.140777 LR 1.75e-05
	 Magnitude of data 1.271e+06 output 2.511e+04 target 1.271e+06
Train Epoch: 1 [23040/81276 (28%)]	Loss: 9.091216 LR 1.80e-05
	 Magnitude of data 1.259e+06 output 2.628e+04 target 1.259e+06
Train Epoch: 1 [23680/81276 (29%)]	Loss: 8.923466 LR 1.85e-05
	 Magnitude of data 1.231e+06 output 2.748e+04 target 1.231e+06
Train Epoch: 1 [24320/81276 (30%)]	Loss: 8.888862 LR 1.90e-05
	 Magnitude of data 1.323e+06 output 2.871e+04 target 1.322e+06
Train Epoch: 1 [24960/81276 (31%)]	Loss: 8.746445 LR 1.95e-05
	 Magnitude of data 1.341e+06 output 2.994e+04 target 1.341e+06
Train Epoch: 1 [25600/81276 (32%)]	Loss: 8.721508 LR 2.00e-05
	 Magnitude of data 1.299e+06 output 3.123e+04 target 1.299e+06
Train Epoch: 1 [26240/81276 (32%)]	Loss: 8.631906 LR 2.05e-05
	 Magnitude of data 1.329e+06 output 3.256e+04 target 1.329e+06
Train Epoch: 1 [26880/81276 (33%)]	Loss: 8.502169 LR 2.10e-05
	 Magnitude of data 1.258e+06 output 3.389e+04 target 1.258e+06
Train Epoch: 1 [27520/81276 (34%)]	Loss: 8.552497 LR 2.15e-05
	 Magnitude of data 1.280e+06 output 3.525e+04 target 1.280e+06
Train Epoch: 1 [28160/81276 (35%)]	Loss: 8.404217 LR 2.20e-05
	 Magnitude of data 1.353e+06 output 3.664e+04 target 1.353e+06
Train Epoch: 1 [28800/81276 (35%)]	Loss: 8.326910 LR 2.25e-05
	 Magnitude of data 1.316e+06 output 3.803e+04 target 1.316e+06
Train Epoch: 1 [29440/81276 (36%)]	Loss: 8.260703 LR 2.30e-05
	 Magnitude of data 1.295e+06 output 3.945e+04 target 1.295e+06
Train Epoch: 1 [30080/81276 (37%)]	Loss: 8.294806 LR 2.35e-05
	 Magnitude of data 1.290e+06 output 4.089e+04 target 1.290e+06
Train Epoch: 1 [30720/81276 (38%)]	Loss: 8.196349 LR 2.40e-05
	 Magnitude of data 1.320e+06 output 4.236e+04 target 1.320e+06
Train Epoch: 1 [31360/81276 (39%)]	Loss: 8.076207 LR 2.45e-05
	 Magnitude of data 1.397e+06 output 4.385e+04 target 1.397e+06
Train Epoch: 1 [32000/81276 (39%)]	Loss: 8.099161 LR 2.50e-05
	 Magnitude of data 1.283e+06 output 4.530e+04 target 1.283e+06
Train Epoch: 1 [32640/81276 (40%)]	Loss: 8.150474 LR 2.54e-05
	 Magnitude of data 1.354e+06 output 4.681e+04 target 1.354e+06
Train Epoch: 1 [33280/81276 (41%)]	Loss: 8.047694 LR 2.59e-05
	 Magnitude of data 1.271e+06 output 4.829e+04 target 1.271e+06
Train Epoch: 1 [33920/81276 (42%)]	Loss: 7.981164 LR 2.64e-05
	 Magnitude of data 1.296e+06 output 4.980e+04 target 1.296e+06
Train Epoch: 1 [34560/81276 (43%)]	Loss: 7.879169 LR 2.69e-05
	 Magnitude of data 1.312e+06 output 5.127e+04 target 1.312e+06
Train Epoch: 1 [35200/81276 (43%)]	Loss: 8.045605 LR 2.74e-05
	 Magnitude of data 1.383e+06 output 5.276e+04 target 1.383e+06
Train Epoch: 1 [35840/81276 (44%)]	Loss: 7.852698 LR 2.79e-05
	 Magnitude of data 1.314e+06 output 5.428e+04 target 1.314e+06
Train Epoch: 1 [36480/81276 (45%)]	Loss: 7.739443 LR 2.84e-05
	 Magnitude of data 1.359e+06 output 5.575e+04 target 1.359e+06
Train Epoch: 1 [37120/81276 (46%)]	Loss: 7.673316 LR 2.89e-05
	 Magnitude of data 1.273e+06 output 5.721e+04 target 1.273e+06
Train Epoch: 1 [37760/81276 (46%)]	Loss: 7.639373 LR 2.94e-05
	 Magnitude of data 1.261e+06 output 5.869e+04 target 1.261e+06
Train Epoch: 1 [38400/81276 (47%)]	Loss: 7.681692 LR 2.99e-05
	 Magnitude of data 1.358e+06 output 6.011e+04 target 1.358e+06
Train Epoch: 1 [39040/81276 (48%)]	Loss: 7.668279 LR 3.04e-05
	 Magnitude of data 1.339e+06 output 6.158e+04 target 1.339e+06
Train Epoch: 1 [39680/81276 (49%)]	Loss: 7.508271 LR 3.09e-05
	 Magnitude of data 1.233e+06 output 6.296e+04 target 1.233e+06
Train Epoch: 1 [40320/81276 (50%)]	Loss: 7.725695 LR 3.14e-05
	 Magnitude of data 1.395e+06 output 6.434e+04 target 1.395e+06
Train Epoch: 1 [40960/81276 (50%)]	Loss: 7.540021 LR 3.18e-05
	 Magnitude of data 1.324e+06 output 6.573e+04 target 1.324e+06
Train Epoch: 1 [41600/81276 (51%)]	Loss: 7.566790 LR 3.23e-05
	 Magnitude of data 1.367e+06 output 6.707e+04 target 1.367e+06
Train Epoch: 1 [42240/81276 (52%)]	Loss: 7.542429 LR 3.28e-05
	 Magnitude of data 1.301e+06 output 6.845e+04 target 1.301e+06
Train Epoch: 1 [42880/81276 (53%)]	Loss: 7.411039 LR 3.33e-05
	 Magnitude of data 1.223e+06 output 6.979e+04 target 1.223e+06
Train Epoch: 1 [43520/81276 (54%)]	Loss: 7.461411 LR 3.38e-05
	 Magnitude of data 1.285e+06 output 7.100e+04 target 1.285e+06
Train Epoch: 1 [44160/81276 (54%)]	Loss: 7.421968 LR 3.43e-05
	 Magnitude of data 1.281e+06 output 7.223e+04 target 1.281e+06
Train Epoch: 1 [44800/81276 (55%)]	Loss: 7.472388 LR 3.48e-05
	 Magnitude of data 1.413e+06 output 7.340e+04 target 1.413e+06
Train Epoch: 1 [45440/81276 (56%)]	Loss: 7.470087 LR 3.53e-05
	 Magnitude of data 1.310e+06 output 7.447e+04 target 1.310e+06
Train Epoch: 1 [46080/81276 (57%)]	Loss: 7.482762 LR 3.58e-05
	 Magnitude of data 1.308e+06 output 7.560e+04 target 1.308e+06
Train Epoch: 1 [46720/81276 (58%)]	Loss: 7.484683 LR 3.63e-05
	 Magnitude of data 1.370e+06 output 7.648e+04 target 1.371e+06
Train Epoch: 1 [47360/81276 (58%)]	Loss: 7.323445 LR 3.67e-05
	 Magnitude of data 1.361e+06 output 7.714e+04 target 1.361e+06
Train Epoch: 1 [48000/81276 (59%)]	Loss: 7.403510 LR 3.72e-05
	 Magnitude of data 1.285e+06 output 7.777e+04 target 1.286e+06
Train Epoch: 1 [48640/81276 (60%)]	Loss: 7.297204 LR 3.77e-05
	 Magnitude of data 1.249e+06 output 7.838e+04 target 1.249e+06
Train Epoch: 1 [49280/81276 (61%)]	Loss: 7.247702 LR 3.82e-05
	 Magnitude of data 1.305e+06 output 7.926e+04 target 1.305e+06
Train Epoch: 1 [49920/81276 (61%)]	Loss: 7.365381 LR 3.87e-05
	 Magnitude of data 1.259e+06 output 8.009e+04 target 1.259e+06
Train Epoch: 1 [50560/81276 (62%)]	Loss: 7.333674 LR 3.92e-05
	 Magnitude of data 1.274e+06 output 8.079e+04 target 1.273e+06
Train Epoch: 1 [51200/81276 (63%)]	Loss: 7.214077 LR 3.97e-05
	 Magnitude of data 1.319e+06 output 8.135e+04 target 1.319e+06
Train Epoch: 1 [51840/81276 (64%)]	Loss: 7.293200 LR 4.01e-05
	 Magnitude of data 1.351e+06 output 8.272e+04 target 1.351e+06
Train Epoch: 1 [52480/81276 (65%)]	Loss: 7.156312 LR 4.06e-05
	 Magnitude of data 1.318e+06 output 8.388e+04 target 1.318e+06
Train Epoch: 1 [53120/81276 (65%)]	Loss: 7.061010 LR 4.11e-05
	 Magnitude of data 1.274e+06 output 8.475e+04 target 1.274e+06
Train Epoch: 1 [53760/81276 (66%)]	Loss: 7.336077 LR 4.16e-05
	 Magnitude of data 1.363e+06 output 8.640e+04 target 1.363e+06
Train Epoch: 1 [54400/81276 (67%)]	Loss: 7.155916 LR 4.21e-05
	 Magnitude of data 1.305e+06 output 8.644e+04 target 1.305e+06
Train Epoch: 1 [55040/81276 (68%)]	Loss: 7.191957 LR 4.26e-05
	 Magnitude of data 1.319e+06 output 8.774e+04 target 1.318e+06
Train Epoch: 1 [55680/81276 (69%)]	Loss: 7.183036 LR 4.30e-05
	 Magnitude of data 1.197e+06 output 8.897e+04 target 1.197e+06
Train Epoch: 1 [56320/81276 (69%)]	Loss: 7.213150 LR 4.35e-05
	 Magnitude of data 1.373e+06 output 8.956e+04 target 1.373e+06
Train Epoch: 1 [56960/81276 (70%)]	Loss: 7.199580 LR 4.40e-05
	 Magnitude of data 1.323e+06 output 9.093e+04 target 1.323e+06
Train Epoch: 1 [57600/81276 (71%)]	Loss: 7.009979 LR 4.45e-05
	 Magnitude of data 1.223e+06 output 9.155e+04 target 1.223e+06
Train Epoch: 1 [58240/81276 (72%)]	Loss: 7.278961 LR 4.50e-05
	 Magnitude of data 1.344e+06 output 9.264e+04 target 1.344e+06
Train Epoch: 1 [58880/81276 (72%)]	Loss: 7.186088 LR 4.55e-05
	 Magnitude of data 1.282e+06 output 9.322e+04 target 1.282e+06
Train Epoch: 1 [59520/81276 (73%)]	Loss: 6.945459 LR 4.59e-05
	 Magnitude of data 1.214e+06 output 9.422e+04 target 1.214e+06
Train Epoch: 1 [60160/81276 (74%)]	Loss: 7.105260 LR 4.64e-05
	 Magnitude of data 1.322e+06 output 9.552e+04 target 1.323e+06
Train Epoch: 1 [60800/81276 (75%)]	Loss: 7.046062 LR 4.69e-05
	 Magnitude of data 1.290e+06 output 9.732e+04 target 1.290e+06
Train Epoch: 1 [61440/81276 (76%)]	Loss: 7.122824 LR 4.74e-05
	 Magnitude of data 1.354e+06 output 9.825e+04 target 1.354e+06
Train Epoch: 1 [62080/81276 (76%)]	Loss: 7.010834 LR 4.79e-05
	 Magnitude of data 1.348e+06 output 9.785e+04 target 1.348e+06
Train Epoch: 1 [62720/81276 (77%)]	Loss: 7.053173 LR 4.83e-05
	 Magnitude of data 1.358e+06 output 9.986e+04 target 1.358e+06
Train Epoch: 1 [63360/81276 (78%)]	Loss: 7.119152 LR 4.88e-05
	 Magnitude of data 1.367e+06 output 1.003e+05 target 1.367e+06
Train Epoch: 1 [64000/81276 (79%)]	Loss: 7.085427 LR 4.92e-05
	 Magnitude of data 1.341e+06 output 1.008e+05 target 1.341e+06
Train Epoch: 1 [64640/81276 (80%)]	Loss: 6.992692 LR 4.92e-05
	 Magnitude of data 1.274e+06 output 1.037e+05 target 1.274e+06
Train Epoch: 1 [65280/81276 (80%)]	Loss: 7.179012 LR 4.92e-05
	 Magnitude of data 1.638e+06 output 1.032e+05 target 1.638e+06
Train Epoch: 1 [65920/81276 (81%)]	Loss: 6.883253 LR 4.92e-05
	 Magnitude of data 1.178e+06 output 1.037e+05 target 1.178e+06
Train Epoch: 1 [66560/81276 (82%)]	Loss: 7.153742 LR 4.92e-05
	 Magnitude of data 1.313e+06 output 1.046e+05 target 1.313e+06
Train Epoch: 1 [67200/81276 (83%)]	Loss: 6.944738 LR 4.92e-05
	 Magnitude of data 1.305e+06 output 1.050e+05 target 1.305e+06
Train Epoch: 1 [67840/81276 (84%)]	Loss: 6.883546 LR 4.91e-05
	 Magnitude of data 1.243e+06 output 1.056e+05 target 1.243e+06
Train Epoch: 1 [68480/81276 (84%)]	Loss: 7.070658 LR 4.91e-05
	 Magnitude of data 1.389e+06 output 1.069e+05 target 1.389e+06
Train Epoch: 1 [69120/81276 (85%)]	Loss: 7.034863 LR 4.91e-05
	 Magnitude of data 1.368e+06 output 1.087e+05 target 1.368e+06
Train Epoch: 1 [69760/81276 (86%)]	Loss: 7.028214 LR 4.91e-05
	 Magnitude of data 1.272e+06 output 1.101e+05 target 1.272e+06
Train Epoch: 1 [70400/81276 (87%)]	Loss: 7.031360 LR 4.91e-05
	 Magnitude of data 1.307e+06 output 1.094e+05 target 1.307e+06
Train Epoch: 1 [71040/81276 (87%)]	Loss: 7.160437 LR 4.91e-05
	 Magnitude of data 1.298e+06 output 1.109e+05 target 1.298e+06
Train Epoch: 1 [71680/81276 (88%)]	Loss: 7.030445 LR 4.90e-05
	 Magnitude of data 1.285e+06 output 1.101e+05 target 1.285e+06
Train Epoch: 1 [72320/81276 (89%)]	Loss: 6.968877 LR 4.90e-05
	 Magnitude of data 1.372e+06 output 1.106e+05 target 1.372e+06
Train Epoch: 1 [72960/81276 (90%)]	Loss: 6.944224 LR 4.90e-05
	 Magnitude of data 1.268e+06 output 1.119e+05 target 1.268e+06
Train Epoch: 1 [73600/81276 (91%)]	Loss: 6.861008 LR 4.90e-05
	 Magnitude of data 1.248e+06 output 1.120e+05 target 1.248e+06
Train Epoch: 1 [74240/81276 (91%)]	Loss: 7.070155 LR 4.90e-05
	 Magnitude of data 1.344e+06 output 1.139e+05 target 1.344e+06
Train Epoch: 1 [74880/81276 (92%)]	Loss: 7.167336 LR 4.90e-05
	 Magnitude of data 1.405e+06 output 1.157e+05 target 1.405e+06
Train Epoch: 1 [75520/81276 (93%)]	Loss: 6.952049 LR 4.89e-05
	 Magnitude of data 1.326e+06 output 1.134e+05 target 1.326e+06
Train Epoch: 1 [76160/81276 (94%)]	Loss: 6.924011 LR 4.89e-05
	 Magnitude of data 1.291e+06 output 1.145e+05 target 1.291e+06
Train Epoch: 1 [76800/81276 (95%)]	Loss: 6.985326 LR 4.89e-05
	 Magnitude of data 1.338e+06 output 1.165e+05 target 1.338e+06
Train Epoch: 1 [77440/81276 (95%)]	Loss: 6.927793 LR 4.89e-05
	 Magnitude of data 1.279e+06 output 1.149e+05 target 1.279e+06
Train Epoch: 1 [78080/81276 (96%)]	Loss: 6.897579 LR 4.89e-05
	 Magnitude of data 1.287e+06 output 1.168e+05 target 1.287e+06
Train Epoch: 1 [78720/81276 (97%)]	Loss: 6.946007 LR 4.88e-05
	 Magnitude of data 1.253e+06 output 1.167e+05 target 1.253e+06
Train Epoch: 1 [79360/81276 (98%)]	Loss: 7.114809 LR 4.88e-05
	 Magnitude of data 1.327e+06 output 1.171e+05 target 1.327e+06
Train Epoch: 1 [80000/81276 (99%)]	Loss: 7.106954 LR 4.88e-05
	 Magnitude of data 1.478e+06 output 1.187e+05 target 1.478e+06
Train Epoch: 1 [80640/81276 (99%)]	Loss: 6.945631 LR 4.88e-05
	 Magnitude of data 1.218e+06 output 1.205e+05 target 1.218e+06
Train Epoch: 1 [81216/81276 (100%)]	Loss: 6.801493 LR 4.88e-05
Test set: Average loss: 6.93680231
Train Epoch: 2 [0/81276 (0%)]	Loss: 6.949060 LR 4.88e-05
	 Magnitude of data 1.348e+06 output 1.196e+05 target 1.348e+06
Train Epoch: 2 [640/81276 (1%)]	Loss: 6.934716 LR 4.88e-05
	 Magnitude of data 1.314e+06 output 1.205e+05 target 1.314e+06
Train Epoch: 2 [1280/81276 (2%)]	Loss: 7.065080 LR 4.87e-05
	 Magnitude of data 1.495e+06 output 1.209e+05 target 1.495e+06
Train Epoch: 2 [1920/81276 (2%)]	Loss: 6.856941 LR 4.87e-05
	 Magnitude of data 1.218e+06 output 1.207e+05 target 1.218e+06
Train Epoch: 2 [2560/81276 (3%)]	Loss: 6.774236 LR 4.87e-05
	 Magnitude of data 1.281e+06 output 1.235e+05 target 1.281e+06
Train Epoch: 2 [3200/81276 (4%)]	Loss: 6.766816 LR 4.87e-05
	 Magnitude of data 1.317e+06 output 1.240e+05 target 1.317e+06
Train Epoch: 2 [3840/81276 (5%)]	Loss: 6.834990 LR 4.87e-05
	 Magnitude of data 1.281e+06 output 1.228e+05 target 1.281e+06
Train Epoch: 2 [4480/81276 (6%)]	Loss: 6.799378 LR 4.86e-05
	 Magnitude of data 1.306e+06 output 1.236e+05 target 1.306e+06
Train Epoch: 2 [5120/81276 (6%)]	Loss: 6.844705 LR 4.86e-05
	 Magnitude of data 1.360e+06 output 1.239e+05 target 1.360e+06
Train Epoch: 2 [5760/81276 (7%)]	Loss: 6.919939 LR 4.86e-05
	 Magnitude of data 1.349e+06 output 1.257e+05 target 1.350e+06
Train Epoch: 2 [6400/81276 (8%)]	Loss: 7.092917 LR 4.86e-05
	 Magnitude of data 1.285e+06 output 1.256e+05 target 1.286e+06
Train Epoch: 2 [7040/81276 (9%)]	Loss: 6.917377 LR 4.86e-05
	 Magnitude of data 1.278e+06 output 1.279e+05 target 1.278e+06
Train Epoch: 2 [7680/81276 (9%)]	Loss: 7.073175 LR 4.85e-05
	 Magnitude of data 1.419e+06 output 1.252e+05 target 1.419e+06
Train Epoch: 2 [8320/81276 (10%)]	Loss: 6.977255 LR 4.85e-05
	 Magnitude of data 1.234e+06 output 1.257e+05 target 1.234e+06
Train Epoch: 2 [8960/81276 (11%)]	Loss: 6.989079 LR 4.85e-05
	 Magnitude of data 1.348e+06 output 1.255e+05 target 1.348e+06
Train Epoch: 2 [9600/81276 (12%)]	Loss: 6.841192 LR 4.85e-05
	 Magnitude of data 1.364e+06 output 1.262e+05 target 1.364e+06
Train Epoch: 2 [10240/81276 (13%)]	Loss: 6.778175 LR 4.84e-05
	 Magnitude of data 1.276e+06 output 1.283e+05 target 1.276e+06
Train Epoch: 2 [10880/81276 (13%)]	Loss: 6.775453 LR 4.84e-05
	 Magnitude of data 1.240e+06 output 1.283e+05 target 1.240e+06
Train Epoch: 2 [11520/81276 (14%)]	Loss: 6.875647 LR 4.84e-05
	 Magnitude of data 1.342e+06 output 1.300e+05 target 1.342e+06
Train Epoch: 2 [12160/81276 (15%)]	Loss: 6.852270 LR 4.84e-05
	 Magnitude of data 1.359e+06 output 1.277e+05 target 1.359e+06
Train Epoch: 2 [12800/81276 (16%)]	Loss: 6.895722 LR 4.84e-05
	 Magnitude of data 1.366e+06 output 1.293e+05 target 1.366e+06
Train Epoch: 2 [13440/81276 (17%)]	Loss: 6.675690 LR 4.83e-05
	 Magnitude of data 1.241e+06 output 1.302e+05 target 1.241e+06
Train Epoch: 2 [14080/81276 (17%)]	Loss: 6.894568 LR 4.83e-05
	 Magnitude of data 1.396e+06 output 1.317e+05 target 1.396e+06
Train Epoch: 2 [14720/81276 (18%)]	Loss: 6.980617 LR 4.83e-05
	 Magnitude of data 1.450e+06 output 1.314e+05 target 1.450e+06
Train Epoch: 2 [15360/81276 (19%)]	Loss: 7.063584 LR 4.83e-05
	 Magnitude of data 1.387e+06 output 1.323e+05 target 1.387e+06
Train Epoch: 2 [16000/81276 (20%)]	Loss: 6.881816 LR 4.83e-05
	 Magnitude of data 1.371e+06 output 1.337e+05 target 1.371e+06
Train Epoch: 2 [16640/81276 (20%)]	Loss: 6.729370 LR 4.82e-05
	 Magnitude of data 1.274e+06 output 1.341e+05 target 1.274e+06
Train Epoch: 2 [17280/81276 (21%)]	Loss: 7.062331 LR 4.82e-05
	 Magnitude of data 1.443e+06 output 1.347e+05 target 1.442e+06
Train Epoch: 2 [17920/81276 (22%)]	Loss: 6.828859 LR 4.82e-05
	 Magnitude of data 1.267e+06 output 1.335e+05 target 1.266e+06
Train Epoch: 2 [18560/81276 (23%)]	Loss: 6.610816 LR 4.82e-05
	 Magnitude of data 1.246e+06 output 1.321e+05 target 1.246e+06
Train Epoch: 2 [19200/81276 (24%)]	Loss: 6.664390 LR 4.81e-05
	 Magnitude of data 1.254e+06 output 1.334e+05 target 1.254e+06
Train Epoch: 2 [19840/81276 (24%)]	Loss: 6.830395 LR 4.81e-05
	 Magnitude of data 1.331e+06 output 1.359e+05 target 1.331e+06
Train Epoch: 2 [20480/81276 (25%)]	Loss: 6.759163 LR 4.81e-05
	 Magnitude of data 1.190e+06 output 1.336e+05 target 1.190e+06
Train Epoch: 2 [21120/81276 (26%)]	Loss: 6.800800 LR 4.81e-05
	 Magnitude of data 1.290e+06 output 1.354e+05 target 1.290e+06
Train Epoch: 2 [21760/81276 (27%)]	Loss: 6.840104 LR 4.80e-05
	 Magnitude of data 1.386e+06 output 1.365e+05 target 1.385e+06
Train Epoch: 2 [22400/81276 (28%)]	Loss: 6.725213 LR 4.80e-05
	 Magnitude of data 1.271e+06 output 1.369e+05 target 1.271e+06
Train Epoch: 2 [23040/81276 (28%)]	Loss: 6.946663 LR 4.80e-05
	 Magnitude of data 1.259e+06 output 1.362e+05 target 1.259e+06
Train Epoch: 2 [23680/81276 (29%)]	Loss: 6.698806 LR 4.80e-05
	 Magnitude of data 1.231e+06 output 1.380e+05 target 1.231e+06
Train Epoch: 2 [24320/81276 (30%)]	Loss: 6.864354 LR 4.79e-05
	 Magnitude of data 1.323e+06 output 1.400e+05 target 1.322e+06
Train Epoch: 2 [24960/81276 (31%)]	Loss: 6.582379 LR 4.79e-05
	 Magnitude of data 1.341e+06 output 1.342e+05 target 1.341e+06
Train Epoch: 2 [25600/81276 (32%)]	Loss: 6.743730 LR 4.79e-05
	 Magnitude of data 1.299e+06 output 1.399e+05 target 1.299e+06
Train Epoch: 2 [26240/81276 (32%)]	Loss: 6.825347 LR 4.79e-05
	 Magnitude of data 1.329e+06 output 1.391e+05 target 1.329e+06
Train Epoch: 2 [26880/81276 (33%)]	Loss: 6.552937 LR 4.78e-05
	 Magnitude of data 1.258e+06 output 1.397e+05 target 1.258e+06
Train Epoch: 2 [27520/81276 (34%)]	Loss: 6.804069 LR 4.78e-05
	 Magnitude of data 1.280e+06 output 1.416e+05 target 1.280e+06
Train Epoch: 2 [28160/81276 (35%)]	Loss: 6.767579 LR 4.78e-05
	 Magnitude of data 1.353e+06 output 1.391e+05 target 1.353e+06
Train Epoch: 2 [28800/81276 (35%)]	Loss: 6.692924 LR 4.78e-05
	 Magnitude of data 1.316e+06 output 1.411e+05 target 1.316e+06
Train Epoch: 2 [29440/81276 (36%)]	Loss: 6.791650 LR 4.77e-05
	 Magnitude of data 1.295e+06 output 1.421e+05 target 1.295e+06
Train Epoch: 2 [30080/81276 (37%)]	Loss: 6.709067 LR 4.77e-05
	 Magnitude of data 1.290e+06 output 1.413e+05 target 1.290e+06
Train Epoch: 2 [30720/81276 (38%)]	Loss: 6.722466 LR 4.77e-05
	 Magnitude of data 1.320e+06 output 1.415e+05 target 1.320e+06
Train Epoch: 2 [31360/81276 (39%)]	Loss: 6.620823 LR 4.77e-05
	 Magnitude of data 1.397e+06 output 1.417e+05 target 1.397e+06
Train Epoch: 2 [32000/81276 (39%)]	Loss: 6.741335 LR 4.76e-05
	 Magnitude of data 1.283e+06 output 1.437e+05 target 1.283e+06
Train Epoch: 2 [32640/81276 (40%)]	Loss: 6.920171 LR 4.76e-05
	 Magnitude of data 1.354e+06 output 1.439e+05 target 1.354e+06
Train Epoch: 2 [33280/81276 (41%)]	Loss: 6.814720 LR 4.76e-05
	 Magnitude of data 1.271e+06 output 1.428e+05 target 1.271e+06
Train Epoch: 2 [33920/81276 (42%)]	Loss: 6.797543 LR 4.76e-05
	 Magnitude of data 1.296e+06 output 1.448e+05 target 1.296e+06
Train Epoch: 2 [34560/81276 (43%)]	Loss: 6.792278 LR 4.75e-05
	 Magnitude of data 1.312e+06 output 1.469e+05 target 1.312e+06
Train Epoch: 2 [35200/81276 (43%)]	Loss: 7.107021 LR 4.75e-05
	 Magnitude of data 1.383e+06 output 1.442e+05 target 1.383e+06
Train Epoch: 2 [35840/81276 (44%)]	Loss: 6.738787 LR 4.75e-05
	 Magnitude of data 1.314e+06 output 1.450e+05 target 1.314e+06
Train Epoch: 2 [36480/81276 (45%)]	Loss: 6.759240 LR 4.75e-05
	 Magnitude of data 1.359e+06 output 1.435e+05 target 1.359e+06
Train Epoch: 2 [37120/81276 (46%)]	Loss: 6.488495 LR 4.74e-05
	 Magnitude of data 1.273e+06 output 1.466e+05 target 1.273e+06
Train Epoch: 2 [37760/81276 (46%)]	Loss: 6.586667 LR 4.74e-05
	 Magnitude of data 1.261e+06 output 1.462e+05 target 1.261e+06
Train Epoch: 2 [38400/81276 (47%)]	Loss: 6.620820 LR 4.74e-05
	 Magnitude of data 1.358e+06 output 1.458e+05 target 1.358e+06
Train Epoch: 2 [39040/81276 (48%)]	Loss: 6.754321 LR 4.73e-05
	 Magnitude of data 1.339e+06 output 1.490e+05 target 1.339e+06
Train Epoch: 2 [39680/81276 (49%)]	Loss: 6.472381 LR 4.73e-05
	 Magnitude of data 1.233e+06 output 1.452e+05 target 1.233e+06
Train Epoch: 2 [40320/81276 (50%)]	Loss: 6.769315 LR 4.73e-05
	 Magnitude of data 1.395e+06 output 1.473e+05 target 1.395e+06
Train Epoch: 2 [40960/81276 (50%)]	Loss: 6.672719 LR 4.73e-05
	 Magnitude of data 1.324e+06 output 1.481e+05 target 1.324e+06
Train Epoch: 2 [41600/81276 (51%)]	Loss: 6.685730 LR 4.72e-05
	 Magnitude of data 1.367e+06 output 1.482e+05 target 1.367e+06
Train Epoch: 2 [42240/81276 (52%)]	Loss: 6.680979 LR 4.72e-05
	 Magnitude of data 1.301e+06 output 1.482e+05 target 1.301e+06
Train Epoch: 2 [42880/81276 (53%)]	Loss: 6.502718 LR 4.72e-05
	 Magnitude of data 1.223e+06 output 1.472e+05 target 1.223e+06
Train Epoch: 2 [43520/81276 (54%)]	Loss: 6.625882 LR 4.71e-05
	 Magnitude of data 1.285e+06 output 1.492e+05 target 1.285e+06
Train Epoch: 2 [44160/81276 (54%)]	Loss: 6.603191 LR 4.71e-05
	 Magnitude of data 1.281e+06 output 1.521e+05 target 1.281e+06
Train Epoch: 2 [44800/81276 (55%)]	Loss: 6.691215 LR 4.71e-05
	 Magnitude of data 1.413e+06 output 1.478e+05 target 1.413e+06
Train Epoch: 2 [45440/81276 (56%)]	Loss: 6.726687 LR 4.71e-05
	 Magnitude of data 1.310e+06 output 1.529e+05 target 1.310e+06
Train Epoch: 2 [46080/81276 (57%)]	Loss: 6.764995 LR 4.70e-05
	 Magnitude of data 1.308e+06 output 1.523e+05 target 1.308e+06
Train Epoch: 2 [46720/81276 (58%)]	Loss: 6.781881 LR 4.70e-05
	 Magnitude of data 1.370e+06 output 1.508e+05 target 1.371e+06
Train Epoch: 2 [47360/81276 (58%)]	Loss: 6.524142 LR 4.70e-05
	 Magnitude of data 1.361e+06 output 1.502e+05 target 1.361e+06
Train Epoch: 2 [48000/81276 (59%)]	Loss: 6.711563 LR 4.69e-05
	 Magnitude of data 1.285e+06 output 1.472e+05 target 1.286e+06
Train Epoch: 2 [48640/81276 (60%)]	Loss: 6.519216 LR 4.69e-05
	 Magnitude of data 1.249e+06 output 1.533e+05 target 1.249e+06
Train Epoch: 2 [49280/81276 (61%)]	Loss: 6.547957 LR 4.69e-05
	 Magnitude of data 1.305e+06 output 1.489e+05 target 1.305e+06
Train Epoch: 2 [49920/81276 (61%)]	Loss: 6.683695 LR 4.68e-05
	 Magnitude of data 1.259e+06 output 1.526e+05 target 1.259e+06
Train Epoch: 2 [50560/81276 (62%)]	Loss: 6.640786 LR 4.68e-05
	 Magnitude of data 1.274e+06 output 1.521e+05 target 1.273e+06
Train Epoch: 2 [51200/81276 (63%)]	Loss: 6.505401 LR 4.68e-05
	 Magnitude of data 1.319e+06 output 1.505e+05 target 1.319e+06
Train Epoch: 2 [51840/81276 (64%)]	Loss: 6.701311 LR 4.68e-05
	 Magnitude of data 1.351e+06 output 1.561e+05 target 1.351e+06
Train Epoch: 2 [52480/81276 (65%)]	Loss: 6.503664 LR 4.67e-05
	 Magnitude of data 1.318e+06 output 1.528e+05 target 1.318e+06
Train Epoch: 2 [53120/81276 (65%)]	Loss: 6.416211 LR 4.67e-05
	 Magnitude of data 1.274e+06 output 1.522e+05 target 1.274e+06
Train Epoch: 2 [53760/81276 (66%)]	Loss: 6.726757 LR 4.67e-05
	 Magnitude of data 1.363e+06 output 1.536e+05 target 1.363e+06
Train Epoch: 2 [54400/81276 (67%)]	Loss: 6.580065 LR 4.66e-05
	 Magnitude of data 1.305e+06 output 1.513e+05 target 1.305e+06
Train Epoch: 2 [55040/81276 (68%)]	Loss: 6.635534 LR 4.66e-05
	 Magnitude of data 1.319e+06 output 1.563e+05 target 1.318e+06
Train Epoch: 2 [55680/81276 (69%)]	Loss: 6.669207 LR 4.66e-05
	 Magnitude of data 1.197e+06 output 1.547e+05 target 1.197e+06
Train Epoch: 2 [56320/81276 (69%)]	Loss: 6.635942 LR 4.65e-05
	 Magnitude of data 1.373e+06 output 1.510e+05 target 1.373e+06
Train Epoch: 2 [56960/81276 (70%)]	Loss: 6.674441 LR 4.65e-05
	 Magnitude of data 1.323e+06 output 1.577e+05 target 1.323e+06
Train Epoch: 2 [57600/81276 (71%)]	Loss: 6.504979 LR 4.65e-05
	 Magnitude of data 1.223e+06 output 1.557e+05 target 1.223e+06
Train Epoch: 2 [58240/81276 (72%)]	Loss: 6.799437 LR 4.64e-05
	 Magnitude of data 1.344e+06 output 1.548e+05 target 1.344e+06
Train Epoch: 2 [58880/81276 (72%)]	Loss: 6.734368 LR 4.64e-05
	 Magnitude of data 1.282e+06 output 1.540e+05 target 1.282e+06
Train Epoch: 2 [59520/81276 (73%)]	Loss: 6.411813 LR 4.64e-05
	 Magnitude of data 1.214e+06 output 1.542e+05 target 1.214e+06
Train Epoch: 2 [60160/81276 (74%)]	Loss: 6.607175 LR 4.64e-05
	 Magnitude of data 1.322e+06 output 1.592e+05 target 1.323e+06
Train Epoch: 2 [60800/81276 (75%)]	Loss: 6.573741 LR 4.63e-05
	 Magnitude of data 1.290e+06 output 1.562e+05 target 1.290e+06
Train Epoch: 2 [61440/81276 (76%)]	Loss: 6.610553 LR 4.63e-05
	 Magnitude of data 1.354e+06 output 1.574e+05 target 1.354e+06
Train Epoch: 2 [62080/81276 (76%)]	Loss: 6.542545 LR 4.63e-05
	 Magnitude of data 1.348e+06 output 1.575e+05 target 1.348e+06
Train Epoch: 2 [62720/81276 (77%)]	Loss: 6.565197 LR 4.62e-05
	 Magnitude of data 1.358e+06 output 1.578e+05 target 1.358e+06
Train Epoch: 2 [63360/81276 (78%)]	Loss: 6.684038 LR 4.62e-05
	 Magnitude of data 1.367e+06 output 1.558e+05 target 1.367e+06
Train Epoch: 2 [64000/81276 (79%)]	Loss: 6.619267 LR 4.62e-05
	 Magnitude of data 1.341e+06 output 1.565e+05 target 1.341e+06
Train Epoch: 2 [64640/81276 (80%)]	Loss: 6.552411 LR 4.61e-05
	 Magnitude of data 1.274e+06 output 1.620e+05 target 1.274e+06
Train Epoch: 2 [65280/81276 (80%)]	Loss: 6.669178 LR 4.61e-05
	 Magnitude of data 1.638e+06 output 1.578e+05 target 1.638e+06
Train Epoch: 2 [65920/81276 (81%)]	Loss: 6.445100 LR 4.61e-05
	 Magnitude of data 1.178e+06 output 1.586e+05 target 1.178e+06
Train Epoch: 2 [66560/81276 (82%)]	Loss: 6.716679 LR 4.60e-05
	 Magnitude of data 1.313e+06 output 1.549e+05 target 1.313e+06
Train Epoch: 2 [67200/81276 (83%)]	Loss: 6.504442 LR 4.60e-05
	 Magnitude of data 1.305e+06 output 1.601e+05 target 1.305e+06
Train Epoch: 2 [67840/81276 (84%)]	Loss: 6.398026 LR 4.60e-05
	 Magnitude of data 1.243e+06 output 1.571e+05 target 1.243e+06
Train Epoch: 2 [68480/81276 (84%)]	Loss: 6.625050 LR 4.59e-05
	 Magnitude of data 1.389e+06 output 1.592e+05 target 1.389e+06
Train Epoch: 2 [69120/81276 (85%)]	Loss: 6.603095 LR 4.59e-05
	 Magnitude of data 1.368e+06 output 1.605e+05 target 1.368e+06
Train Epoch: 2 [69760/81276 (86%)]	Loss: 6.619489 LR 4.59e-05
	 Magnitude of data 1.272e+06 output 1.637e+05 target 1.272e+06
Train Epoch: 2 [70400/81276 (87%)]	Loss: 6.645811 LR 4.58e-05
	 Magnitude of data 1.307e+06 output 1.590e+05 target 1.307e+06
Train Epoch: 2 [71040/81276 (87%)]	Loss: 6.780040 LR 4.58e-05
	 Magnitude of data 1.298e+06 output 1.620e+05 target 1.298e+06
Train Epoch: 2 [71680/81276 (88%)]	Loss: 6.609878 LR 4.58e-05
	 Magnitude of data 1.285e+06 output 1.577e+05 target 1.285e+06
Train Epoch: 2 [72320/81276 (89%)]	Loss: 6.531770 LR 4.57e-05
	 Magnitude of data 1.372e+06 output 1.602e+05 target 1.372e+06
Train Epoch: 2 [72960/81276 (90%)]	Loss: 6.536674 LR 4.57e-05
	 Magnitude of data 1.268e+06 output 1.612e+05 target 1.268e+06
Train Epoch: 2 [73600/81276 (91%)]	Loss: 6.429773 LR 4.56e-05
	 Magnitude of data 1.248e+06 output 1.601e+05 target 1.248e+06
Train Epoch: 2 [74240/81276 (91%)]	Loss: 6.676544 LR 4.56e-05
	 Magnitude of data 1.344e+06 output 1.597e+05 target 1.344e+06
Train Epoch: 2 [74880/81276 (92%)]	Loss: 6.788002 LR 4.56e-05
	 Magnitude of data 1.405e+06 output 1.607e+05 target 1.405e+06
Train Epoch: 2 [75520/81276 (93%)]	Loss: 6.555741 LR 4.55e-05
	 Magnitude of data 1.326e+06 output 1.594e+05 target 1.326e+06
Train Epoch: 2 [76160/81276 (94%)]	Loss: 6.536755 LR 4.55e-05
	 Magnitude of data 1.291e+06 output 1.615e+05 target 1.291e+06
Train Epoch: 2 [76800/81276 (95%)]	Loss: 6.609304 LR 4.55e-05
	 Magnitude of data 1.338e+06 output 1.605e+05 target 1.338e+06
Train Epoch: 2 [77440/81276 (95%)]	Loss: 6.525684 LR 4.54e-05
	 Magnitude of data 1.279e+06 output 1.620e+05 target 1.279e+06
Train Epoch: 2 [78080/81276 (96%)]	Loss: 6.495573 LR 4.54e-05
	 Magnitude of data 1.287e+06 output 1.609e+05 target 1.287e+06
Train Epoch: 2 [78720/81276 (97%)]	Loss: 6.612090 LR 4.54e-05
	 Magnitude of data 1.253e+06 output 1.582e+05 target 1.253e+06
Train Epoch: 2 [79360/81276 (98%)]	Loss: 6.770093 LR 4.53e-05
	 Magnitude of data 1.327e+06 output 1.606e+05 target 1.327e+06
Train Epoch: 2 [80000/81276 (99%)]	Loss: 6.740955 LR 4.53e-05
	 Magnitude of data 1.478e+06 output 1.623e+05 target 1.478e+06
Train Epoch: 2 [80640/81276 (99%)]	Loss: 6.562546 LR 4.53e-05
	 Magnitude of data 1.218e+06 output 1.659e+05 target 1.218e+06
Train Epoch: 2 [81216/81276 (100%)]	Loss: 6.447648 LR 4.52e-05
Test set: Average loss: 6.57403312
Train Epoch: 3 [0/81276 (0%)]	Loss: 6.594769 LR 4.52e-05
	 Magnitude of data 1.348e+06 output 1.595e+05 target 1.348e+06
Train Epoch: 3 [640/81276 (1%)]	Loss: 6.573676 LR 4.52e-05
	 Magnitude of data 1.314e+06 output 1.638e+05 target 1.314e+06
Train Epoch: 3 [1280/81276 (2%)]	Loss: 6.748825 LR 4.51e-05
	 Magnitude of data 1.495e+06 output 1.626e+05 target 1.495e+06
Train Epoch: 3 [1920/81276 (2%)]	Loss: 6.527438 LR 4.51e-05
	 Magnitude of data 1.218e+06 output 1.638e+05 target 1.218e+06
Train Epoch: 3 [2560/81276 (3%)]	Loss: 6.387085 LR 4.51e-05
	 Magnitude of data 1.281e+06 output 1.633e+05 target 1.281e+06
Train Epoch: 3 [3200/81276 (4%)]	Loss: 6.374400 LR 4.50e-05
	 Magnitude of data 1.317e+06 output 1.673e+05 target 1.317e+06
Train Epoch: 3 [3840/81276 (5%)]	Loss: 6.443857 LR 4.50e-05
	 Magnitude of data 1.281e+06 output 1.628e+05 target 1.281e+06
Train Epoch: 3 [4480/81276 (6%)]	Loss: 6.439304 LR 4.50e-05
	 Magnitude of data 1.306e+06 output 1.626e+05 target 1.306e+06
Train Epoch: 3 [5120/81276 (6%)]	Loss: 6.484279 LR 4.49e-05
	 Magnitude of data 1.360e+06 output 1.663e+05 target 1.360e+06
Train Epoch: 3 [5760/81276 (7%)]	Loss: 6.576810 LR 4.49e-05
	 Magnitude of data 1.349e+06 output 1.639e+05 target 1.350e+06
Train Epoch: 3 [6400/81276 (8%)]	Loss: 6.725543 LR 4.49e-05
	 Magnitude of data 1.285e+06 output 1.607e+05 target 1.286e+06
Train Epoch: 3 [7040/81276 (9%)]	Loss: 6.556888 LR 4.48e-05
	 Magnitude of data 1.278e+06 output 1.665e+05 target 1.278e+06
Train Epoch: 3 [7680/81276 (9%)]	Loss: 6.768878 LR 4.48e-05
	 Magnitude of data 1.419e+06 output 1.626e+05 target 1.419e+06
Train Epoch: 3 [8320/81276 (10%)]	Loss: 6.657302 LR 4.47e-05
	 Magnitude of data 1.234e+06 output 1.623e+05 target 1.234e+06
Train Epoch: 3 [8960/81276 (11%)]	Loss: 6.694883 LR 4.47e-05
	 Magnitude of data 1.348e+06 output 1.632e+05 target 1.348e+06
Train Epoch: 3 [9600/81276 (12%)]	Loss: 6.505591 LR 4.47e-05
	 Magnitude of data 1.364e+06 output 1.637e+05 target 1.364e+06
Train Epoch: 3 [10240/81276 (13%)]	Loss: 6.461652 LR 4.46e-05
	 Magnitude of data 1.276e+06 output 1.651e+05 target 1.276e+06
Train Epoch: 3 [10880/81276 (13%)]	Loss: 6.437673 LR 4.46e-05
	 Magnitude of data 1.240e+06 output 1.665e+05 target 1.240e+06
Train Epoch: 3 [11520/81276 (14%)]	Loss: 6.554837 LR 4.45e-05
	 Magnitude of data 1.342e+06 output 1.632e+05 target 1.342e+06
Train Epoch: 3 [12160/81276 (15%)]	Loss: 6.502884 LR 4.45e-05
	 Magnitude of data 1.359e+06 output 1.627e+05 target 1.359e+06
Train Epoch: 3 [12800/81276 (16%)]	Loss: 6.580936 LR 4.45e-05
	 Magnitude of data 1.366e+06 output 1.656e+05 target 1.366e+06
Train Epoch: 3 [13440/81276 (17%)]	Loss: 6.348916 LR 4.44e-05
	 Magnitude of data 1.241e+06 output 1.652e+05 target 1.241e+06
Train Epoch: 3 [14080/81276 (17%)]	Loss: 6.584309 LR 4.44e-05
	 Magnitude of data 1.396e+06 output 1.653e+05 target 1.396e+06
Train Epoch: 3 [14720/81276 (18%)]	Loss: 6.678571 LR 4.44e-05
	 Magnitude of data 1.450e+06 output 1.646e+05 target 1.450e+06
Train Epoch: 3 [15360/81276 (19%)]	Loss: 6.778381 LR 4.43e-05
	 Magnitude of data 1.387e+06 output 1.649e+05 target 1.387e+06
Train Epoch: 3 [16000/81276 (20%)]	Loss: 6.554284 LR 4.43e-05
	 Magnitude of data 1.371e+06 output 1.666e+05 target 1.371e+06
Train Epoch: 3 [16640/81276 (20%)]	Loss: 6.407035 LR 4.42e-05
	 Magnitude of data 1.274e+06 output 1.689e+05 target 1.274e+06
Train Epoch: 3 [17280/81276 (21%)]	Loss: 6.782712 LR 4.42e-05
	 Magnitude of data 1.443e+06 output 1.647e+05 target 1.442e+06
Train Epoch: 3 [17920/81276 (22%)]	Loss: 6.526790 LR 4.42e-05
	 Magnitude of data 1.267e+06 output 1.666e+05 target 1.266e+06
Train Epoch: 3 [18560/81276 (23%)]	Loss: 6.325577 LR 4.41e-05
	 Magnitude of data 1.246e+06 output 1.657e+05 target 1.246e+06
Train Epoch: 3 [19200/81276 (24%)]	Loss: 6.380477 LR 4.41e-05
	 Magnitude of data 1.254e+06 output 1.624e+05 target 1.254e+06
Train Epoch: 3 [19840/81276 (24%)]	Loss: 6.532373 LR 4.40e-05
	 Magnitude of data 1.331e+06 output 1.677e+05 target 1.331e+06
Train Epoch: 3 [20480/81276 (25%)]	Loss: 6.458440 LR 4.40e-05
	 Magnitude of data 1.190e+06 output 1.674e+05 target 1.190e+06
Train Epoch: 3 [21120/81276 (26%)]	Loss: 6.524909 LR 4.40e-05
	 Magnitude of data 1.290e+06 output 1.644e+05 target 1.290e+06
Train Epoch: 3 [21760/81276 (27%)]	Loss: 6.542057 LR 4.39e-05
	 Magnitude of data 1.386e+06 output 1.662e+05 target 1.385e+06
Train Epoch: 3 [22400/81276 (28%)]	Loss: 6.412209 LR 4.39e-05
	 Magnitude of data 1.271e+06 output 1.658e+05 target 1.271e+06
Train Epoch: 3 [23040/81276 (28%)]	Loss: 6.683762 LR 4.38e-05
	 Magnitude of data 1.259e+06 output 1.673e+05 target 1.259e+06
Train Epoch: 3 [23680/81276 (29%)]	Loss: 6.419557 LR 4.38e-05
	 Magnitude of data 1.231e+06 output 1.696e+05 target 1.231e+06
Train Epoch: 3 [24320/81276 (30%)]	Loss: 6.579145 LR 4.38e-05
	 Magnitude of data 1.323e+06 output 1.696e+05 target 1.322e+06
Train Epoch: 3 [24960/81276 (31%)]	Loss: 6.282966 LR 4.37e-05
	 Magnitude of data 1.341e+06 output 1.665e+05 target 1.341e+06
Train Epoch: 3 [25600/81276 (32%)]	Loss: 6.434726 LR 4.37e-05
	 Magnitude of data 1.299e+06 output 1.678e+05 target 1.299e+06
Train Epoch: 3 [26240/81276 (32%)]	Loss: 6.559192 LR 4.36e-05
	 Magnitude of data 1.329e+06 output 1.660e+05 target 1.329e+06
Train Epoch: 3 [26880/81276 (33%)]	Loss: 6.252183 LR 4.36e-05
	 Magnitude of data 1.258e+06 output 1.683e+05 target 1.258e+06
Train Epoch: 3 [27520/81276 (34%)]	Loss: 6.526134 LR 4.35e-05
	 Magnitude of data 1.280e+06 output 1.711e+05 target 1.280e+06
Train Epoch: 3 [28160/81276 (35%)]	Loss: 6.489134 LR 4.35e-05
	 Magnitude of data 1.353e+06 output 1.646e+05 target 1.353e+06
Train Epoch: 3 [28800/81276 (35%)]	Loss: 6.344073 LR 4.35e-05
	 Magnitude of data 1.316e+06 output 1.704e+05 target 1.316e+06
Train Epoch: 3 [29440/81276 (36%)]	Loss: 6.514338 LR 4.34e-05
	 Magnitude of data 1.295e+06 output 1.668e+05 target 1.295e+06
Train Epoch: 3 [30080/81276 (37%)]	Loss: 6.442693 LR 4.34e-05
	 Magnitude of data 1.290e+06 output 1.682e+05 target 1.290e+06
Train Epoch: 3 [30720/81276 (38%)]	Loss: 6.420266 LR 4.33e-05
	 Magnitude of data 1.320e+06 output 1.688e+05 target 1.320e+06
Train Epoch: 3 [31360/81276 (39%)]	Loss: 6.393661 LR 4.33e-05
	 Magnitude of data 1.397e+06 output 1.648e+05 target 1.397e+06
Train Epoch: 3 [32000/81276 (39%)]	Loss: 6.458292 LR 4.33e-05
	 Magnitude of data 1.283e+06 output 1.692e+05 target 1.283e+06
Train Epoch: 3 [32640/81276 (40%)]	Loss: 6.725585 LR 4.32e-05
	 Magnitude of data 1.354e+06 output 1.666e+05 target 1.354e+06
Train Epoch: 3 [33280/81276 (41%)]	Loss: 6.552812 LR 4.32e-05
	 Magnitude of data 1.271e+06 output 1.690e+05 target 1.271e+06
Train Epoch: 3 [33920/81276 (42%)]	Loss: 6.527352 LR 4.31e-05
	 Magnitude of data 1.296e+06 output 1.716e+05 target 1.296e+06
Train Epoch: 3 [34560/81276 (43%)]	Loss: 6.543916 LR 4.31e-05
	 Magnitude of data 1.312e+06 output 1.698e+05 target 1.312e+06
Train Epoch: 3 [35200/81276 (43%)]	Loss: 6.876618 LR 4.30e-05
	 Magnitude of data 1.383e+06 output 1.701e+05 target 1.383e+06
Train Epoch: 3 [35840/81276 (44%)]	Loss: 6.478720 LR 4.30e-05
	 Magnitude of data 1.314e+06 output 1.692e+05 target 1.314e+06
Train Epoch: 3 [36480/81276 (45%)]	Loss: 6.521189 LR 4.30e-05
	 Magnitude of data 1.359e+06 output 1.684e+05 target 1.359e+06
Train Epoch: 3 [37120/81276 (46%)]	Loss: 6.177391 LR 4.29e-05
	 Magnitude of data 1.273e+06 output 1.683e+05 target 1.273e+06
Train Epoch: 3 [37760/81276 (46%)]	Loss: 6.320503 LR 4.29e-05
	 Magnitude of data 1.261e+06 output 1.711e+05 target 1.261e+06
Train Epoch: 3 [38400/81276 (47%)]	Loss: 6.300489 LR 4.28e-05
	 Magnitude of data 1.358e+06 output 1.699e+05 target 1.358e+06
Train Epoch: 3 [39040/81276 (48%)]	Loss: 6.486496 LR 4.28e-05
	 Magnitude of data 1.339e+06 output 1.717e+05 target 1.339e+06
Train Epoch: 3 [39680/81276 (49%)]	Loss: 6.232392 LR 4.27e-05
	 Magnitude of data 1.233e+06 output 1.688e+05 target 1.233e+06
Train Epoch: 3 [40320/81276 (50%)]	Loss: 6.515876 LR 4.27e-05
	 Magnitude of data 1.395e+06 output 1.666e+05 target 1.395e+06
Train Epoch: 3 [40960/81276 (50%)]	Loss: 6.405564 LR 4.26e-05
	 Magnitude of data 1.324e+06 output 1.704e+05 target 1.324e+06
Train Epoch: 3 [41600/81276 (51%)]	Loss: 6.452888 LR 4.26e-05
	 Magnitude of data 1.367e+06 output 1.701e+05 target 1.367e+06
Train Epoch: 3 [42240/81276 (52%)]	Loss: 6.421182 LR 4.26e-05
	 Magnitude of data 1.301e+06 output 1.693e+05 target 1.301e+06
Train Epoch: 3 [42880/81276 (53%)]	Loss: 6.231850 LR 4.25e-05
	 Magnitude of data 1.223e+06 output 1.693e+05 target 1.223e+06
Train Epoch: 3 [43520/81276 (54%)]	Loss: 6.378393 LR 4.25e-05
	 Magnitude of data 1.285e+06 output 1.699e+05 target 1.285e+06
Train Epoch: 3 [44160/81276 (54%)]	Loss: 6.344300 LR 4.24e-05
	 Magnitude of data 1.281e+06 output 1.720e+05 target 1.281e+06
Train Epoch: 3 [44800/81276 (55%)]	Loss: 6.442809 LR 4.24e-05
	 Magnitude of data 1.413e+06 output 1.717e+05 target 1.413e+06
Train Epoch: 3 [45440/81276 (56%)]	Loss: 6.484284 LR 4.23e-05
	 Magnitude of data 1.310e+06 output 1.720e+05 target 1.310e+06
Train Epoch: 3 [46080/81276 (57%)]	Loss: 6.531045 LR 4.23e-05
	 Magnitude of data 1.308e+06 output 1.718e+05 target 1.308e+06
Train Epoch: 3 [46720/81276 (58%)]	Loss: 6.557087 LR 4.23e-05
	 Magnitude of data 1.370e+06 output 1.713e+05 target 1.371e+06
Train Epoch: 3 [47360/81276 (58%)]	Loss: 6.269309 LR 4.22e-05
	 Magnitude of data 1.361e+06 output 1.697e+05 target 1.361e+06
Train Epoch: 3 [48000/81276 (59%)]	Loss: 6.504102 LR 4.22e-05
	 Magnitude of data 1.285e+06 output 1.673e+05 target 1.286e+06
Train Epoch: 3 [48640/81276 (60%)]	Loss: 6.244153 LR 4.21e-05
	 Magnitude of data 1.249e+06 output 1.724e+05 target 1.249e+06
Train Epoch: 3 [49280/81276 (61%)]	Loss: 6.304291 LR 4.21e-05
	 Magnitude of data 1.305e+06 output 1.674e+05 target 1.305e+06
Train Epoch: 3 [49920/81276 (61%)]	Loss: 6.419147 LR 4.20e-05
	 Magnitude of data 1.259e+06 output 1.722e+05 target 1.259e+06
Train Epoch: 3 [50560/81276 (62%)]	Loss: 6.401552 LR 4.20e-05
	 Magnitude of data 1.274e+06 output 1.717e+05 target 1.273e+06
Train Epoch: 3 [51200/81276 (63%)]	Loss: 6.233728 LR 4.19e-05
	 Magnitude of data 1.319e+06 output 1.702e+05 target 1.319e+06
Train Epoch: 3 [51840/81276 (64%)]	Loss: 6.456356 LR 4.19e-05
	 Magnitude of data 1.351e+06 output 1.747e+05 target 1.351e+06
Train Epoch: 3 [52480/81276 (65%)]	Loss: 6.224984 LR 4.18e-05
	 Magnitude of data 1.318e+06 output 1.721e+05 target 1.318e+06
Train Epoch: 3 [53120/81276 (65%)]	Loss: 6.185708 LR 4.18e-05
	 Magnitude of data 1.274e+06 output 1.713e+05 target 1.274e+06
Train Epoch: 3 [53760/81276 (66%)]	Loss: 6.480914 LR 4.18e-05
	 Magnitude of data 1.363e+06 output 1.687e+05 target 1.363e+06
Train Epoch: 3 [54400/81276 (67%)]	Loss: 6.340167 LR 4.17e-05
	 Magnitude of data 1.305e+06 output 1.698e+05 target 1.305e+06
Train Epoch: 3 [55040/81276 (68%)]	Loss: 6.395680 LR 4.17e-05
	 Magnitude of data 1.319e+06 output 1.749e+05 target 1.318e+06
Train Epoch: 3 [55680/81276 (69%)]	Loss: 6.453549 LR 4.16e-05
	 Magnitude of data 1.197e+06 output 1.724e+05 target 1.197e+06
Train Epoch: 3 [56320/81276 (69%)]	Loss: 6.386389 LR 4.16e-05
	 Magnitude of data 1.373e+06 output 1.659e+05 target 1.373e+06
Train Epoch: 3 [56960/81276 (70%)]	Loss: 6.438293 LR 4.15e-05
	 Magnitude of data 1.323e+06 output 1.717e+05 target 1.323e+06
Train Epoch: 3 [57600/81276 (71%)]	Loss: 6.277837 LR 4.15e-05
	 Magnitude of data 1.223e+06 output 1.726e+05 target 1.223e+06
Train Epoch: 3 [58240/81276 (72%)]	Loss: 6.601683 LR 4.14e-05
	 Magnitude of data 1.344e+06 output 1.712e+05 target 1.344e+06
Train Epoch: 3 [58880/81276 (72%)]	Loss: 6.538271 LR 4.14e-05
	 Magnitude of data 1.282e+06 output 1.692e+05 target 1.282e+06
Train Epoch: 3 [59520/81276 (73%)]	Loss: 6.173308 LR 4.13e-05
	 Magnitude of data 1.214e+06 output 1.706e+05 target 1.214e+06
Train Epoch: 3 [60160/81276 (74%)]	Loss: 6.387234 LR 4.13e-05
	 Magnitude of data 1.322e+06 output 1.739e+05 target 1.323e+06
Train Epoch: 3 [60800/81276 (75%)]	Loss: 6.355814 LR 4.12e-05
	 Magnitude of data 1.290e+06 output 1.716e+05 target 1.290e+06
Train Epoch: 3 [61440/81276 (76%)]	Loss: 6.359174 LR 4.12e-05
	 Magnitude of data 1.354e+06 output 1.718e+05 target 1.354e+06
Train Epoch: 3 [62080/81276 (76%)]	Loss: 6.308832 LR 4.11e-05
	 Magnitude of data 1.348e+06 output 1.733e+05 target 1.348e+06
Train Epoch: 3 [62720/81276 (77%)]	Loss: 6.340032 LR 4.11e-05
	 Magnitude of data 1.358e+06 output 1.734e+05 target 1.358e+06
Train Epoch: 3 [63360/81276 (78%)]	Loss: 6.476350 LR 4.11e-05
	 Magnitude of data 1.367e+06 output 1.701e+05 target 1.367e+06
Train Epoch: 3 [64000/81276 (79%)]	Loss: 6.362285 LR 4.10e-05
	 Magnitude of data 1.341e+06 output 1.712e+05 target 1.341e+06
Train Epoch: 3 [64640/81276 (80%)]	Loss: 6.339694 LR 4.10e-05
	 Magnitude of data 1.274e+06 output 1.775e+05 target 1.274e+06
Train Epoch: 3 [65280/81276 (80%)]	Loss: 6.402420 LR 4.09e-05
	 Magnitude of data 1.638e+06 output 1.707e+05 target 1.638e+06
Train Epoch: 3 [65920/81276 (81%)]	Loss: 6.215543 LR 4.09e-05
	 Magnitude of data 1.178e+06 output 1.769e+05 target 1.178e+06
Train Epoch: 3 [66560/81276 (82%)]	Loss: 6.502820 LR 4.08e-05
	 Magnitude of data 1.313e+06 output 1.709e+05 target 1.313e+06
Train Epoch: 3 [67200/81276 (83%)]	Loss: 6.302625 LR 4.08e-05
	 Magnitude of data 1.305e+06 output 1.726e+05 target 1.305e+06
Train Epoch: 3 [67840/81276 (84%)]	Loss: 6.156585 LR 4.07e-05
	 Magnitude of data 1.243e+06 output 1.721e+05 target 1.243e+06
Train Epoch: 3 [68480/81276 (84%)]	Loss: 6.404355 LR 4.07e-05
	 Magnitude of data 1.389e+06 output 1.752e+05 target 1.389e+06
Train Epoch: 3 [69120/81276 (85%)]	Loss: 6.380384 LR 4.06e-05
	 Magnitude of data 1.368e+06 output 1.742e+05 target 1.368e+06
Train Epoch: 3 [69760/81276 (86%)]	Loss: 6.434573 LR 4.06e-05
	 Magnitude of data 1.272e+06 output 1.789e+05 target 1.272e+06
Train Epoch: 3 [70400/81276 (87%)]	Loss: 6.454217 LR 4.05e-05
	 Magnitude of data 1.307e+06 output 1.722e+05 target 1.307e+06
Train Epoch: 3 [71040/81276 (87%)]	Loss: 6.582881 LR 4.05e-05
	 Magnitude of data 1.298e+06 output 1.759e+05 target 1.298e+06
Train Epoch: 3 [71680/81276 (88%)]	Loss: 6.395334 LR 4.04e-05
	 Magnitude of data 1.285e+06 output 1.734e+05 target 1.285e+06
Train Epoch: 3 [72320/81276 (89%)]	Loss: 6.306991 LR 4.04e-05
	 Magnitude of data 1.372e+06 output 1.742e+05 target 1.372e+06
Train Epoch: 3 [72960/81276 (90%)]	Loss: 6.334082 LR 4.03e-05
	 Magnitude of data 1.268e+06 output 1.730e+05 target 1.268e+06
Train Epoch: 3 [73600/81276 (91%)]	Loss: 6.219256 LR 4.03e-05
	 Magnitude of data 1.248e+06 output 1.742e+05 target 1.248e+06
Train Epoch: 3 [74240/81276 (91%)]	Loss: 6.463184 LR 4.02e-05
	 Magnitude of data 1.344e+06 output 1.733e+05 target 1.344e+06
Train Epoch: 3 [74880/81276 (92%)]	Loss: 6.587905 LR 4.02e-05
	 Magnitude of data 1.405e+06 output 1.728e+05 target 1.405e+06
Train Epoch: 3 [75520/81276 (93%)]	Loss: 6.350892 LR 4.01e-05
	 Magnitude of data 1.326e+06 output 1.684e+05 target 1.326e+06
Train Epoch: 3 [76160/81276 (94%)]	Loss: 6.342537 LR 4.01e-05
	 Magnitude of data 1.291e+06 output 1.750e+05 target 1.291e+06
Train Epoch: 3 [76800/81276 (95%)]	Loss: 6.413624 LR 4.00e-05
	 Magnitude of data 1.338e+06 output 1.730e+05 target 1.338e+06
Train Epoch: 3 [77440/81276 (95%)]	Loss: 6.308958 LR 4.00e-05
	 Magnitude of data 1.279e+06 output 1.734e+05 target 1.279e+06
Train Epoch: 3 [78080/81276 (96%)]	Loss: 6.292926 LR 3.99e-05
	 Magnitude of data 1.287e+06 output 1.769e+05 target 1.287e+06
Train Epoch: 3 [78720/81276 (97%)]	Loss: 6.423817 LR 3.99e-05
	 Magnitude of data 1.253e+06 output 1.710e+05 target 1.253e+06
Train Epoch: 3 [79360/81276 (98%)]	Loss: 6.580358 LR 3.98e-05
	 Magnitude of data 1.327e+06 output 1.707e+05 target 1.327e+06
Train Epoch: 3 [80000/81276 (99%)]	Loss: 6.539603 LR 3.98e-05
	 Magnitude of data 1.478e+06 output 1.726e+05 target 1.478e+06
Train Epoch: 3 [80640/81276 (99%)]	Loss: 6.371012 LR 3.97e-05
	 Magnitude of data 1.218e+06 output 1.763e+05 target 1.218e+06
Train Epoch: 3 [81216/81276 (100%)]	Loss: 6.249016 LR 3.97e-05
Test set: Average loss: 6.38050840
Train Epoch: 4 [0/81276 (0%)]	Loss: 6.412244 LR 3.97e-05
	 Magnitude of data 1.348e+06 output 1.733e+05 target 1.348e+06
Train Epoch: 4 [640/81276 (1%)]	Loss: 6.376455 LR 3.96e-05
	 Magnitude of data 1.314e+06 output 1.745e+05 target 1.314e+06
Train Epoch: 4 [1280/81276 (2%)]	Loss: 6.565378 LR 3.96e-05
	 Magnitude of data 1.495e+06 output 1.732e+05 target 1.495e+06
Train Epoch: 4 [1920/81276 (2%)]	Loss: 6.343092 LR 3.95e-05
	 Magnitude of data 1.218e+06 output 1.772e+05 target 1.218e+06
Train Epoch: 4 [2560/81276 (3%)]	Loss: 6.166728 LR 3.95e-05
	 Magnitude of data 1.281e+06 output 1.764e+05 target 1.281e+06
Train Epoch: 4 [3200/81276 (4%)]	Loss: 6.157331 LR 3.94e-05
	 Magnitude of data 1.317e+06 output 1.761e+05 target 1.317e+06
Train Epoch: 4 [3840/81276 (5%)]	Loss: 6.229760 LR 3.94e-05
	 Magnitude of data 1.281e+06 output 1.751e+05 target 1.281e+06
Train Epoch: 4 [4480/81276 (6%)]	Loss: 6.240766 LR 3.93e-05
	 Magnitude of data 1.306e+06 output 1.745e+05 target 1.306e+06
Train Epoch: 4 [5120/81276 (6%)]	Loss: 6.294073 LR 3.93e-05
	 Magnitude of data 1.360e+06 output 1.760e+05 target 1.360e+06
Train Epoch: 4 [5760/81276 (7%)]	Loss: 6.384279 LR 3.92e-05
	 Magnitude of data 1.349e+06 output 1.771e+05 target 1.350e+06
Train Epoch: 4 [6400/81276 (8%)]	Loss: 6.535595 LR 3.92e-05
	 Magnitude of data 1.285e+06 output 1.698e+05 target 1.286e+06
Train Epoch: 4 [7040/81276 (9%)]	Loss: 6.361488 LR 3.91e-05
	 Magnitude of data 1.278e+06 output 1.763e+05 target 1.278e+06
Train Epoch: 4 [7680/81276 (9%)]	Loss: 6.596100 LR 3.91e-05
	 Magnitude of data 1.419e+06 output 1.706e+05 target 1.419e+06
Train Epoch: 4 [8320/81276 (10%)]	Loss: 6.471816 LR 3.90e-05
	 Magnitude of data 1.234e+06 output 1.721e+05 target 1.234e+06
Train Epoch: 4 [8960/81276 (11%)]	Loss: 6.524077 LR 3.90e-05
	 Magnitude of data 1.348e+06 output 1.729e+05 target 1.348e+06
Train Epoch: 4 [9600/81276 (12%)]	Loss: 6.322246 LR 3.89e-05
	 Magnitude of data 1.364e+06 output 1.721e+05 target 1.364e+06
Train Epoch: 4 [10240/81276 (13%)]	Loss: 6.296765 LR 3.89e-05
	 Magnitude of data 1.276e+06 output 1.742e+05 target 1.276e+06
Train Epoch: 4 [10880/81276 (13%)]	Loss: 6.256671 LR 3.88e-05
	 Magnitude of data 1.240e+06 output 1.776e+05 target 1.240e+06
Train Epoch: 4 [11520/81276 (14%)]	Loss: 6.364784 LR 3.88e-05
	 Magnitude of data 1.342e+06 output 1.736e+05 target 1.342e+06
Train Epoch: 4 [12160/81276 (15%)]	Loss: 6.331172 LR 3.87e-05
	 Magnitude of data 1.359e+06 output 1.719e+05 target 1.359e+06
Train Epoch: 4 [12800/81276 (16%)]	Loss: 6.404059 LR 3.87e-05
	 Magnitude of data 1.366e+06 output 1.731e+05 target 1.366e+06
Train Epoch: 4 [13440/81276 (17%)]	Loss: 6.165047 LR 3.86e-05
	 Magnitude of data 1.241e+06 output 1.758e+05 target 1.241e+06
Train Epoch: 4 [14080/81276 (17%)]	Loss: 6.407956 LR 3.86e-05
	 Magnitude of data 1.396e+06 output 1.769e+05 target 1.396e+06
Train Epoch: 4 [14720/81276 (18%)]	Loss: 6.516144 LR 3.85e-05
	 Magnitude of data 1.450e+06 output 1.732e+05 target 1.450e+06
Train Epoch: 4 [15360/81276 (19%)]	Loss: 6.612294 LR 3.85e-05
	 Magnitude of data 1.387e+06 output 1.733e+05 target 1.387e+06
Train Epoch: 4 [16000/81276 (20%)]	Loss: 6.373872 LR 3.84e-05
	 Magnitude of data 1.371e+06 output 1.762e+05 target 1.371e+06
Train Epoch: 4 [16640/81276 (20%)]	Loss: 6.238799 LR 3.84e-05
	 Magnitude of data 1.274e+06 output 1.783e+05 target 1.274e+06
Train Epoch: 4 [17280/81276 (21%)]	Loss: 6.607085 LR 3.83e-05
	 Magnitude of data 1.443e+06 output 1.730e+05 target 1.442e+06
Train Epoch: 4 [17920/81276 (22%)]	Loss: 6.356970 LR 3.83e-05
	 Magnitude of data 1.267e+06 output 1.751e+05 target 1.266e+06
Train Epoch: 4 [18560/81276 (23%)]	Loss: 6.173800 LR 3.82e-05
	 Magnitude of data 1.246e+06 output 1.760e+05 target 1.246e+06
Train Epoch: 4 [19200/81276 (24%)]	Loss: 6.219654 LR 3.81e-05
	 Magnitude of data 1.254e+06 output 1.733e+05 target 1.254e+06
Train Epoch: 4 [19840/81276 (24%)]	Loss: 6.358770 LR 3.81e-05
	 Magnitude of data 1.331e+06 output 1.743e+05 target 1.331e+06
Train Epoch: 4 [20480/81276 (25%)]	Loss: 6.301059 LR 3.80e-05
	 Magnitude of data 1.190e+06 output 1.787e+05 target 1.190e+06
Train Epoch: 4 [21120/81276 (26%)]	Loss: 6.361650 LR 3.80e-05
	 Magnitude of data 1.290e+06 output 1.724e+05 target 1.290e+06
Train Epoch: 4 [21760/81276 (27%)]	Loss: 6.367057 LR 3.79e-05
	 Magnitude of data 1.386e+06 output 1.765e+05 target 1.385e+06
Train Epoch: 4 [22400/81276 (28%)]	Loss: 6.215986 LR 3.79e-05
	 Magnitude of data 1.271e+06 output 1.739e+05 target 1.271e+06
Train Epoch: 4 [23040/81276 (28%)]	Loss: 6.537668 LR 3.78e-05
	 Magnitude of data 1.259e+06 output 1.759e+05 target 1.259e+06
Train Epoch: 4 [23680/81276 (29%)]	Loss: 6.259049 LR 3.78e-05
	 Magnitude of data 1.231e+06 output 1.780e+05 target 1.231e+06
Train Epoch: 4 [24320/81276 (30%)]	Loss: 6.425452 LR 3.77e-05
	 Magnitude of data 1.323e+06 output 1.783e+05 target 1.322e+06
Train Epoch: 4 [24960/81276 (31%)]	Loss: 6.112330 LR 3.77e-05
	 Magnitude of data 1.341e+06 output 1.762e+05 target 1.341e+06
Train Epoch: 4 [25600/81276 (32%)]	Loss: 6.253259 LR 3.76e-05
	 Magnitude of data 1.299e+06 output 1.765e+05 target 1.299e+06
Train Epoch: 4 [26240/81276 (32%)]	Loss: 6.397676 LR 3.76e-05
	 Magnitude of data 1.329e+06 output 1.747e+05 target 1.329e+06
Train Epoch: 4 [26880/81276 (33%)]	Loss: 6.080969 LR 3.75e-05
	 Magnitude of data 1.258e+06 output 1.761e+05 target 1.258e+06
Train Epoch: 4 [27520/81276 (34%)]	Loss: 6.369282 LR 3.75e-05
	 Magnitude of data 1.280e+06 output 1.797e+05 target 1.280e+06
Train Epoch: 4 [28160/81276 (35%)]	Loss: 6.330227 LR 3.74e-05
	 Magnitude of data 1.353e+06 output 1.720e+05 target 1.353e+06
Train Epoch: 4 [28800/81276 (35%)]	Loss: 6.117764 LR 3.73e-05
	 Magnitude of data 1.316e+06 output 1.787e+05 target 1.316e+06
Train Epoch: 4 [29440/81276 (36%)]	Loss: 6.347229 LR 3.73e-05
	 Magnitude of data 1.295e+06 output 1.746e+05 target 1.295e+06
Train Epoch: 4 [30080/81276 (37%)]	Loss: 6.287269 LR 3.72e-05
	 Magnitude of data 1.290e+06 output 1.766e+05 target 1.290e+06
Train Epoch: 4 [30720/81276 (38%)]	Loss: 6.237244 LR 3.72e-05
	 Magnitude of data 1.320e+06 output 1.765e+05 target 1.320e+06
Train Epoch: 4 [31360/81276 (39%)]	Loss: 6.256681 LR 3.71e-05
	 Magnitude of data 1.397e+06 output 1.727e+05 target 1.397e+06
Train Epoch: 4 [32000/81276 (39%)]	Loss: 6.293782 LR 3.71e-05
	 Magnitude of data 1.283e+06 output 1.761e+05 target 1.283e+06
Train Epoch: 4 [32640/81276 (40%)]	Loss: 6.596945 LR 3.70e-05
	 Magnitude of data 1.354e+06 output 1.728e+05 target 1.354e+06
Train Epoch: 4 [33280/81276 (41%)]	Loss: 6.398758 LR 3.70e-05
	 Magnitude of data 1.271e+06 output 1.758e+05 target 1.271e+06
Train Epoch: 4 [33920/81276 (42%)]	Loss: 6.362110 LR 3.69e-05
	 Magnitude of data 1.296e+06 output 1.786e+05 target 1.296e+06
Train Epoch: 4 [34560/81276 (43%)]	Loss: 6.388202 LR 3.69e-05
	 Magnitude of data 1.312e+06 output 1.769e+05 target 1.312e+06
Train Epoch: 4 [35200/81276 (43%)]	Loss: 6.742835 LR 3.68e-05
	 Magnitude of data 1.383e+06 output 1.777e+05 target 1.383e+06
Train Epoch: 4 [35840/81276 (44%)]	Loss: 6.329344 LR 3.68e-05
	 Magnitude of data 1.314e+06 output 1.755e+05 target 1.314e+06
Train Epoch: 4 [36480/81276 (45%)]	Loss: 6.387776 LR 3.67e-05
	 Magnitude of data 1.359e+06 output 1.766e+05 target 1.359e+06
Train Epoch: 4 [37120/81276 (46%)]	Loss: 5.998410 LR 3.66e-05
	 Magnitude of data 1.273e+06 output 1.764e+05 target 1.273e+06
Train Epoch: 4 [37760/81276 (46%)]	Loss: 6.169301 LR 3.66e-05
	 Magnitude of data 1.261e+06 output 1.778e+05 target 1.261e+06
Train Epoch: 4 [38400/81276 (47%)]	Loss: 6.106871 LR 3.65e-05
	 Magnitude of data 1.358e+06 output 1.772e+05 target 1.358e+06
Train Epoch: 4 [39040/81276 (48%)]	Loss: 6.325070 LR 3.65e-05
	 Magnitude of data 1.339e+06 output 1.787e+05 target 1.339e+06
Train Epoch: 4 [39680/81276 (49%)]	Loss: 6.087216 LR 3.64e-05
	 Magnitude of data 1.233e+06 output 1.779e+05 target 1.233e+06
Train Epoch: 4 [40320/81276 (50%)]	Loss: 6.329240 LR 3.64e-05
	 Magnitude of data 1.395e+06 output 1.727e+05 target 1.395e+06
Train Epoch: 4 [40960/81276 (50%)]	Loss: 6.233678 LR 3.63e-05
	 Magnitude of data 1.324e+06 output 1.775e+05 target 1.324e+06
Train Epoch: 4 [41600/81276 (51%)]	Loss: 6.304615 LR 3.63e-05
	 Magnitude of data 1.367e+06 output 1.763e+05 target 1.367e+06
Train Epoch: 4 [42240/81276 (52%)]	Loss: 6.265344 LR 3.62e-05
	 Magnitude of data 1.301e+06 output 1.760e+05 target 1.301e+06
Train Epoch: 4 [42880/81276 (53%)]	Loss: 6.057409 LR 3.61e-05
	 Magnitude of data 1.223e+06 output 1.783e+05 target 1.223e+06
Train Epoch: 4 [43520/81276 (54%)]	Loss: 6.224579 LR 3.61e-05
	 Magnitude of data 1.285e+06 output 1.760e+05 target 1.285e+06
Train Epoch: 4 [44160/81276 (54%)]	Loss: 6.186721 LR 3.60e-05
	 Magnitude of data 1.281e+06 output 1.776e+05 target 1.281e+06
Train Epoch: 4 [44800/81276 (55%)]	Loss: 6.263422 LR 3.60e-05
	 Magnitude of data 1.413e+06 output 1.790e+05 target 1.413e+06
Train Epoch: 4 [45440/81276 (56%)]	Loss: 6.333348 LR 3.59e-05
	 Magnitude of data 1.310e+06 output 1.785e+05 target 1.310e+06
Train Epoch: 4 [46080/81276 (57%)]	Loss: 6.391701 LR 3.59e-05
	 Magnitude of data 1.308e+06 output 1.772e+05 target 1.308e+06
Train Epoch: 4 [46720/81276 (58%)]	Loss: 6.412017 LR 3.58e-05
	 Magnitude of data 1.370e+06 output 1.779e+05 target 1.371e+06
Train Epoch: 4 [47360/81276 (58%)]	Loss: 6.104062 LR 3.58e-05
	 Magnitude of data 1.361e+06 output 1.759e+05 target 1.361e+06
Train Epoch: 4 [48000/81276 (59%)]	Loss: 6.369561 LR 3.57e-05
	 Magnitude of data 1.285e+06 output 1.745e+05 target 1.286e+06
Train Epoch: 4 [48640/81276 (60%)]	Loss: 6.079551 LR 3.56e-05
	 Magnitude of data 1.249e+06 output 1.797e+05 target 1.249e+06
Train Epoch: 4 [49280/81276 (61%)]	Loss: 6.155902 LR 3.56e-05
	 Magnitude of data 1.305e+06 output 1.738e+05 target 1.305e+06
Train Epoch: 4 [49920/81276 (61%)]	Loss: 6.259623 LR 3.55e-05
	 Magnitude of data 1.259e+06 output 1.797e+05 target 1.259e+06
Train Epoch: 4 [50560/81276 (62%)]	Loss: 6.261556 LR 3.55e-05
	 Magnitude of data 1.274e+06 output 1.785e+05 target 1.273e+06
Train Epoch: 4 [51200/81276 (63%)]	Loss: 6.071769 LR 3.54e-05
	 Magnitude of data 1.319e+06 output 1.762e+05 target 1.319e+06
Train Epoch: 4 [51840/81276 (64%)]	Loss: 6.311924 LR 3.54e-05
	 Magnitude of data 1.351e+06 output 1.811e+05 target 1.351e+06
Train Epoch: 4 [52480/81276 (65%)]	Loss: 6.051996 LR 3.53e-05
	 Magnitude of data 1.318e+06 output 1.781e+05 target 1.318e+06
Train Epoch: 4 [53120/81276 (65%)]	Loss: 6.048464 LR 3.53e-05
	 Magnitude of data 1.274e+06 output 1.793e+05 target 1.274e+06
Train Epoch: 4 [53760/81276 (66%)]	Loss: 6.334754 LR 3.52e-05
	 Magnitude of data 1.363e+06 output 1.755e+05 target 1.363e+06
Train Epoch: 4 [54400/81276 (67%)]	Loss: 6.199175 LR 3.51e-05
	 Magnitude of data 1.305e+06 output 1.760e+05 target 1.305e+06
Train Epoch: 4 [55040/81276 (68%)]	Loss: 6.235974 LR 3.51e-05
	 Magnitude of data 1.319e+06 output 1.802e+05 target 1.318e+06
Train Epoch: 4 [55680/81276 (69%)]	Loss: 6.327556 LR 3.50e-05
	 Magnitude of data 1.197e+06 output 1.786e+05 target 1.197e+06
Train Epoch: 4 [56320/81276 (69%)]	Loss: 6.223614 LR 3.50e-05
	 Magnitude of data 1.373e+06 output 1.714e+05 target 1.373e+06
Train Epoch: 4 [56960/81276 (70%)]	Loss: 6.292342 LR 3.49e-05
	 Magnitude of data 1.323e+06 output 1.772e+05 target 1.323e+06
Train Epoch: 4 [57600/81276 (71%)]	Loss: 6.137163 LR 3.49e-05
	 Magnitude of data 1.223e+06 output 1.784e+05 target 1.223e+06
Train Epoch: 4 [58240/81276 (72%)]	Loss: 6.475890 LR 3.48e-05
	 Magnitude of data 1.344e+06 output 1.760e+05 target 1.344e+06
Train Epoch: 4 [58880/81276 (72%)]	Loss: 6.399030 LR 3.47e-05
	 Magnitude of data 1.282e+06 output 1.738e+05 target 1.282e+06
Train Epoch: 4 [59520/81276 (73%)]	Loss: 6.025454 LR 3.47e-05
	 Magnitude of data 1.214e+06 output 1.761e+05 target 1.214e+06
Train Epoch: 4 [60160/81276 (74%)]	Loss: 6.250571 LR 3.46e-05
	 Magnitude of data 1.322e+06 output 1.792e+05 target 1.323e+06
Train Epoch: 4 [60800/81276 (75%)]	Loss: 6.211436 LR 3.46e-05
	 Magnitude of data 1.290e+06 output 1.777e+05 target 1.290e+06
Train Epoch: 4 [61440/81276 (76%)]	Loss: 6.193822 LR 3.45e-05
	 Magnitude of data 1.354e+06 output 1.776e+05 target 1.354e+06
Train Epoch: 4 [62080/81276 (76%)]	Loss: 6.132088 LR 3.45e-05
	 Magnitude of data 1.348e+06 output 1.789e+05 target 1.348e+06
Train Epoch: 4 [62720/81276 (77%)]	Loss: 6.198828 LR 3.44e-05
	 Magnitude of data 1.358e+06 output 1.784e+05 target 1.358e+06
Train Epoch: 4 [63360/81276 (78%)]	Loss: 6.332761 LR 3.43e-05
	 Magnitude of data 1.367e+06 output 1.744e+05 target 1.367e+06
Train Epoch: 4 [64000/81276 (79%)]	Loss: 6.177399 LR 3.43e-05
	 Magnitude of data 1.341e+06 output 1.764e+05 target 1.341e+06
Train Epoch: 4 [64640/81276 (80%)]	Loss: 6.211694 LR 3.42e-05
	 Magnitude of data 1.274e+06 output 1.830e+05 target 1.274e+06
Train Epoch: 4 [65280/81276 (80%)]	Loss: 6.226581 LR 3.42e-05
	 Magnitude of data 1.638e+06 output 1.759e+05 target 1.638e+06
Train Epoch: 4 [65920/81276 (81%)]	Loss: 6.071725 LR 3.41e-05
	 Magnitude of data 1.178e+06 output 1.831e+05 target 1.178e+06
Train Epoch: 4 [66560/81276 (82%)]	Loss: 6.366628 LR 3.41e-05
	 Magnitude of data 1.313e+06 output 1.766e+05 target 1.313e+06
Train Epoch: 4 [67200/81276 (83%)]	Loss: 6.170298 LR 3.40e-05
	 Magnitude of data 1.305e+06 output 1.774e+05 target 1.305e+06
Train Epoch: 4 [67840/81276 (84%)]	Loss: 5.992985 LR 3.39e-05
	 Magnitude of data 1.243e+06 output 1.775e+05 target 1.243e+06
Train Epoch: 4 [68480/81276 (84%)]	Loss: 6.254150 LR 3.39e-05
	 Magnitude of data 1.389e+06 output 1.806e+05 target 1.389e+06
Train Epoch: 4 [69120/81276 (85%)]	Loss: 6.240761 LR 3.38e-05
	 Magnitude of data 1.368e+06 output 1.782e+05 target 1.368e+06
Train Epoch: 4 [69760/81276 (86%)]	Loss: 6.317186 LR 3.38e-05
	 Magnitude of data 1.272e+06 output 1.845e+05 target 1.272e+06
Train Epoch: 4 [70400/81276 (87%)]	Loss: 6.332893 LR 3.37e-05
	 Magnitude of data 1.307e+06 output 1.767e+05 target 1.307e+06
Train Epoch: 4 [71040/81276 (87%)]	Loss: 6.449866 LR 3.36e-05
	 Magnitude of data 1.298e+06 output 1.800e+05 target 1.298e+06
Train Epoch: 4 [71680/81276 (88%)]	Loss: 6.257999 LR 3.36e-05
	 Magnitude of data 1.285e+06 output 1.780e+05 target 1.285e+06
Train Epoch: 4 [72320/81276 (89%)]	Loss: 6.160357 LR 3.35e-05
	 Magnitude of data 1.372e+06 output 1.784e+05 target 1.372e+06
Train Epoch: 4 [72960/81276 (90%)]	Loss: 6.204750 LR 3.35e-05
	 Magnitude of data 1.268e+06 output 1.761e+05 target 1.268e+06
Train Epoch: 4 [73600/81276 (91%)]	Loss: 6.077620 LR 3.34e-05
	 Magnitude of data 1.248e+06 output 1.798e+05 target 1.248e+06
Train Epoch: 4 [74240/81276 (91%)]	Loss: 6.327361 LR 3.34e-05
	 Magnitude of data 1.344e+06 output 1.770e+05 target 1.344e+06
Train Epoch: 4 [74880/81276 (92%)]	Loss: 6.459691 LR 3.33e-05
	 Magnitude of data 1.405e+06 output 1.782e+05 target 1.405e+06
Train Epoch: 4 [75520/81276 (93%)]	Loss: 6.206865 LR 3.32e-05
	 Magnitude of data 1.326e+06 output 1.732e+05 target 1.326e+06
Train Epoch: 4 [76160/81276 (94%)]	Loss: 6.215901 LR 3.32e-05
	 Magnitude of data 1.291e+06 output 1.789e+05 target 1.291e+06
Train Epoch: 4 [76800/81276 (95%)]	Loss: 6.285749 LR 3.31e-05
	 Magnitude of data 1.338e+06 output 1.770e+05 target 1.338e+06
Train Epoch: 4 [77440/81276 (95%)]	Loss: 6.169846 LR 3.31e-05
	 Magnitude of data 1.279e+06 output 1.772e+05 target 1.279e+06
Train Epoch: 4 [78080/81276 (96%)]	Loss: 6.160636 LR 3.30e-05
	 Magnitude of data 1.287e+06 output 1.816e+05 target 1.287e+06
Train Epoch: 4 [78720/81276 (97%)]	Loss: 6.291895 LR 3.29e-05
	 Magnitude of data 1.253e+06 output 1.756e+05 target 1.253e+06
Train Epoch: 4 [79360/81276 (98%)]	Loss: 6.450920 LR 3.29e-05
	 Magnitude of data 1.327e+06 output 1.751e+05 target 1.327e+06
Train Epoch: 4 [80000/81276 (99%)]	Loss: 6.398672 LR 3.28e-05
	 Magnitude of data 1.478e+06 output 1.772e+05 target 1.478e+06
Train Epoch: 4 [80640/81276 (99%)]	Loss: 6.245533 LR 3.28e-05
	 Magnitude of data 1.218e+06 output 1.806e+05 target 1.218e+06
Train Epoch: 4 [81216/81276 (100%)]	Loss: 6.100282 LR 3.27e-05
Test set: Average loss: 6.25309242

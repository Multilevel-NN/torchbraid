Using GPU Device
Run info rank: 0: Torch version: 2.1.2+cu121 | Device: cuda:0 | Host: cpu
Loading dataset; args.percent_data=0.2
Loaded tensor from ../data/wikipedia.data
1.4 Splitting data into training and validation data
len(train_data)=104035585, len(val_data)=11559510 percent_data=0.2
len(train_data)=20807117, len(val_data)=2311902
-- procs    = 1
-- Tf       = 1.0
-- steps    = 64
-- max_levels     = 1
-- max_bwd_iters  = 1
-- max_fwd_iters  = 3
-- cfactor        = 4
-- fine fcf       = False
-- skip down      = True

args.model_dimension=384 args.num_heads=6 args.batch_size=64
rank 0: len(list(model.parameters())) 1798
rank 0: 152238673
Train Epoch: 1 [0/81276 (0%)]	Loss: 11.001037 LR 6.00e-07
	 Magnitude of data 1.348e+06 output 1.660e+04 target 1.348e+06
Train Epoch: 1 [640/81276 (1%)]	Loss: 11.009785 LR 6.60e-06
	 Magnitude of data 1.314e+06 output 1.658e+04 target 1.314e+06
Train Epoch: 1 [1280/81276 (2%)]	Loss: 10.986897 LR 1.26e-05
	 Magnitude of data 1.495e+06 output 1.654e+04 target 1.495e+06
Train Epoch: 1 [1920/81276 (2%)]	Loss: 10.976315 LR 1.86e-05
	 Magnitude of data 1.218e+06 output 1.646e+04 target 1.218e+06
Train Epoch: 1 [2560/81276 (3%)]	Loss: 10.976267 LR 2.46e-05
	 Magnitude of data 1.281e+06 output 1.636e+04 target 1.281e+06
Train Epoch: 1 [3200/81276 (4%)]	Loss: 10.979126 LR 3.06e-05
	 Magnitude of data 1.317e+06 output 1.623e+04 target 1.317e+06
Train Epoch: 1 [3840/81276 (5%)]	Loss: 10.965816 LR 3.66e-05
	 Magnitude of data 1.281e+06 output 1.607e+04 target 1.281e+06
Train Epoch: 1 [4480/81276 (6%)]	Loss: 10.952092 LR 4.26e-05
	 Magnitude of data 1.306e+06 output 1.588e+04 target 1.306e+06
Train Epoch: 1 [5120/81276 (6%)]	Loss: 10.962046 LR 4.86e-05
	 Magnitude of data 1.360e+06 output 1.566e+04 target 1.360e+06
Train Epoch: 1 [5760/81276 (7%)]	Loss: 10.943570 LR 5.46e-05
	 Magnitude of data 1.349e+06 output 1.542e+04 target 1.350e+06
Train Epoch: 1 [6400/81276 (8%)]	Loss: 10.927478 LR 6.06e-05
	 Magnitude of data 1.285e+06 output 1.515e+04 target 1.286e+06
Train Epoch: 1 [7040/81276 (9%)]	Loss: 10.922976 LR 6.66e-05
	 Magnitude of data 1.278e+06 output 1.485e+04 target 1.278e+06
Train Epoch: 1 [7680/81276 (9%)]	Loss: 10.897355 LR 7.26e-05
	 Magnitude of data 1.419e+06 output 1.454e+04 target 1.419e+06
Train Epoch: 1 [8320/81276 (10%)]	Loss: 10.892459 LR 7.86e-05
	 Magnitude of data 1.234e+06 output 1.420e+04 target 1.234e+06
Train Epoch: 1 [8960/81276 (11%)]	Loss: 10.874632 LR 8.46e-05
	 Magnitude of data 1.348e+06 output 1.384e+04 target 1.348e+06
Train Epoch: 1 [9600/81276 (12%)]	Loss: 10.858024 LR 9.06e-05
	 Magnitude of data 1.364e+06 output 1.346e+04 target 1.364e+06
Train Epoch: 1 [10240/81276 (13%)]	Loss: 10.829244 LR 9.66e-05
	 Magnitude of data 1.276e+06 output 1.306e+04 target 1.276e+06
Train Epoch: 1 [10880/81276 (13%)]	Loss: 10.828484 LR 1.03e-04
	 Magnitude of data 1.240e+06 output 1.264e+04 target 1.240e+06
Train Epoch: 1 [11520/81276 (14%)]	Loss: 10.800307 LR 1.09e-04
	 Magnitude of data 1.342e+06 output 1.221e+04 target 1.342e+06
Train Epoch: 1 [12160/81276 (15%)]	Loss: 10.800478 LR 1.15e-04
	 Magnitude of data 1.359e+06 output 1.176e+04 target 1.359e+06
Train Epoch: 1 [12800/81276 (16%)]	Loss: 10.744129 LR 1.21e-04
	 Magnitude of data 1.366e+06 output 1.130e+04 target 1.366e+06
Train Epoch: 1 [13440/81276 (17%)]	Loss: 10.734391 LR 1.27e-04
	 Magnitude of data 1.241e+06 output 1.083e+04 target 1.241e+06
Train Epoch: 1 [14080/81276 (17%)]	Loss: 10.719276 LR 1.33e-04
	 Magnitude of data 1.396e+06 output 1.035e+04 target 1.396e+06
Train Epoch: 1 [14720/81276 (18%)]	Loss: 10.705218 LR 1.38e-04
	 Magnitude of data 1.450e+06 output 9.852e+03 target 1.450e+06
Train Epoch: 1 [15360/81276 (19%)]	Loss: 10.696748 LR 1.44e-04
	 Magnitude of data 1.387e+06 output 9.353e+03 target 1.387e+06
Train Epoch: 1 [16000/81276 (20%)]	Loss: 10.663296 LR 1.50e-04
	 Magnitude of data 1.371e+06 output 8.848e+03 target 1.371e+06
Train Epoch: 1 [16640/81276 (20%)]	Loss: 10.644563 LR 1.56e-04
	 Magnitude of data 1.274e+06 output 8.337e+03 target 1.274e+06
Train Epoch: 1 [17280/81276 (21%)]	Loss: 10.623212 LR 1.62e-04
	 Magnitude of data 1.443e+06 output 7.825e+03 target 1.442e+06
Train Epoch: 1 [17920/81276 (22%)]	Loss: 10.588928 LR 1.68e-04
	 Magnitude of data 1.267e+06 output 7.314e+03 target 1.266e+06
Train Epoch: 1 [18560/81276 (23%)]	Loss: 10.528165 LR 1.74e-04
	 Magnitude of data 1.246e+06 output 6.803e+03 target 1.246e+06
Train Epoch: 1 [19200/81276 (24%)]	Loss: 10.535610 LR 1.80e-04
	 Magnitude of data 1.254e+06 output 6.296e+03 target 1.254e+06
Train Epoch: 1 [19840/81276 (24%)]	Loss: 10.517177 LR 1.86e-04
	 Magnitude of data 1.331e+06 output 5.795e+03 target 1.331e+06
Train Epoch: 1 [20480/81276 (25%)]	Loss: 10.486961 LR 1.92e-04
	 Magnitude of data 1.190e+06 output 5.301e+03 target 1.190e+06
Train Epoch: 1 [21120/81276 (26%)]	Loss: 10.464493 LR 1.98e-04
	 Magnitude of data 1.290e+06 output 4.817e+03 target 1.290e+06
Train Epoch: 1 [21760/81276 (27%)]	Loss: 10.459992 LR 2.04e-04
	 Magnitude of data 1.386e+06 output 4.346e+03 target 1.385e+06
Train Epoch: 1 [22400/81276 (28%)]	Loss: 10.404846 LR 2.10e-04
	 Magnitude of data 1.271e+06 output 3.890e+03 target 1.271e+06
Train Epoch: 1 [23040/81276 (28%)]	Loss: 10.420540 LR 2.16e-04
	 Magnitude of data 1.259e+06 output 3.450e+03 target 1.259e+06
Train Epoch: 1 [23680/81276 (29%)]	Loss: 10.377642 LR 2.22e-04
	 Magnitude of data 1.231e+06 output 3.032e+03 target 1.231e+06
Train Epoch: 1 [24320/81276 (30%)]	Loss: 10.389224 LR 2.28e-04
	 Magnitude of data 1.323e+06 output 2.637e+03 target 1.322e+06
Train Epoch: 1 [24960/81276 (31%)]	Loss: 10.244206 LR 2.34e-04
	 Magnitude of data 1.341e+06 output 2.264e+03 target 1.341e+06
Train Epoch: 1 [25600/81276 (32%)]	Loss: 10.305932 LR 2.40e-04
	 Magnitude of data 1.299e+06 output 1.926e+03 target 1.299e+06
Train Epoch: 1 [26240/81276 (32%)]	Loss: 10.306967 LR 2.46e-04
	 Magnitude of data 1.329e+06 output 1.619e+03 target 1.329e+06
Train Epoch: 1 [26880/81276 (33%)]	Loss: 10.269332 LR 2.52e-04
	 Magnitude of data 1.258e+06 output 1.348e+03 target 1.258e+06
Train Epoch: 1 [27520/81276 (34%)]	Loss: 10.251020 LR 2.58e-04
	 Magnitude of data 1.280e+06 output 1.118e+03 target 1.280e+06
Train Epoch: 1 [28160/81276 (35%)]	Loss: 10.217192 LR 2.64e-04
	 Magnitude of data 1.353e+06 output 9.430e+02 target 1.353e+06
Train Epoch: 1 [28800/81276 (35%)]	Loss: 10.266344 LR 2.70e-04
	 Magnitude of data 1.316e+06 output 7.917e+02 target 1.316e+06
Train Epoch: 1 [29440/81276 (36%)]	Loss: 10.221718 LR 2.76e-04
	 Magnitude of data 1.295e+06 output 7.097e+02 target 1.295e+06
Train Epoch: 1 [30080/81276 (37%)]	Loss: 10.161969 LR 2.82e-04
	 Magnitude of data 1.290e+06 output 6.586e+02 target 1.290e+06
Train Epoch: 1 [30720/81276 (38%)]	Loss: 10.153009 LR 2.88e-04
	 Magnitude of data 1.320e+06 output 6.472e+02 target 1.320e+06
Train Epoch: 1 [31360/81276 (39%)]	Loss: 10.046467 LR 2.94e-04
	 Magnitude of data 1.397e+06 output 6.693e+02 target 1.397e+06
Train Epoch: 1 [32000/81276 (39%)]	Loss: 10.113692 LR 2.99e-04
	 Magnitude of data 1.283e+06 output 6.710e+02 target 1.283e+06
Train Epoch: 1 [32640/81276 (40%)]	Loss: 10.037689 LR 2.99e-04
	 Magnitude of data 1.354e+06 output 7.012e+02 target 1.354e+06
Train Epoch: 1 [33280/81276 (41%)]	Loss: 10.094398 LR 2.99e-04
	 Magnitude of data 1.271e+06 output 6.891e+02 target 1.271e+06
Train Epoch: 1 [33920/81276 (42%)]	Loss: 10.064110 LR 2.99e-04
	 Magnitude of data 1.296e+06 output 7.261e+02 target 1.296e+06
Train Epoch: 1 [34560/81276 (43%)]	Loss: 10.053273 LR 2.99e-04
	 Magnitude of data 1.312e+06 output 7.341e+02 target 1.312e+06
Train Epoch: 1 [35200/81276 (43%)]	Loss: 10.100883 LR 2.99e-04
	 Magnitude of data 1.383e+06 output 7.368e+02 target 1.383e+06
Train Epoch: 1 [35840/81276 (44%)]	Loss: 9.981919 LR 2.99e-04
	 Magnitude of data 1.314e+06 output 7.690e+02 target 1.314e+06
Train Epoch: 1 [36480/81276 (45%)]	Loss: 10.038406 LR 2.99e-04
	 Magnitude of data 1.359e+06 output 7.951e+02 target 1.359e+06
Train Epoch: 1 [37120/81276 (46%)]	Loss: 9.921707 LR 2.98e-04
	 Magnitude of data 1.273e+06 output 7.972e+02 target 1.273e+06
Train Epoch: 1 [37760/81276 (46%)]	Loss: 9.948433 LR 2.98e-04
	 Magnitude of data 1.261e+06 output 8.279e+02 target 1.261e+06
Train Epoch: 1 [38400/81276 (47%)]	Loss: 9.942468 LR 2.98e-04
	 Magnitude of data 1.358e+06 output 8.279e+02 target 1.358e+06
Train Epoch: 1 [39040/81276 (48%)]	Loss: 9.938878 LR 2.98e-04
	 Magnitude of data 1.339e+06 output 8.563e+02 target 1.339e+06
Train Epoch: 1 [39680/81276 (49%)]	Loss: 9.753169 LR 2.98e-04
	 Magnitude of data 1.233e+06 output 8.827e+02 target 1.233e+06
Train Epoch: 1 [40320/81276 (50%)]	Loss: 9.849951 LR 2.98e-04
	 Magnitude of data 1.395e+06 output 8.794e+02 target 1.395e+06
Train Epoch: 1 [40960/81276 (50%)]	Loss: 9.861244 LR 2.98e-04
	 Magnitude of data 1.324e+06 output 9.202e+02 target 1.324e+06
Train Epoch: 1 [41600/81276 (51%)]	Loss: 9.824983 LR 2.98e-04
	 Magnitude of data 1.367e+06 output 9.242e+02 target 1.367e+06
Train Epoch: 1 [42240/81276 (52%)]	Loss: 9.874044 LR 2.98e-04
	 Magnitude of data 1.301e+06 output 9.365e+02 target 1.301e+06
Train Epoch: 1 [42880/81276 (53%)]	Loss: 9.771461 LR 2.98e-04
	 Magnitude of data 1.223e+06 output 9.519e+02 target 1.223e+06
Train Epoch: 1 [43520/81276 (54%)]	Loss: 9.771355 LR 2.98e-04
	 Magnitude of data 1.285e+06 output 9.608e+02 target 1.285e+06
Train Epoch: 1 [44160/81276 (54%)]	Loss: 9.859571 LR 2.98e-04
	 Magnitude of data 1.281e+06 output 9.765e+02 target 1.281e+06
Train Epoch: 1 [44800/81276 (55%)]	Loss: 9.815419 LR 2.98e-04
	 Magnitude of data 1.413e+06 output 9.711e+02 target 1.413e+06
Train Epoch: 1 [45440/81276 (56%)]	Loss: 9.838673 LR 2.98e-04
	 Magnitude of data 1.310e+06 output 9.986e+02 target 1.310e+06
Train Epoch: 1 [46080/81276 (57%)]	Loss: 9.840847 LR 2.98e-04
	 Magnitude of data 1.308e+06 output 1.015e+03 target 1.308e+06
Train Epoch: 1 [46720/81276 (58%)]	Loss: 9.829112 LR 2.98e-04
	 Magnitude of data 1.370e+06 output 1.025e+03 target 1.371e+06
Train Epoch: 1 [47360/81276 (58%)]	Loss: 9.753019 LR 2.97e-04
	 Magnitude of data 1.361e+06 output 1.037e+03 target 1.361e+06
Train Epoch: 1 [48000/81276 (59%)]	Loss: 9.785112 LR 2.97e-04
	 Magnitude of data 1.285e+06 output 1.049e+03 target 1.286e+06
Train Epoch: 1 [48640/81276 (60%)]	Loss: 9.770635 LR 2.97e-04
	 Magnitude of data 1.249e+06 output 1.056e+03 target 1.249e+06
Train Epoch: 1 [49280/81276 (61%)]	Loss: 9.722301 LR 2.97e-04
	 Magnitude of data 1.305e+06 output 1.074e+03 target 1.305e+06
Train Epoch: 1 [49920/81276 (61%)]	Loss: 9.832065 LR 2.97e-04
	 Magnitude of data 1.259e+06 output 1.085e+03 target 1.259e+06
Train Epoch: 1 [50560/81276 (62%)]	Loss: 9.790834 LR 2.97e-04
	 Magnitude of data 1.274e+06 output 1.099e+03 target 1.273e+06
Train Epoch: 1 [51200/81276 (63%)]	Loss: 9.760202 LR 2.97e-04
	 Magnitude of data 1.319e+06 output 1.096e+03 target 1.319e+06
Train Epoch: 1 [51840/81276 (64%)]	Loss: 9.713017 LR 2.97e-04
	 Magnitude of data 1.351e+06 output 1.113e+03 target 1.351e+06
Train Epoch: 1 [52480/81276 (65%)]	Loss: 9.744592 LR 2.97e-04
	 Magnitude of data 1.318e+06 output 1.115e+03 target 1.318e+06
Train Epoch: 1 [53120/81276 (65%)]	Loss: 9.686730 LR 2.97e-04
	 Magnitude of data 1.274e+06 output 1.126e+03 target 1.274e+06
Train Epoch: 1 [53760/81276 (66%)]	Loss: 9.814179 LR 2.97e-04
	 Magnitude of data 1.363e+06 output 1.128e+03 target 1.363e+06
Train Epoch: 1 [54400/81276 (67%)]	Loss: 9.701568 LR 2.97e-04
	 Magnitude of data 1.305e+06 output 1.139e+03 target 1.305e+06
Train Epoch: 1 [55040/81276 (68%)]	Loss: 9.678449 LR 2.97e-04
	 Magnitude of data 1.319e+06 output 1.118e+03 target 1.318e+06
Train Epoch: 1 [55680/81276 (69%)]	Loss: 9.750702 LR 2.97e-04
	 Magnitude of data 1.197e+06 output 1.146e+03 target 1.197e+06
Train Epoch: 1 [56320/81276 (69%)]	Loss: 9.786210 LR 2.96e-04
	 Magnitude of data 1.373e+06 output 1.137e+03 target 1.373e+06
Train Epoch: 1 [56960/81276 (70%)]	Loss: 9.707522 LR 2.96e-04
	 Magnitude of data 1.323e+06 output 1.153e+03 target 1.323e+06
Train Epoch: 1 [57600/81276 (71%)]	Loss: 9.662727 LR 2.96e-04
	 Magnitude of data 1.223e+06 output 1.170e+03 target 1.223e+06
Train Epoch: 1 [58240/81276 (72%)]	Loss: 9.736353 LR 2.96e-04
	 Magnitude of data 1.344e+06 output 1.177e+03 target 1.344e+06
Train Epoch: 1 [58880/81276 (72%)]	Loss: 9.722019 LR 2.96e-04
	 Magnitude of data 1.282e+06 output 1.196e+03 target 1.282e+06
Train Epoch: 1 [59520/81276 (73%)]	Loss: 9.588763 LR 2.96e-04
	 Magnitude of data 1.214e+06 output 1.181e+03 target 1.214e+06
Train Epoch: 1 [60160/81276 (74%)]	Loss: 9.736371 LR 2.96e-04
	 Magnitude of data 1.322e+06 output 1.181e+03 target 1.323e+06
Train Epoch: 1 [60800/81276 (75%)]	Loss: 9.667764 LR 2.96e-04
	 Magnitude of data 1.290e+06 output 1.211e+03 target 1.290e+06
Train Epoch: 1 [61440/81276 (76%)]	Loss: 9.736705 LR 2.96e-04
	 Magnitude of data 1.354e+06 output 1.206e+03 target 1.354e+06
Train Epoch: 1 [62080/81276 (76%)]	Loss: 9.600975 LR 2.96e-04
	 Magnitude of data 1.348e+06 output 1.201e+03 target 1.348e+06
Train Epoch: 1 [62720/81276 (77%)]	Loss: 9.660353 LR 2.96e-04
	 Magnitude of data 1.358e+06 output 1.227e+03 target 1.358e+06
Train Epoch: 1 [63360/81276 (78%)]	Loss: 9.614470 LR 2.96e-04
	 Magnitude of data 1.367e+06 output 1.213e+03 target 1.367e+06
Train Epoch: 1 [64000/81276 (79%)]	Loss: 9.700813 LR 2.95e-04
	 Magnitude of data 1.341e+06 output 1.205e+03 target 1.341e+06
Train Epoch: 1 [64640/81276 (80%)]	Loss: 9.707563 LR 2.95e-04
	 Magnitude of data 1.274e+06 output 1.215e+03 target 1.274e+06
Train Epoch: 1 [65280/81276 (80%)]	Loss: 9.715969 LR 2.95e-04
	 Magnitude of data 1.638e+06 output 1.198e+03 target 1.638e+06
Train Epoch: 1 [65920/81276 (81%)]	Loss: 9.601300 LR 2.95e-04
	 Magnitude of data 1.178e+06 output 1.220e+03 target 1.178e+06
Train Epoch: 1 [66560/81276 (82%)]	Loss: 9.720813 LR 2.95e-04
	 Magnitude of data 1.313e+06 output 1.210e+03 target 1.313e+06
Train Epoch: 1 [67200/81276 (83%)]	Loss: 9.664508 LR 2.95e-04
	 Magnitude of data 1.305e+06 output 1.218e+03 target 1.305e+06
Train Epoch: 1 [67840/81276 (84%)]	Loss: 9.634558 LR 2.95e-04
	 Magnitude of data 1.243e+06 output 1.210e+03 target 1.243e+06
Train Epoch: 1 [68480/81276 (84%)]	Loss: 9.754306 LR 2.95e-04
	 Magnitude of data 1.389e+06 output 1.198e+03 target 1.389e+06
Train Epoch: 1 [69120/81276 (85%)]	Loss: 9.688003 LR 2.95e-04
	 Magnitude of data 1.368e+06 output 1.217e+03 target 1.368e+06
Train Epoch: 1 [69760/81276 (86%)]	Loss: 9.724274 LR 2.95e-04
	 Magnitude of data 1.272e+06 output 1.223e+03 target 1.272e+06
Train Epoch: 1 [70400/81276 (87%)]	Loss: 9.667950 LR 2.94e-04
	 Magnitude of data 1.307e+06 output 1.225e+03 target 1.307e+06
Train Epoch: 1 [71040/81276 (87%)]	Loss: 9.777876 LR 2.94e-04
	 Magnitude of data 1.298e+06 output 1.204e+03 target 1.298e+06
Train Epoch: 1 [71680/81276 (88%)]	Loss: 9.771397 LR 2.94e-04
	 Magnitude of data 1.285e+06 output 1.220e+03 target 1.285e+06
Train Epoch: 1 [72320/81276 (89%)]	Loss: 9.717569 LR 2.94e-04
	 Magnitude of data 1.372e+06 output 1.214e+03 target 1.372e+06
Train Epoch: 1 [72960/81276 (90%)]	Loss: 9.713075 LR 2.94e-04
	 Magnitude of data 1.268e+06 output 1.210e+03 target 1.268e+06
Train Epoch: 1 [73600/81276 (91%)]	Loss: 9.700651 LR 2.94e-04
	 Magnitude of data 1.248e+06 output 1.207e+03 target 1.248e+06
Train Epoch: 1 [74240/81276 (91%)]	Loss: 9.791484 LR 2.94e-04
	 Magnitude of data 1.344e+06 output 1.203e+03 target 1.344e+06
Train Epoch: 1 [74880/81276 (92%)]	Loss: 9.805196 LR 2.94e-04
	 Magnitude of data 1.405e+06 output 1.208e+03 target 1.405e+06
Train Epoch: 1 [75520/81276 (93%)]	Loss: 9.695243 LR 2.94e-04
	 Magnitude of data 1.326e+06 output 1.216e+03 target 1.326e+06
Train Epoch: 1 [76160/81276 (94%)]	Loss: 9.680762 LR 2.94e-04
	 Magnitude of data 1.291e+06 output 1.212e+03 target 1.291e+06
Train Epoch: 1 [76800/81276 (95%)]	Loss: 9.684088 LR 2.93e-04
	 Magnitude of data 1.338e+06 output 1.198e+03 target 1.338e+06
Train Epoch: 1 [77440/81276 (95%)]	Loss: 9.746220 LR 2.93e-04
	 Magnitude of data 1.279e+06 output 1.185e+03 target 1.279e+06
Train Epoch: 1 [78080/81276 (96%)]	Loss: 9.721887 LR 2.93e-04
	 Magnitude of data 1.287e+06 output 1.190e+03 target 1.287e+06
Train Epoch: 1 [78720/81276 (97%)]	Loss: 9.683990 LR 2.93e-04
	 Magnitude of data 1.253e+06 output 1.195e+03 target 1.253e+06
Train Epoch: 1 [79360/81276 (98%)]	Loss: 9.779396 LR 2.93e-04
	 Magnitude of data 1.327e+06 output 1.182e+03 target 1.327e+06
Train Epoch: 1 [80000/81276 (99%)]	Loss: 9.779530 LR 2.93e-04
	 Magnitude of data 1.478e+06 output 1.171e+03 target 1.478e+06
Train Epoch: 1 [80640/81276 (99%)]	Loss: 9.804163 LR 2.93e-04
	 Magnitude of data 1.218e+06 output 1.185e+03 target 1.218e+06
Train Epoch: 1 [81216/81276 (100%)]	Loss: 9.675432 LR 2.93e-04
Test set: Average loss: 9.74319785
Train Epoch: 2 [0/81276 (0%)]	Loss: 9.729366 LR 2.93e-04
	 Magnitude of data 1.348e+06 output 1.185e+03 target 1.348e+06
Train Epoch: 2 [640/81276 (1%)]	Loss: 9.749332 LR 2.93e-04
	 Magnitude of data 1.314e+06 output 1.195e+03 target 1.314e+06
Train Epoch: 2 [1280/81276 (2%)]	Loss: 9.771557 LR 2.92e-04
	 Magnitude of data 1.495e+06 output 1.191e+03 target 1.495e+06
Train Epoch: 2 [1920/81276 (2%)]	Loss: 9.706458 LR 2.92e-04
	 Magnitude of data 1.218e+06 output 1.188e+03 target 1.218e+06
Train Epoch: 2 [2560/81276 (3%)]	Loss: 9.723559 LR 2.92e-04
	 Magnitude of data 1.281e+06 output 1.199e+03 target 1.281e+06
Train Epoch: 2 [3200/81276 (4%)]	Loss: 9.741793 LR 2.92e-04
	 Magnitude of data 1.317e+06 output 1.202e+03 target 1.317e+06
Train Epoch: 2 [3840/81276 (5%)]	Loss: 9.751646 LR 2.92e-04
	 Magnitude of data 1.281e+06 output 1.198e+03 target 1.281e+06
Train Epoch: 2 [4480/81276 (6%)]	Loss: 9.767529 LR 2.92e-04
	 Magnitude of data 1.306e+06 output 1.194e+03 target 1.306e+06
Train Epoch: 2 [5120/81276 (6%)]	Loss: 9.812014 LR 2.92e-04
	 Magnitude of data 1.360e+06 output 1.182e+03 target 1.360e+06
Train Epoch: 2 [5760/81276 (7%)]	Loss: 9.765349 LR 2.92e-04
	 Magnitude of data 1.349e+06 output 1.190e+03 target 1.350e+06
Train Epoch: 2 [6400/81276 (8%)]	Loss: 9.854352 LR 2.91e-04
	 Magnitude of data 1.285e+06 output 1.158e+03 target 1.286e+06
Train Epoch: 2 [7040/81276 (9%)]	Loss: 9.828631 LR 2.91e-04
	 Magnitude of data 1.278e+06 output 1.180e+03 target 1.278e+06
Train Epoch: 2 [7680/81276 (9%)]	Loss: 9.761966 LR 2.91e-04
	 Magnitude of data 1.419e+06 output 1.174e+03 target 1.419e+06
Train Epoch: 2 [8320/81276 (10%)]	Loss: 9.801991 LR 2.91e-04
	 Magnitude of data 1.234e+06 output 1.182e+03 target 1.234e+06
Train Epoch: 2 [8960/81276 (11%)]	Loss: 9.788591 LR 2.91e-04
	 Magnitude of data 1.348e+06 output 1.171e+03 target 1.348e+06
Train Epoch: 2 [9600/81276 (12%)]	Loss: 9.779305 LR 2.91e-04
	 Magnitude of data 1.364e+06 output 1.189e+03 target 1.364e+06
Train Epoch: 2 [10240/81276 (13%)]	Loss: 9.708466 LR 2.91e-04
	 Magnitude of data 1.276e+06 output 1.178e+03 target 1.276e+06
Train Epoch: 2 [10880/81276 (13%)]	Loss: 9.775073 LR 2.91e-04
	 Magnitude of data 1.240e+06 output 1.169e+03 target 1.240e+06
Train Epoch: 2 [11520/81276 (14%)]	Loss: 9.777273 LR 2.90e-04
	 Magnitude of data 1.342e+06 output 1.175e+03 target 1.342e+06
Train Epoch: 2 [12160/81276 (15%)]	Loss: 9.800549 LR 2.90e-04
	 Magnitude of data 1.359e+06 output 1.169e+03 target 1.359e+06
Train Epoch: 2 [12800/81276 (16%)]	Loss: 9.774079 LR 2.90e-04
	 Magnitude of data 1.366e+06 output 1.158e+03 target 1.366e+06
Train Epoch: 2 [13440/81276 (17%)]	Loss: 9.746241 LR 2.90e-04
	 Magnitude of data 1.241e+06 output 1.162e+03 target 1.241e+06
Train Epoch: 2 [14080/81276 (17%)]	Loss: 9.787015 LR 2.90e-04
	 Magnitude of data 1.396e+06 output 1.164e+03 target 1.396e+06
Train Epoch: 2 [14720/81276 (18%)]	Loss: 9.793781 LR 2.90e-04
	 Magnitude of data 1.450e+06 output 1.168e+03 target 1.450e+06
Train Epoch: 2 [15360/81276 (19%)]	Loss: 9.865606 LR 2.90e-04
	 Magnitude of data 1.387e+06 output 1.166e+03 target 1.387e+06
Train Epoch: 2 [16000/81276 (20%)]	Loss: 9.816252 LR 2.90e-04
	 Magnitude of data 1.371e+06 output 1.168e+03 target 1.371e+06
Train Epoch: 2 [16640/81276 (20%)]	Loss: 9.825355 LR 2.89e-04
	 Magnitude of data 1.274e+06 output 1.159e+03 target 1.274e+06
Train Epoch: 2 [17280/81276 (21%)]	Loss: 9.842239 LR 2.89e-04
	 Magnitude of data 1.443e+06 output 1.157e+03 target 1.442e+06
Train Epoch: 2 [17920/81276 (22%)]	Loss: 9.822375 LR 2.89e-04
	 Magnitude of data 1.267e+06 output 1.160e+03 target 1.266e+06
Train Epoch: 2 [18560/81276 (23%)]	Loss: 9.690094 LR 2.89e-04
	 Magnitude of data 1.246e+06 output 1.151e+03 target 1.246e+06
Train Epoch: 2 [19200/81276 (24%)]	Loss: 9.716260 LR 2.89e-04
	 Magnitude of data 1.254e+06 output 1.167e+03 target 1.254e+06
Train Epoch: 2 [19840/81276 (24%)]	Loss: 9.816702 LR 2.89e-04
	 Magnitude of data 1.331e+06 output 1.146e+03 target 1.331e+06
Train Epoch: 2 [20480/81276 (25%)]	Loss: 9.789901 LR 2.89e-04
	 Magnitude of data 1.190e+06 output 1.147e+03 target 1.190e+06
Train Epoch: 2 [21120/81276 (26%)]	Loss: 9.793200 LR 2.88e-04
	 Magnitude of data 1.290e+06 output 1.143e+03 target 1.290e+06
Train Epoch: 2 [21760/81276 (27%)]	Loss: 9.839305 LR 2.88e-04
	 Magnitude of data 1.386e+06 output 1.129e+03 target 1.385e+06
Train Epoch: 2 [22400/81276 (28%)]	Loss: 9.785851 LR 2.88e-04
	 Magnitude of data 1.271e+06 output 1.134e+03 target 1.271e+06
Train Epoch: 2 [23040/81276 (28%)]	Loss: 9.849105 LR 2.88e-04
	 Magnitude of data 1.259e+06 output 1.126e+03 target 1.259e+06
Train Epoch: 2 [23680/81276 (29%)]	Loss: 9.802502 LR 2.88e-04
	 Magnitude of data 1.231e+06 output 1.124e+03 target 1.231e+06
Train Epoch: 2 [24320/81276 (30%)]	Loss: 9.852560 LR 2.88e-04
	 Magnitude of data 1.323e+06 output 1.136e+03 target 1.322e+06
Train Epoch: 2 [24960/81276 (31%)]	Loss: 9.735205 LR 2.88e-04
	 Magnitude of data 1.341e+06 output 1.104e+03 target 1.341e+06
Train Epoch: 2 [25600/81276 (32%)]	Loss: 9.842608 LR 2.87e-04
	 Magnitude of data 1.299e+06 output 1.119e+03 target 1.299e+06
Train Epoch: 2 [26240/81276 (32%)]	Loss: 9.842205 LR 2.87e-04
	 Magnitude of data 1.329e+06 output 1.137e+03 target 1.329e+06
Train Epoch: 2 [26880/81276 (33%)]	Loss: 9.820340 LR 2.87e-04
	 Magnitude of data 1.258e+06 output 1.132e+03 target 1.258e+06
Train Epoch: 2 [27520/81276 (34%)]	Loss: 9.851532 LR 2.87e-04
	 Magnitude of data 1.280e+06 output 1.127e+03 target 1.280e+06
Train Epoch: 2 [28160/81276 (35%)]	Loss: 9.808041 LR 2.87e-04
	 Magnitude of data 1.353e+06 output 1.139e+03 target 1.353e+06
Train Epoch: 2 [28800/81276 (35%)]	Loss: 9.871183 LR 2.87e-04
	 Magnitude of data 1.316e+06 output 1.125e+03 target 1.316e+06
Train Epoch: 2 [29440/81276 (36%)]	Loss: 9.836966 LR 2.86e-04
	 Magnitude of data 1.295e+06 output 1.130e+03 target 1.295e+06
Train Epoch: 2 [30080/81276 (37%)]	Loss: 9.861829 LR 2.86e-04
	 Magnitude of data 1.290e+06 output 1.121e+03 target 1.290e+06
Train Epoch: 2 [30720/81276 (38%)]	Loss: 9.874709 LR 2.86e-04
	 Magnitude of data 1.320e+06 output 1.121e+03 target 1.320e+06
Train Epoch: 2 [31360/81276 (39%)]	Loss: 9.791847 LR 2.86e-04
	 Magnitude of data 1.397e+06 output 1.129e+03 target 1.397e+06
Train Epoch: 2 [32000/81276 (39%)]	Loss: 9.892064 LR 2.86e-04
	 Magnitude of data 1.283e+06 output 1.124e+03 target 1.283e+06
Train Epoch: 2 [32640/81276 (40%)]	Loss: 9.863738 LR 2.86e-04
	 Magnitude of data 1.354e+06 output 1.131e+03 target 1.354e+06
Train Epoch: 2 [33280/81276 (41%)]	Loss: 9.923353 LR 2.86e-04
	 Magnitude of data 1.271e+06 output 1.107e+03 target 1.271e+06
Train Epoch: 2 [33920/81276 (42%)]	Loss: 9.885174 LR 2.85e-04
	 Magnitude of data 1.296e+06 output 1.111e+03 target 1.296e+06
Train Epoch: 2 [34560/81276 (43%)]	Loss: 9.869950 LR 2.85e-04
	 Magnitude of data 1.312e+06 output 1.102e+03 target 1.312e+06
Train Epoch: 2 [35200/81276 (43%)]	Loss: 9.946607 LR 2.85e-04
	 Magnitude of data 1.383e+06 output 1.088e+03 target 1.383e+06
Train Epoch: 2 [35840/81276 (44%)]	Loss: 9.886708 LR 2.85e-04
	 Magnitude of data 1.314e+06 output 1.088e+03 target 1.314e+06
Train Epoch: 2 [36480/81276 (45%)]	Loss: 9.896850 LR 2.85e-04
	 Magnitude of data 1.359e+06 output 1.094e+03 target 1.359e+06
Train Epoch: 2 [37120/81276 (46%)]	Loss: 9.867439 LR 2.85e-04
	 Magnitude of data 1.273e+06 output 1.078e+03 target 1.273e+06
Train Epoch: 2 [37760/81276 (46%)]	Loss: 9.893914 LR 2.84e-04
	 Magnitude of data 1.261e+06 output 1.085e+03 target 1.261e+06
Train Epoch: 2 [38400/81276 (47%)]	Loss: 9.932567 LR 2.84e-04
	 Magnitude of data 1.358e+06 output 1.065e+03 target 1.358e+06
Train Epoch: 2 [39040/81276 (48%)]	Loss: 9.904453 LR 2.84e-04
	 Magnitude of data 1.339e+06 output 1.075e+03 target 1.339e+06
Train Epoch: 2 [39680/81276 (49%)]	Loss: 9.797399 LR 2.84e-04
	 Magnitude of data 1.233e+06 output 1.074e+03 target 1.233e+06
Train Epoch: 2 [40320/81276 (50%)]	Loss: 9.881750 LR 2.84e-04
	 Magnitude of data 1.395e+06 output 1.065e+03 target 1.395e+06
Train Epoch: 2 [40960/81276 (50%)]	Loss: 9.884046 LR 2.84e-04
	 Magnitude of data 1.324e+06 output 1.079e+03 target 1.324e+06
Train Epoch: 2 [41600/81276 (51%)]	Loss: 9.899709 LR 2.83e-04
	 Magnitude of data 1.367e+06 output 1.074e+03 target 1.367e+06
Train Epoch: 2 [42240/81276 (52%)]	Loss: 9.917465 LR 2.83e-04
	 Magnitude of data 1.301e+06 output 1.071e+03 target 1.301e+06
Train Epoch: 2 [42880/81276 (53%)]	Loss: 9.874048 LR 2.83e-04
	 Magnitude of data 1.223e+06 output 1.069e+03 target 1.223e+06
Train Epoch: 2 [43520/81276 (54%)]	Loss: 9.878044 LR 2.83e-04
	 Magnitude of data 1.285e+06 output 1.066e+03 target 1.285e+06
Train Epoch: 2 [44160/81276 (54%)]	Loss: 9.925007 LR 2.83e-04
	 Magnitude of data 1.281e+06 output 1.062e+03 target 1.281e+06
Train Epoch: 2 [44800/81276 (55%)]	Loss: 9.909719 LR 2.83e-04
	 Magnitude of data 1.413e+06 output 1.055e+03 target 1.413e+06
Train Epoch: 2 [45440/81276 (56%)]	Loss: 9.946562 LR 2.82e-04
	 Magnitude of data 1.310e+06 output 1.057e+03 target 1.310e+06
Train Epoch: 2 [46080/81276 (57%)]	Loss: 9.949397 LR 2.82e-04
	 Magnitude of data 1.308e+06 output 1.065e+03 target 1.308e+06
Train Epoch: 2 [46720/81276 (58%)]	Loss: 9.947660 LR 2.82e-04
	 Magnitude of data 1.370e+06 output 1.063e+03 target 1.371e+06
Train Epoch: 2 [47360/81276 (58%)]	Loss: 9.883620 LR 2.82e-04
	 Magnitude of data 1.361e+06 output 1.060e+03 target 1.361e+06
Train Epoch: 2 [48000/81276 (59%)]	Loss: 9.927551 LR 2.82e-04
	 Magnitude of data 1.285e+06 output 1.060e+03 target 1.286e+06
Train Epoch: 2 [48640/81276 (60%)]	Loss: 9.936440 LR 2.81e-04
	 Magnitude of data 1.249e+06 output 1.055e+03 target 1.249e+06
Train Epoch: 2 [49280/81276 (61%)]	Loss: 9.871000 LR 2.81e-04
	 Magnitude of data 1.305e+06 output 1.059e+03 target 1.305e+06
Train Epoch: 2 [49920/81276 (61%)]	Loss: 10.001942 LR 2.81e-04
	 Magnitude of data 1.259e+06 output 1.050e+03 target 1.259e+06
Train Epoch: 2 [50560/81276 (62%)]	Loss: 9.967405 LR 2.81e-04
	 Magnitude of data 1.274e+06 output 1.054e+03 target 1.273e+06
Train Epoch: 2 [51200/81276 (63%)]	Loss: 9.956663 LR 2.81e-04
	 Magnitude of data 1.319e+06 output 1.046e+03 target 1.319e+06
Train Epoch: 2 [51840/81276 (64%)]	Loss: 9.930109 LR 2.81e-04
	 Magnitude of data 1.351e+06 output 1.050e+03 target 1.351e+06
Train Epoch: 2 [52480/81276 (65%)]	Loss: 9.946213 LR 2.80e-04
	 Magnitude of data 1.318e+06 output 1.046e+03 target 1.318e+06
Train Epoch: 2 [53120/81276 (65%)]	Loss: 9.897843 LR 2.80e-04
	 Magnitude of data 1.274e+06 output 1.040e+03 target 1.274e+06
Train Epoch: 2 [53760/81276 (66%)]	Loss: 10.011972 LR 2.80e-04
	 Magnitude of data 1.363e+06 output 1.036e+03 target 1.363e+06
Train Epoch: 2 [54400/81276 (67%)]	Loss: 9.940898 LR 2.80e-04
	 Magnitude of data 1.305e+06 output 1.031e+03 target 1.305e+06
Train Epoch: 2 [55040/81276 (68%)]	Loss: 9.957077 LR 2.80e-04
	 Magnitude of data 1.319e+06 output 1.008e+03 target 1.318e+06
Train Epoch: 2 [55680/81276 (69%)]	Loss: 9.995575 LR 2.79e-04
	 Magnitude of data 1.197e+06 output 1.024e+03 target 1.197e+06
Train Epoch: 2 [56320/81276 (69%)]	Loss: 10.039969 LR 2.79e-04
	 Magnitude of data 1.373e+06 output 1.013e+03 target 1.373e+06
Train Epoch: 2 [56960/81276 (70%)]	Loss: 9.949596 LR 2.79e-04
	 Magnitude of data 1.323e+06 output 1.015e+03 target 1.323e+06
Train Epoch: 2 [57600/81276 (71%)]	Loss: 9.938609 LR 2.79e-04
	 Magnitude of data 1.223e+06 output 1.018e+03 target 1.223e+06
Train Epoch: 2 [58240/81276 (72%)]	Loss: 10.023725 LR 2.79e-04
	 Magnitude of data 1.344e+06 output 1.020e+03 target 1.344e+06
Train Epoch: 2 [58880/81276 (72%)]	Loss: 9.991881 LR 2.78e-04
	 Magnitude of data 1.282e+06 output 1.033e+03 target 1.282e+06
Train Epoch: 2 [59520/81276 (73%)]	Loss: 9.920443 LR 2.78e-04
	 Magnitude of data 1.214e+06 output 1.018e+03 target 1.214e+06
Train Epoch: 2 [60160/81276 (74%)]	Loss: 10.011065 LR 2.78e-04
	 Magnitude of data 1.322e+06 output 1.009e+03 target 1.323e+06
Train Epoch: 2 [60800/81276 (75%)]	Loss: 9.948073 LR 2.78e-04
	 Magnitude of data 1.290e+06 output 1.025e+03 target 1.290e+06
Train Epoch: 2 [61440/81276 (76%)]	Loss: 10.013556 LR 2.78e-04
	 Magnitude of data 1.354e+06 output 1.016e+03 target 1.354e+06
Train Epoch: 2 [62080/81276 (76%)]	Loss: 9.940047 LR 2.78e-04
	 Magnitude of data 1.348e+06 output 1.010e+03 target 1.348e+06
Train Epoch: 2 [62720/81276 (77%)]	Loss: 9.953813 LR 2.77e-04
	 Magnitude of data 1.358e+06 output 1.030e+03 target 1.358e+06
Train Epoch: 2 [63360/81276 (78%)]	Loss: 9.981911 LR 2.77e-04
	 Magnitude of data 1.367e+06 output 1.022e+03 target 1.367e+06
Train Epoch: 2 [64000/81276 (79%)]	Loss: 10.001561 LR 2.77e-04
	 Magnitude of data 1.341e+06 output 1.013e+03 target 1.341e+06
Train Epoch: 2 [64640/81276 (80%)]	Loss: 10.006804 LR 2.77e-04
	 Magnitude of data 1.274e+06 output 1.015e+03 target 1.274e+06
Train Epoch: 2 [65280/81276 (80%)]	Loss: 10.020098 LR 2.77e-04
	 Magnitude of data 1.638e+06 output 1.004e+03 target 1.638e+06
Train Epoch: 2 [65920/81276 (81%)]	Loss: 9.944818 LR 2.76e-04
	 Magnitude of data 1.178e+06 output 1.008e+03 target 1.178e+06
Train Epoch: 2 [66560/81276 (82%)]	Loss: 10.021218 LR 2.76e-04
	 Magnitude of data 1.313e+06 output 1.003e+03 target 1.313e+06
Train Epoch: 2 [67200/81276 (83%)]	Loss: 9.989515 LR 2.76e-04
	 Magnitude of data 1.305e+06 output 9.989e+02 target 1.305e+06
Train Epoch: 2 [67840/81276 (84%)]	Loss: 9.997280 LR 2.76e-04
	 Magnitude of data 1.243e+06 output 9.903e+02 target 1.243e+06
Train Epoch: 2 [68480/81276 (84%)]	Loss: 10.058000 LR 2.76e-04
	 Magnitude of data 1.389e+06 output 9.769e+02 target 1.389e+06
Train Epoch: 2 [69120/81276 (85%)]	Loss: 10.018179 LR 2.75e-04
	 Magnitude of data 1.368e+06 output 9.833e+02 target 1.368e+06
Train Epoch: 2 [69760/81276 (86%)]	Loss: 10.041290 LR 2.75e-04
	 Magnitude of data 1.272e+06 output 9.848e+02 target 1.272e+06
Train Epoch: 2 [70400/81276 (87%)]	Loss: 10.017400 LR 2.75e-04
	 Magnitude of data 1.307e+06 output 9.858e+02 target 1.307e+06
Train Epoch: 2 [71040/81276 (87%)]	Loss: 10.089643 LR 2.75e-04
	 Magnitude of data 1.298e+06 output 9.725e+02 target 1.298e+06
Train Epoch: 2 [71680/81276 (88%)]	Loss: 10.075175 LR 2.75e-04
	 Magnitude of data 1.285e+06 output 9.783e+02 target 1.285e+06
Train Epoch: 2 [72320/81276 (89%)]	Loss: 10.075131 LR 2.74e-04
	 Magnitude of data 1.372e+06 output 9.709e+02 target 1.372e+06
Train Epoch: 2 [72960/81276 (90%)]	Loss: 10.060015 LR 2.74e-04
	 Magnitude of data 1.268e+06 output 9.673e+02 target 1.268e+06
Train Epoch: 2 [73600/81276 (91%)]	Loss: 10.040986 LR 2.74e-04
	 Magnitude of data 1.248e+06 output 9.628e+02 target 1.248e+06
Train Epoch: 2 [74240/81276 (91%)]	Loss: 10.103274 LR 2.74e-04
	 Magnitude of data 1.344e+06 output 9.572e+02 target 1.344e+06
Train Epoch: 2 [74880/81276 (92%)]	Loss: 10.098734 LR 2.73e-04
	 Magnitude of data 1.405e+06 output 9.589e+02 target 1.405e+06
Train Epoch: 2 [75520/81276 (93%)]	Loss: 10.061505 LR 2.73e-04
	 Magnitude of data 1.326e+06 output 9.577e+02 target 1.326e+06
Train Epoch: 2 [76160/81276 (94%)]	Loss: 10.057102 LR 2.73e-04
	 Magnitude of data 1.291e+06 output 9.473e+02 target 1.291e+06
Train Epoch: 2 [76800/81276 (95%)]	Loss: 10.024032 LR 2.73e-04
	 Magnitude of data 1.338e+06 output 9.365e+02 target 1.338e+06
Train Epoch: 2 [77440/81276 (95%)]	Loss: 10.103233 LR 2.73e-04
	 Magnitude of data 1.279e+06 output 9.210e+02 target 1.279e+06
Train Epoch: 2 [78080/81276 (96%)]	Loss: 10.091839 LR 2.72e-04
	 Magnitude of data 1.287e+06 output 9.145e+02 target 1.287e+06
Train Epoch: 2 [78720/81276 (97%)]	Loss: 10.068993 LR 2.72e-04
	 Magnitude of data 1.253e+06 output 9.115e+02 target 1.253e+06
Train Epoch: 2 [79360/81276 (98%)]	Loss: 10.138674 LR 2.72e-04
	 Magnitude of data 1.327e+06 output 9.001e+02 target 1.327e+06
Train Epoch: 2 [80000/81276 (99%)]	Loss: 10.136512 LR 2.72e-04
	 Magnitude of data 1.478e+06 output 8.878e+02 target 1.478e+06
Train Epoch: 2 [80640/81276 (99%)]	Loss: 10.122923 LR 2.72e-04
	 Magnitude of data 1.218e+06 output 8.921e+02 target 1.218e+06
Train Epoch: 2 [81216/81276 (100%)]	Loss: 10.086191 LR 2.71e-04
Test set: Average loss: 10.11758235
Train Epoch: 3 [0/81276 (0%)]	Loss: 10.102440 LR 2.71e-04
	 Magnitude of data 1.348e+06 output 8.899e+02 target 1.348e+06
Train Epoch: 3 [640/81276 (1%)]	Loss: 10.148290 LR 2.71e-04
	 Magnitude of data 1.314e+06 output 8.936e+02 target 1.314e+06
Train Epoch: 3 [1280/81276 (2%)]	Loss: 10.148781 LR 2.71e-04
	 Magnitude of data 1.495e+06 output 8.916e+02 target 1.495e+06
Train Epoch: 3 [1920/81276 (2%)]	Loss: 10.122449 LR 2.71e-04
	 Magnitude of data 1.218e+06 output 8.835e+02 target 1.218e+06
Train Epoch: 3 [2560/81276 (3%)]	Loss: 10.089172 LR 2.70e-04
	 Magnitude of data 1.281e+06 output 8.880e+02 target 1.281e+06
Train Epoch: 3 [3200/81276 (4%)]	Loss: 10.123573 LR 2.70e-04
	 Magnitude of data 1.317e+06 output 8.892e+02 target 1.317e+06
Train Epoch: 3 [3840/81276 (5%)]	Loss: 10.102618 LR 2.70e-04
	 Magnitude of data 1.281e+06 output 8.894e+02 target 1.281e+06
Train Epoch: 3 [4480/81276 (6%)]	Loss: 10.136219 LR 2.70e-04
	 Magnitude of data 1.306e+06 output 8.849e+02 target 1.306e+06
Train Epoch: 3 [5120/81276 (6%)]	Loss: 10.151679 LR 2.70e-04
	 Magnitude of data 1.360e+06 output 8.728e+02 target 1.360e+06
Train Epoch: 3 [5760/81276 (7%)]	Loss: 10.150324 LR 2.69e-04
	 Magnitude of data 1.349e+06 output 8.725e+02 target 1.350e+06
Train Epoch: 3 [6400/81276 (8%)]	Loss: 10.170718 LR 2.69e-04
	 Magnitude of data 1.285e+06 output 8.527e+02 target 1.286e+06
Train Epoch: 3 [7040/81276 (9%)]	Loss: 10.190585 LR 2.69e-04
	 Magnitude of data 1.278e+06 output 8.560e+02 target 1.278e+06
Train Epoch: 3 [7680/81276 (9%)]	Loss: 10.169618 LR 2.69e-04
	 Magnitude of data 1.419e+06 output 8.516e+02 target 1.419e+06
Train Epoch: 3 [8320/81276 (10%)]	Loss: 10.165552 LR 2.68e-04
	 Magnitude of data 1.234e+06 output 8.551e+02 target 1.234e+06
Train Epoch: 3 [8960/81276 (11%)]	Loss: 10.159634 LR 2.68e-04
	 Magnitude of data 1.348e+06 output 8.467e+02 target 1.348e+06
Train Epoch: 3 [9600/81276 (12%)]	Loss: 10.166506 LR 2.68e-04
	 Magnitude of data 1.364e+06 output 8.473e+02 target 1.364e+06
Train Epoch: 3 [10240/81276 (13%)]	Loss: 10.137877 LR 2.68e-04
	 Magnitude of data 1.276e+06 output 8.410e+02 target 1.276e+06
Train Epoch: 3 [10880/81276 (13%)]	Loss: 10.171064 LR 2.68e-04
	 Magnitude of data 1.240e+06 output 8.310e+02 target 1.240e+06
Train Epoch: 3 [11520/81276 (14%)]	Loss: 10.202703 LR 2.67e-04
	 Magnitude of data 1.342e+06 output 8.319e+02 target 1.342e+06
Train Epoch: 3 [12160/81276 (15%)]	Loss: 10.173646 LR 2.67e-04
	 Magnitude of data 1.359e+06 output 8.280e+02 target 1.359e+06
Train Epoch: 3 [12800/81276 (16%)]	Loss: 10.200556 LR 2.67e-04
	 Magnitude of data 1.366e+06 output 8.142e+02 target 1.366e+06
Train Epoch: 3 [13440/81276 (17%)]	Loss: 10.149713 LR 2.67e-04
	 Magnitude of data 1.241e+06 output 8.123e+02 target 1.241e+06
Train Epoch: 3 [14080/81276 (17%)]	Loss: 10.186625 LR 2.66e-04
	 Magnitude of data 1.396e+06 output 8.065e+02 target 1.396e+06
Train Epoch: 3 [14720/81276 (18%)]	Loss: 10.180918 LR 2.66e-04
	 Magnitude of data 1.450e+06 output 8.073e+02 target 1.450e+06
Train Epoch: 3 [15360/81276 (19%)]	Loss: 10.242448 LR 2.66e-04
	 Magnitude of data 1.387e+06 output 8.034e+02 target 1.387e+06
Train Epoch: 3 [16000/81276 (20%)]	Loss: 10.222068 LR 2.66e-04
	 Magnitude of data 1.371e+06 output 7.966e+02 target 1.371e+06
Train Epoch: 3 [16640/81276 (20%)]	Loss: 10.223704 LR 2.65e-04
	 Magnitude of data 1.274e+06 output 7.891e+02 target 1.274e+06
Train Epoch: 3 [17280/81276 (21%)]	Loss: 10.244376 LR 2.65e-04
	 Magnitude of data 1.443e+06 output 7.830e+02 target 1.442e+06
Train Epoch: 3 [17920/81276 (22%)]	Loss: 10.242380 LR 2.65e-04
	 Magnitude of data 1.267e+06 output 7.743e+02 target 1.266e+06
Train Epoch: 3 [18560/81276 (23%)]	Loss: 10.150992 LR 2.65e-04
	 Magnitude of data 1.246e+06 output 7.688e+02 target 1.246e+06
Train Epoch: 3 [19200/81276 (24%)]	Loss: 10.149617 LR 2.64e-04
	 Magnitude of data 1.254e+06 output 7.722e+02 target 1.254e+06
Train Epoch: 3 [19840/81276 (24%)]	Loss: 10.246449 LR 2.64e-04
	 Magnitude of data 1.331e+06 output 7.578e+02 target 1.331e+06
Train Epoch: 3 [20480/81276 (25%)]	Loss: 10.236513 LR 2.64e-04
	 Magnitude of data 1.190e+06 output 7.531e+02 target 1.190e+06
Train Epoch: 3 [21120/81276 (26%)]	Loss: 10.227141 LR 2.64e-04
	 Magnitude of data 1.290e+06 output 7.513e+02 target 1.290e+06
Train Epoch: 3 [21760/81276 (27%)]	Loss: 10.256854 LR 2.63e-04
	 Magnitude of data 1.386e+06 output 7.401e+02 target 1.385e+06
Train Epoch: 3 [22400/81276 (28%)]	Loss: 10.236083 LR 2.63e-04
	 Magnitude of data 1.271e+06 output 7.376e+02 target 1.271e+06
Train Epoch: 3 [23040/81276 (28%)]	Loss: 10.268070 LR 2.63e-04
	 Magnitude of data 1.259e+06 output 7.281e+02 target 1.259e+06
Train Epoch: 3 [23680/81276 (29%)]	Loss: 10.249501 LR 2.63e-04
	 Magnitude of data 1.231e+06 output 7.192e+02 target 1.231e+06
Train Epoch: 3 [24320/81276 (30%)]	Loss: 10.264892 LR 2.63e-04
	 Magnitude of data 1.323e+06 output 7.201e+02 target 1.322e+06
Train Epoch: 3 [24960/81276 (31%)]	Loss: 10.231018 LR 2.62e-04
	 Magnitude of data 1.341e+06 output 7.019e+02 target 1.341e+06
Train Epoch: 3 [25600/81276 (32%)]	Loss: 10.286488 LR 2.62e-04
	 Magnitude of data 1.299e+06 output 7.008e+02 target 1.299e+06
Train Epoch: 3 [26240/81276 (32%)]	Loss: 10.275554 LR 2.62e-04
	 Magnitude of data 1.329e+06 output 7.067e+02 target 1.329e+06
Train Epoch: 3 [26880/81276 (33%)]	Loss: 10.272505 LR 2.62e-04
	 Magnitude of data 1.258e+06 output 7.011e+02 target 1.258e+06
Train Epoch: 3 [27520/81276 (34%)]	Loss: 10.294521 LR 2.61e-04
	 Magnitude of data 1.280e+06 output 6.955e+02 target 1.280e+06
Train Epoch: 3 [28160/81276 (35%)]	Loss: 10.268777 LR 2.61e-04
	 Magnitude of data 1.353e+06 output 6.979e+02 target 1.353e+06
Train Epoch: 3 [28800/81276 (35%)]	Loss: 10.287480 LR 2.61e-04
	 Magnitude of data 1.316e+06 output 6.928e+02 target 1.316e+06
Train Epoch: 3 [29440/81276 (36%)]	Loss: 10.270371 LR 2.61e-04
	 Magnitude of data 1.295e+06 output 6.915e+02 target 1.295e+06
Train Epoch: 3 [30080/81276 (37%)]	Loss: 10.311821 LR 2.60e-04
	 Magnitude of data 1.290e+06 output 6.839e+02 target 1.290e+06
Train Epoch: 3 [30720/81276 (38%)]	Loss: 10.316832 LR 2.60e-04
	 Magnitude of data 1.320e+06 output 6.783e+02 target 1.320e+06
Train Epoch: 3 [31360/81276 (39%)]	Loss: 10.288558 LR 2.60e-04
	 Magnitude of data 1.397e+06 output 6.751e+02 target 1.397e+06
Train Epoch: 3 [32000/81276 (39%)]	Loss: 10.341888 LR 2.60e-04
	 Magnitude of data 1.283e+06 output 6.677e+02 target 1.283e+06
Train Epoch: 3 [32640/81276 (40%)]	Loss: 10.349030 LR 2.59e-04
	 Magnitude of data 1.354e+06 output 6.660e+02 target 1.354e+06
Train Epoch: 3 [33280/81276 (41%)]	Loss: 10.358438 LR 2.59e-04
	 Magnitude of data 1.271e+06 output 6.540e+02 target 1.271e+06
Train Epoch: 3 [33920/81276 (42%)]	Loss: 10.340107 LR 2.59e-04
	 Magnitude of data 1.296e+06 output 6.459e+02 target 1.296e+06
Train Epoch: 3 [34560/81276 (43%)]	Loss: 10.326877 LR 2.58e-04
	 Magnitude of data 1.312e+06 output 6.364e+02 target 1.312e+06
Train Epoch: 3 [35200/81276 (43%)]	Loss: 10.370893 LR 2.58e-04
	 Magnitude of data 1.383e+06 output 6.261e+02 target 1.383e+06
Train Epoch: 3 [35840/81276 (44%)]	Loss: 10.359848 LR 2.58e-04
	 Magnitude of data 1.314e+06 output 6.165e+02 target 1.314e+06
Train Epoch: 3 [36480/81276 (45%)]	Loss: 10.349924 LR 2.58e-04
	 Magnitude of data 1.359e+06 output 6.122e+02 target 1.359e+06
Train Epoch: 3 [37120/81276 (46%)]	Loss: 10.359903 LR 2.57e-04
	 Magnitude of data 1.273e+06 output 6.017e+02 target 1.273e+06
Train Epoch: 3 [37760/81276 (46%)]	Loss: 10.373226 LR 2.57e-04
	 Magnitude of data 1.261e+06 output 5.955e+02 target 1.261e+06
Train Epoch: 3 [38400/81276 (47%)]	Loss: 10.403273 LR 2.57e-04
	 Magnitude of data 1.358e+06 output 5.814e+02 target 1.358e+06
Train Epoch: 3 [39040/81276 (48%)]	Loss: 10.382311 LR 2.57e-04
	 Magnitude of data 1.339e+06 output 5.794e+02 target 1.339e+06
Train Epoch: 3 [39680/81276 (49%)]	Loss: 10.356992 LR 2.56e-04
	 Magnitude of data 1.233e+06 output 5.709e+02 target 1.233e+06
Train Epoch: 3 [40320/81276 (50%)]	Loss: 10.390692 LR 2.56e-04
	 Magnitude of data 1.395e+06 output 5.644e+02 target 1.395e+06
Train Epoch: 3 [40960/81276 (50%)]	Loss: 10.391065 LR 2.56e-04
	 Magnitude of data 1.324e+06 output 5.618e+02 target 1.324e+06
Train Epoch: 3 [41600/81276 (51%)]	Loss: 10.414572 LR 2.56e-04
	 Magnitude of data 1.367e+06 output 5.561e+02 target 1.367e+06
Train Epoch: 3 [42240/81276 (52%)]	Loss: 10.413107 LR 2.55e-04
	 Magnitude of data 1.301e+06 output 5.485e+02 target 1.301e+06
Train Epoch: 3 [42880/81276 (53%)]	Loss: 10.411291 LR 2.55e-04
	 Magnitude of data 1.223e+06 output 5.432e+02 target 1.223e+06
Train Epoch: 3 [43520/81276 (54%)]	Loss: 10.410867 LR 2.55e-04
	 Magnitude of data 1.285e+06 output 5.354e+02 target 1.285e+06
Train Epoch: 3 [44160/81276 (54%)]	Loss: 10.420807 LR 2.55e-04
	 Magnitude of data 1.281e+06 output 5.274e+02 target 1.281e+06
Train Epoch: 3 [44800/81276 (55%)]	Loss: 10.423632 LR 2.54e-04
	 Magnitude of data 1.413e+06 output 5.226e+02 target 1.413e+06
Train Epoch: 3 [45440/81276 (56%)]	Loss: 10.446592 LR 2.54e-04
	 Magnitude of data 1.310e+06 output 5.151e+02 target 1.310e+06
Train Epoch: 3 [46080/81276 (57%)]	Loss: 10.448227 LR 2.54e-04
	 Magnitude of data 1.308e+06 output 5.128e+02 target 1.308e+06
Train Epoch: 3 [46720/81276 (58%)]	Loss: 10.451425 LR 2.54e-04
	 Magnitude of data 1.370e+06 output 5.077e+02 target 1.371e+06
Train Epoch: 3 [47360/81276 (58%)]	Loss: 10.422593 LR 2.53e-04
	 Magnitude of data 1.361e+06 output 5.012e+02 target 1.361e+06
Train Epoch: 3 [48000/81276 (59%)]	Loss: 10.449242 LR 2.53e-04
	 Magnitude of data 1.285e+06 output 4.958e+02 target 1.286e+06
Train Epoch: 3 [48640/81276 (60%)]	Loss: 10.459508 LR 2.53e-04
	 Magnitude of data 1.249e+06 output 4.887e+02 target 1.249e+06
Train Epoch: 3 [49280/81276 (61%)]	Loss: 10.428070 LR 2.52e-04
	 Magnitude of data 1.305e+06 output 4.831e+02 target 1.305e+06
Train Epoch: 3 [49920/81276 (61%)]	Loss: 10.491004 LR 2.52e-04
	 Magnitude of data 1.259e+06 output 4.737e+02 target 1.259e+06
Train Epoch: 3 [50560/81276 (62%)]	Loss: 10.479362 LR 2.52e-04
	 Magnitude of data 1.274e+06 output 4.695e+02 target 1.273e+06
Train Epoch: 3 [51200/81276 (63%)]	Loss: 10.481075 LR 2.52e-04
	 Magnitude of data 1.319e+06 output 4.634e+02 target 1.319e+06
Train Epoch: 3 [51840/81276 (64%)]	Loss: 10.477839 LR 2.51e-04
	 Magnitude of data 1.351e+06 output 4.587e+02 target 1.351e+06
Train Epoch: 3 [52480/81276 (65%)]	Loss: 10.481430 LR 2.51e-04
	 Magnitude of data 1.318e+06 output 4.523e+02 target 1.318e+06
Train Epoch: 3 [53120/81276 (65%)]	Loss: 10.467452 LR 2.51e-04
	 Magnitude of data 1.274e+06 output 4.430e+02 target 1.274e+06
Train Epoch: 3 [53760/81276 (66%)]	Loss: 10.514052 LR 2.51e-04
	 Magnitude of data 1.363e+06 output 4.354e+02 target 1.363e+06
Train Epoch: 3 [54400/81276 (67%)]	Loss: 10.496249 LR 2.50e-04
	 Magnitude of data 1.305e+06 output 4.257e+02 target 1.305e+06
Train Epoch: 3 [55040/81276 (68%)]	Loss: 10.514790 LR 2.50e-04
	 Magnitude of data 1.319e+06 output 4.144e+02 target 1.318e+06
Train Epoch: 3 [55680/81276 (69%)]	Loss: 10.526069 LR 2.50e-04
	 Magnitude of data 1.197e+06 output 4.122e+02 target 1.197e+06
Train Epoch: 3 [56320/81276 (69%)]	Loss: 10.546500 LR 2.49e-04
	 Magnitude of data 1.373e+06 output 4.039e+02 target 1.373e+06
Train Epoch: 3 [56960/81276 (70%)]	Loss: 10.514297 LR 2.49e-04
	 Magnitude of data 1.323e+06 output 3.971e+02 target 1.323e+06
Train Epoch: 3 [57600/81276 (71%)]	Loss: 10.517308 LR 2.49e-04
	 Magnitude of data 1.223e+06 output 3.915e+02 target 1.223e+06
Train Epoch: 3 [58240/81276 (72%)]	Loss: 10.554397 LR 2.49e-04
	 Magnitude of data 1.344e+06 output 3.877e+02 target 1.344e+06
Train Epoch: 3 [58880/81276 (72%)]	Loss: 10.542825 LR 2.48e-04
	 Magnitude of data 1.282e+06 output 3.849e+02 target 1.282e+06
Train Epoch: 3 [59520/81276 (73%)]	Loss: 10.532215 LR 2.48e-04
	 Magnitude of data 1.214e+06 output 3.767e+02 target 1.214e+06
Train Epoch: 3 [60160/81276 (74%)]	Loss: 10.555338 LR 2.48e-04
	 Magnitude of data 1.322e+06 output 3.673e+02 target 1.323e+06
Train Epoch: 3 [60800/81276 (75%)]	Loss: 10.538278 LR 2.47e-04
	 Magnitude of data 1.290e+06 output 3.636e+02 target 1.290e+06
Train Epoch: 3 [61440/81276 (76%)]	Loss: 10.563758 LR 2.47e-04
	 Magnitude of data 1.354e+06 output 3.571e+02 target 1.354e+06
Train Epoch: 3 [62080/81276 (76%)]	Loss: 10.551965 LR 2.47e-04
	 Magnitude of data 1.348e+06 output 3.517e+02 target 1.348e+06
Train Epoch: 3 [62720/81276 (77%)]	Loss: 10.551773 LR 2.47e-04
	 Magnitude of data 1.358e+06 output 3.523e+02 target 1.358e+06
Train Epoch: 3 [63360/81276 (78%)]	Loss: 10.576622 LR 2.46e-04
	 Magnitude of data 1.367e+06 output 3.478e+02 target 1.367e+06
Train Epoch: 3 [64000/81276 (79%)]	Loss: 10.575835 LR 2.46e-04
	 Magnitude of data 1.341e+06 output 3.402e+02 target 1.341e+06
Train Epoch: 3 [64640/81276 (80%)]	Loss: 10.578323 LR 2.46e-04
	 Magnitude of data 1.274e+06 output 3.343e+02 target 1.274e+06
Train Epoch: 3 [65280/81276 (80%)]	Loss: 10.588989 LR 2.45e-04
	 Magnitude of data 1.638e+06 output 3.281e+02 target 1.638e+06
Train Epoch: 3 [65920/81276 (81%)]	Loss: 10.572584 LR 2.45e-04
	 Magnitude of data 1.178e+06 output 3.228e+02 target 1.178e+06
Train Epoch: 3 [66560/81276 (82%)]	Loss: 10.593781 LR 2.45e-04
	 Magnitude of data 1.313e+06 output 3.175e+02 target 1.313e+06
Train Epoch: 3 [67200/81276 (83%)]	Loss: 10.588864 LR 2.45e-04
	 Magnitude of data 1.305e+06 output 3.104e+02 target 1.305e+06
Train Epoch: 3 [67840/81276 (84%)]	Loss: 10.600150 LR 2.44e-04
	 Magnitude of data 1.243e+06 output 3.034e+02 target 1.243e+06
Train Epoch: 3 [68480/81276 (84%)]	Loss: 10.613809 LR 2.44e-04
	 Magnitude of data 1.389e+06 output 2.961e+02 target 1.389e+06
Train Epoch: 3 [69120/81276 (85%)]	Loss: 10.608369 LR 2.44e-04
	 Magnitude of data 1.368e+06 output 2.911e+02 target 1.368e+06
Train Epoch: 3 [69760/81276 (86%)]	Loss: 10.615610 LR 2.43e-04
	 Magnitude of data 1.272e+06 output 2.867e+02 target 1.272e+06
Train Epoch: 3 [70400/81276 (87%)]	Loss: 10.616487 LR 2.43e-04
	 Magnitude of data 1.307e+06 output 2.831e+02 target 1.307e+06
Train Epoch: 3 [71040/81276 (87%)]	Loss: 10.634649 LR 2.43e-04
	 Magnitude of data 1.298e+06 output 2.776e+02 target 1.298e+06
Train Epoch: 3 [71680/81276 (88%)]	Loss: 10.632277 LR 2.43e-04
	 Magnitude of data 1.285e+06 output 2.730e+02 target 1.285e+06
Train Epoch: 3 [72320/81276 (89%)]	Loss: 10.642366 LR 2.42e-04
	 Magnitude of data 1.372e+06 output 2.664e+02 target 1.372e+06
Train Epoch: 3 [72960/81276 (90%)]	Loss: 10.639809 LR 2.42e-04
	 Magnitude of data 1.268e+06 output 2.616e+02 target 1.268e+06
Train Epoch: 3 [73600/81276 (91%)]	Loss: 10.635435 LR 2.42e-04
	 Magnitude of data 1.248e+06 output 2.561e+02 target 1.248e+06
Train Epoch: 3 [74240/81276 (91%)]	Loss: 10.652719 LR 2.41e-04
	 Magnitude of data 1.344e+06 output 2.508e+02 target 1.344e+06
Train Epoch: 3 [74880/81276 (92%)]	Loss: 10.651325 LR 2.41e-04
	 Magnitude of data 1.405e+06 output 2.464e+02 target 1.405e+06
Train Epoch: 3 [75520/81276 (93%)]	Loss: 10.650226 LR 2.41e-04
	 Magnitude of data 1.326e+06 output 2.418e+02 target 1.326e+06
Train Epoch: 3 [76160/81276 (94%)]	Loss: 10.653340 LR 2.40e-04
	 Magnitude of data 1.291e+06 output 2.358e+02 target 1.291e+06
Train Epoch: 3 [76800/81276 (95%)]	Loss: 10.646343 LR 2.40e-04
	 Magnitude of data 1.338e+06 output 2.298e+02 target 1.338e+06
Train Epoch: 3 [77440/81276 (95%)]	Loss: 10.667942 LR 2.40e-04
	 Magnitude of data 1.279e+06 output 2.236e+02 target 1.279e+06
Train Epoch: 3 [78080/81276 (96%)]	Loss: 10.667337 LR 2.40e-04
	 Magnitude of data 1.287e+06 output 2.180e+02 target 1.287e+06
Train Epoch: 3 [78720/81276 (97%)]	Loss: 10.666141 LR 2.39e-04
	 Magnitude of data 1.253e+06 output 2.128e+02 target 1.253e+06
Train Epoch: 3 [79360/81276 (98%)]	Loss: 10.681779 LR 2.39e-04
	 Magnitude of data 1.327e+06 output 2.079e+02 target 1.327e+06
Train Epoch: 3 [80000/81276 (99%)]	Loss: 10.683425 LR 2.39e-04
	 Magnitude of data 1.478e+06 output 2.031e+02 target 1.478e+06
Train Epoch: 3 [80640/81276 (99%)]	Loss: 10.676429 LR 2.38e-04
	 Magnitude of data 1.218e+06 output 1.995e+02 target 1.218e+06
Train Epoch: 3 [81216/81276 (100%)]	Loss: 10.679799 LR 2.38e-04
Test set: Average loss: 10.68365627
Train Epoch: 4 [0/81276 (0%)]	Loss: 10.680807 LR 2.38e-04
	 Magnitude of data 1.348e+06 output 1.967e+02 target 1.348e+06
Train Epoch: 4 [640/81276 (1%)]	Loss: 10.693700 LR 2.38e-04
	 Magnitude of data 1.314e+06 output 1.942e+02 target 1.314e+06
Train Epoch: 4 [1280/81276 (2%)]	Loss: 10.694382 LR 2.38e-04
	 Magnitude of data 1.495e+06 output 1.907e+02 target 1.495e+06
Train Epoch: 4 [1920/81276 (2%)]	Loss: 10.693999 LR 2.37e-04
	 Magnitude of data 1.218e+06 output 1.864e+02 target 1.218e+06
Train Epoch: 4 [2560/81276 (3%)]	Loss: 10.684754 LR 2.37e-04
	 Magnitude of data 1.281e+06 output 1.836e+02 target 1.281e+06
Train Epoch: 4 [3200/81276 (4%)]	Loss: 10.695295 LR 2.37e-04
	 Magnitude of data 1.317e+06 output 1.811e+02 target 1.317e+06
Train Epoch: 4 [3840/81276 (5%)]	Loss: 10.691094 LR 2.36e-04
	 Magnitude of data 1.281e+06 output 1.782e+02 target 1.281e+06
Train Epoch: 4 [4480/81276 (6%)]	Loss: 10.700603 LR 2.36e-04
	 Magnitude of data 1.306e+06 output 1.750e+02 target 1.306e+06
Train Epoch: 4 [5120/81276 (6%)]	Loss: 10.701537 LR 2.36e-04
	 Magnitude of data 1.360e+06 output 1.711e+02 target 1.360e+06
Train Epoch: 4 [5760/81276 (7%)]	Loss: 10.705412 LR 2.35e-04
	 Magnitude of data 1.349e+06 output 1.682e+02 target 1.350e+06
Train Epoch: 4 [6400/81276 (8%)]	Loss: 10.709284 LR 2.35e-04
	 Magnitude of data 1.285e+06 output 1.644e+02 target 1.286e+06
Train Epoch: 4 [7040/81276 (9%)]	Loss: 10.714254 LR 2.35e-04
	 Magnitude of data 1.278e+06 output 1.617e+02 target 1.278e+06
Train Epoch: 4 [7680/81276 (9%)]	Loss: 10.715808 LR 2.34e-04
	 Magnitude of data 1.419e+06 output 1.592e+02 target 1.419e+06
Train Epoch: 4 [8320/81276 (10%)]	Loss: 10.713796 LR 2.34e-04
	 Magnitude of data 1.234e+06 output 1.571e+02 target 1.234e+06
Train Epoch: 4 [8960/81276 (11%)]	Loss: 10.714231 LR 2.34e-04
	 Magnitude of data 1.348e+06 output 1.548e+02 target 1.348e+06
Train Epoch: 4 [9600/81276 (12%)]	Loss: 10.714174 LR 2.34e-04
	 Magnitude of data 1.364e+06 output 1.526e+02 target 1.364e+06
Train Epoch: 4 [10240/81276 (13%)]	Loss: 10.714226 LR 2.33e-04
	 Magnitude of data 1.276e+06 output 1.506e+02 target 1.276e+06
Train Epoch: 4 [10880/81276 (13%)]	Loss: 10.718472 LR 2.33e-04
	 Magnitude of data 1.240e+06 output 1.483e+02 target 1.240e+06
Train Epoch: 4 [11520/81276 (14%)]	Loss: 10.727476 LR 2.33e-04
	 Magnitude of data 1.342e+06 output 1.465e+02 target 1.342e+06
Train Epoch: 4 [12160/81276 (15%)]	Loss: 10.719294 LR 2.32e-04
	 Magnitude of data 1.359e+06 output 1.446e+02 target 1.359e+06
Train Epoch: 4 [12800/81276 (16%)]	Loss: 10.727761 LR 2.32e-04
	 Magnitude of data 1.366e+06 output 1.426e+02 target 1.366e+06
Train Epoch: 4 [13440/81276 (17%)]	Loss: 10.718844 LR 2.32e-04
	 Magnitude of data 1.241e+06 output 1.409e+02 target 1.241e+06
Train Epoch: 4 [14080/81276 (17%)]	Loss: 10.723901 LR 2.31e-04
	 Magnitude of data 1.396e+06 output 1.393e+02 target 1.396e+06
Train Epoch: 4 [14720/81276 (18%)]	Loss: 10.721821 LR 2.31e-04
	 Magnitude of data 1.450e+06 output 1.382e+02 target 1.450e+06
Train Epoch: 4 [15360/81276 (19%)]	Loss: 10.732459 LR 2.31e-04
	 Magnitude of data 1.387e+06 output 1.371e+02 target 1.387e+06
Train Epoch: 4 [16000/81276 (20%)]	Loss: 10.729941 LR 2.30e-04
	 Magnitude of data 1.371e+06 output 1.357e+02 target 1.371e+06
Train Epoch: 4 [16640/81276 (20%)]	Loss: 10.730800 LR 2.30e-04
	 Magnitude of data 1.274e+06 output 1.345e+02 target 1.274e+06
Train Epoch: 4 [17280/81276 (21%)]	Loss: 10.733864 LR 2.30e-04
	 Magnitude of data 1.443e+06 output 1.335e+02 target 1.442e+06
Train Epoch: 4 [17920/81276 (22%)]	Loss: 10.732726 LR 2.30e-04
	 Magnitude of data 1.267e+06 output 1.323e+02 target 1.266e+06
Train Epoch: 4 [18560/81276 (23%)]	Loss: 10.721170 LR 2.29e-04
	 Magnitude of data 1.246e+06 output 1.313e+02 target 1.246e+06
Train Epoch: 4 [19200/81276 (24%)]	Loss: 10.718701 LR 2.29e-04
	 Magnitude of data 1.254e+06 output 1.305e+02 target 1.254e+06
Train Epoch: 4 [19840/81276 (24%)]	Loss: 10.733781 LR 2.29e-04
	 Magnitude of data 1.331e+06 output 1.297e+02 target 1.331e+06
Train Epoch: 4 [20480/81276 (25%)]	Loss: 10.732942 LR 2.28e-04
	 Magnitude of data 1.190e+06 output 1.289e+02 target 1.190e+06
Train Epoch: 4 [21120/81276 (26%)]	Loss: 10.731963 LR 2.28e-04
	 Magnitude of data 1.290e+06 output 1.284e+02 target 1.290e+06
Train Epoch: 4 [21760/81276 (27%)]	Loss: 10.735359 LR 2.28e-04
	 Magnitude of data 1.386e+06 output 1.277e+02 target 1.385e+06
Train Epoch: 4 [22400/81276 (28%)]	Loss: 10.733724 LR 2.27e-04
	 Magnitude of data 1.271e+06 output 1.271e+02 target 1.271e+06
Train Epoch: 4 [23040/81276 (28%)]	Loss: 10.736399 LR 2.27e-04
	 Magnitude of data 1.259e+06 output 1.264e+02 target 1.259e+06
Train Epoch: 4 [23680/81276 (29%)]	Loss: 10.732472 LR 2.27e-04
	 Magnitude of data 1.231e+06 output 1.258e+02 target 1.231e+06
Train Epoch: 4 [24320/81276 (30%)]	Loss: 10.733959 LR 2.26e-04
	 Magnitude of data 1.323e+06 output 1.254e+02 target 1.322e+06
Train Epoch: 4 [24960/81276 (31%)]	Loss: 10.733565 LR 2.26e-04
	 Magnitude of data 1.341e+06 output 1.249e+02 target 1.341e+06
Train Epoch: 4 [25600/81276 (32%)]	Loss: 10.737034 LR 2.26e-04
	 Magnitude of data 1.299e+06 output 1.245e+02 target 1.299e+06
Train Epoch: 4 [26240/81276 (32%)]	Loss: 10.734381 LR 2.25e-04
	 Magnitude of data 1.329e+06 output 1.242e+02 target 1.329e+06
Train Epoch: 4 [26880/81276 (33%)]	Loss: 10.734151 LR 2.25e-04
	 Magnitude of data 1.258e+06 output 1.240e+02 target 1.258e+06
Train Epoch: 4 [27520/81276 (34%)]	Loss: 10.737120 LR 2.25e-04
	 Magnitude of data 1.280e+06 output 1.236e+02 target 1.280e+06
Train Epoch: 4 [28160/81276 (35%)]	Loss: 10.732274 LR 2.24e-04
	 Magnitude of data 1.353e+06 output 1.235e+02 target 1.353e+06
Train Epoch: 4 [28800/81276 (35%)]	Loss: 10.735246 LR 2.24e-04
	 Magnitude of data 1.316e+06 output 1.232e+02 target 1.316e+06
Train Epoch: 4 [29440/81276 (36%)]	Loss: 10.732028 LR 2.24e-04
	 Magnitude of data 1.295e+06 output 1.229e+02 target 1.295e+06
Train Epoch: 4 [30080/81276 (37%)]	Loss: 10.739289 LR 2.23e-04
	 Magnitude of data 1.290e+06 output 1.227e+02 target 1.290e+06
Train Epoch: 4 [30720/81276 (38%)]	Loss: 10.739320 LR 2.23e-04
	 Magnitude of data 1.320e+06 output 1.224e+02 target 1.320e+06
Train Epoch: 4 [31360/81276 (39%)]	Loss: 10.734746 LR 2.23e-04
	 Magnitude of data 1.397e+06 output 1.222e+02 target 1.397e+06
Train Epoch: 4 [32000/81276 (39%)]	Loss: 10.742258 LR 2.22e-04
	 Magnitude of data 1.283e+06 output 1.219e+02 target 1.283e+06
Train Epoch: 4 [32640/81276 (40%)]	Loss: 10.745159 LR 2.22e-04
	 Magnitude of data 1.354e+06 output 1.218e+02 target 1.354e+06
Train Epoch: 4 [33280/81276 (41%)]	Loss: 10.745224 LR 2.22e-04
	 Magnitude of data 1.271e+06 output 1.216e+02 target 1.271e+06
Train Epoch: 4 [33920/81276 (42%)]	Loss: 10.739570 LR 2.22e-04
	 Magnitude of data 1.296e+06 output 1.212e+02 target 1.296e+06
Train Epoch: 4 [34560/81276 (43%)]	Loss: 10.736019 LR 2.21e-04
	 Magnitude of data 1.312e+06 output 1.209e+02 target 1.312e+06
Train Epoch: 4 [35200/81276 (43%)]	Loss: 10.742886 LR 2.21e-04
	 Magnitude of data 1.383e+06 output 1.207e+02 target 1.383e+06
Train Epoch: 4 [35840/81276 (44%)]	Loss: 10.740653 LR 2.21e-04
	 Magnitude of data 1.314e+06 output 1.204e+02 target 1.314e+06
Train Epoch: 4 [36480/81276 (45%)]	Loss: 10.736155 LR 2.20e-04
	 Magnitude of data 1.359e+06 output 1.202e+02 target 1.359e+06
Train Epoch: 4 [37120/81276 (46%)]	Loss: 10.740011 LR 2.20e-04
	 Magnitude of data 1.273e+06 output 1.200e+02 target 1.273e+06
Train Epoch: 4 [37760/81276 (46%)]	Loss: 10.739793 LR 2.20e-04
	 Magnitude of data 1.261e+06 output 1.198e+02 target 1.261e+06
Train Epoch: 4 [38400/81276 (47%)]	Loss: 10.744526 LR 2.19e-04
	 Magnitude of data 1.358e+06 output 1.196e+02 target 1.358e+06
Train Epoch: 4 [39040/81276 (48%)]	Loss: 10.739366 LR 2.19e-04
	 Magnitude of data 1.339e+06 output 1.194e+02 target 1.339e+06
Train Epoch: 4 [39680/81276 (49%)]	Loss: 10.735363 LR 2.19e-04
	 Magnitude of data 1.233e+06 output 1.193e+02 target 1.233e+06
Train Epoch: 4 [40320/81276 (50%)]	Loss: 10.741570 LR 2.18e-04
	 Magnitude of data 1.395e+06 output 1.192e+02 target 1.395e+06
Train Epoch: 4 [40960/81276 (50%)]	Loss: 10.738362 LR 2.18e-04
	 Magnitude of data 1.324e+06 output 1.191e+02 target 1.324e+06
Train Epoch: 4 [41600/81276 (51%)]	Loss: 10.743481 LR 2.18e-04
	 Magnitude of data 1.367e+06 output 1.190e+02 target 1.367e+06
Train Epoch: 4 [42240/81276 (52%)]	Loss: 10.740737 LR 2.17e-04
	 Magnitude of data 1.301e+06 output 1.188e+02 target 1.301e+06
Train Epoch: 4 [42880/81276 (53%)]	Loss: 10.741581 LR 2.17e-04
	 Magnitude of data 1.223e+06 output 1.188e+02 target 1.223e+06
Train Epoch: 4 [43520/81276 (54%)]	Loss: 10.740050 LR 2.17e-04
	 Magnitude of data 1.285e+06 output 1.186e+02 target 1.285e+06
Train Epoch: 4 [44160/81276 (54%)]	Loss: 10.738663 LR 2.16e-04
	 Magnitude of data 1.281e+06 output 1.184e+02 target 1.281e+06
Train Epoch: 4 [44800/81276 (55%)]	Loss: 10.739894 LR 2.16e-04
	 Magnitude of data 1.413e+06 output 1.184e+02 target 1.413e+06
Train Epoch: 4 [45440/81276 (56%)]	Loss: 10.742408 LR 2.16e-04
	 Magnitude of data 1.310e+06 output 1.184e+02 target 1.310e+06
Train Epoch: 4 [46080/81276 (57%)]	Loss: 10.742250 LR 2.15e-04
	 Magnitude of data 1.308e+06 output 1.184e+02 target 1.308e+06
Train Epoch: 4 [46720/81276 (58%)]	Loss: 10.742458 LR 2.15e-04
	 Magnitude of data 1.370e+06 output 1.183e+02 target 1.371e+06
Train Epoch: 4 [47360/81276 (58%)]	Loss: 10.735374 LR 2.15e-04
	 Magnitude of data 1.361e+06 output 1.182e+02 target 1.361e+06
Train Epoch: 4 [48000/81276 (59%)]	Loss: 10.740370 LR 2.14e-04
	 Magnitude of data 1.285e+06 output 1.181e+02 target 1.286e+06
Train Epoch: 4 [48640/81276 (60%)]	Loss: 10.741498 LR 2.14e-04
	 Magnitude of data 1.249e+06 output 1.181e+02 target 1.249e+06
Train Epoch: 4 [49280/81276 (61%)]	Loss: 10.733253 LR 2.14e-04
	 Magnitude of data 1.305e+06 output 1.180e+02 target 1.305e+06
Train Epoch: 4 [49920/81276 (61%)]	Loss: 10.744672 LR 2.13e-04
	 Magnitude of data 1.259e+06 output 1.179e+02 target 1.259e+06
Train Epoch: 4 [50560/81276 (62%)]	Loss: 10.741169 LR 2.13e-04
	 Magnitude of data 1.274e+06 output 1.178e+02 target 1.273e+06
Train Epoch: 4 [51200/81276 (63%)]	Loss: 10.741235 LR 2.13e-04
	 Magnitude of data 1.319e+06 output 1.178e+02 target 1.319e+06
Train Epoch: 4 [51840/81276 (64%)]	Loss: 10.740297 LR 2.12e-04
	 Magnitude of data 1.351e+06 output 1.178e+02 target 1.351e+06
Train Epoch: 4 [52480/81276 (65%)]	Loss: 10.739495 LR 2.12e-04
	 Magnitude of data 1.318e+06 output 1.177e+02 target 1.318e+06
Train Epoch: 4 [53120/81276 (65%)]	Loss: 10.735079 LR 2.12e-04
	 Magnitude of data 1.274e+06 output 1.176e+02 target 1.274e+06
Train Epoch: 4 [53760/81276 (66%)]	Loss: 10.743924 LR 2.11e-04
	 Magnitude of data 1.363e+06 output 1.176e+02 target 1.363e+06
Train Epoch: 4 [54400/81276 (67%)]	Loss: 10.737945 LR 2.11e-04
	 Magnitude of data 1.305e+06 output 1.174e+02 target 1.305e+06
Train Epoch: 4 [55040/81276 (68%)]	Loss: 10.742707 LR 2.11e-04
	 Magnitude of data 1.319e+06 output 1.174e+02 target 1.318e+06
Train Epoch: 4 [55680/81276 (69%)]	Loss: 10.742826 LR 2.10e-04
	 Magnitude of data 1.197e+06 output 1.174e+02 target 1.197e+06
Train Epoch: 4 [56320/81276 (69%)]	Loss: 10.747665 LR 2.10e-04
	 Magnitude of data 1.373e+06 output 1.174e+02 target 1.373e+06
Train Epoch: 4 [56960/81276 (70%)]	Loss: 10.737559 LR 2.09e-04
	 Magnitude of data 1.323e+06 output 1.173e+02 target 1.323e+06
Train Epoch: 4 [57600/81276 (71%)]	Loss: 10.736828 LR 2.09e-04
	 Magnitude of data 1.223e+06 output 1.173e+02 target 1.223e+06
Train Epoch: 4 [58240/81276 (72%)]	Loss: 10.745929 LR 2.09e-04
	 Magnitude of data 1.344e+06 output 1.173e+02 target 1.344e+06
Train Epoch: 4 [58880/81276 (72%)]	Loss: 10.741404 LR 2.08e-04
	 Magnitude of data 1.282e+06 output 1.173e+02 target 1.282e+06
Train Epoch: 4 [59520/81276 (73%)]	Loss: 10.738658 LR 2.08e-04
	 Magnitude of data 1.214e+06 output 1.173e+02 target 1.214e+06
Train Epoch: 4 [60160/81276 (74%)]	Loss: 10.741868 LR 2.08e-04
	 Magnitude of data 1.322e+06 output 1.172e+02 target 1.323e+06
Train Epoch: 4 [60800/81276 (75%)]	Loss: 10.735492 LR 2.07e-04
	 Magnitude of data 1.290e+06 output 1.171e+02 target 1.290e+06
Train Epoch: 4 [61440/81276 (76%)]	Loss: 10.741644 LR 2.07e-04
	 Magnitude of data 1.354e+06 output 1.172e+02 target 1.354e+06
Train Epoch: 4 [62080/81276 (76%)]	Loss: 10.738291 LR 2.07e-04
	 Magnitude of data 1.348e+06 output 1.172e+02 target 1.348e+06
Train Epoch: 4 [62720/81276 (77%)]	Loss: 10.737211 LR 2.06e-04
	 Magnitude of data 1.358e+06 output 1.172e+02 target 1.358e+06
Train Epoch: 4 [63360/81276 (78%)]	Loss: 10.745395 LR 2.06e-04
	 Magnitude of data 1.367e+06 output 1.173e+02 target 1.367e+06
Train Epoch: 4 [64000/81276 (79%)]	Loss: 10.742642 LR 2.06e-04
	 Magnitude of data 1.341e+06 output 1.172e+02 target 1.341e+06
Train Epoch: 4 [64640/81276 (80%)]	Loss: 10.740800 LR 2.05e-04
	 Magnitude of data 1.274e+06 output 1.172e+02 target 1.274e+06
Train Epoch: 4 [65280/81276 (80%)]	Loss: 10.743898 LR 2.05e-04
	 Magnitude of data 1.638e+06 output 1.172e+02 target 1.638e+06
Train Epoch: 4 [65920/81276 (81%)]	Loss: 10.737090 LR 2.05e-04
	 Magnitude of data 1.178e+06 output 1.172e+02 target 1.178e+06
Train Epoch: 4 [66560/81276 (82%)]	Loss: 10.742299 LR 2.04e-04
	 Magnitude of data 1.313e+06 output 1.172e+02 target 1.313e+06
Train Epoch: 4 [67200/81276 (83%)]	Loss: 10.738578 LR 2.04e-04
	 Magnitude of data 1.305e+06 output 1.171e+02 target 1.305e+06
Train Epoch: 4 [67840/81276 (84%)]	Loss: 10.741452 LR 2.04e-04
	 Magnitude of data 1.243e+06 output 1.170e+02 target 1.243e+06
Train Epoch: 4 [68480/81276 (84%)]	Loss: 10.743934 LR 2.03e-04
	 Magnitude of data 1.389e+06 output 1.169e+02 target 1.389e+06
Train Epoch: 4 [69120/81276 (85%)]	Loss: 10.740426 LR 2.03e-04
	 Magnitude of data 1.368e+06 output 1.169e+02 target 1.368e+06
Train Epoch: 4 [69760/81276 (86%)]	Loss: 10.741446 LR 2.03e-04
	 Magnitude of data 1.272e+06 output 1.169e+02 target 1.272e+06
Train Epoch: 4 [70400/81276 (87%)]	Loss: 10.741298 LR 2.02e-04
	 Magnitude of data 1.307e+06 output 1.170e+02 target 1.307e+06
Train Epoch: 4 [71040/81276 (87%)]	Loss: 10.746881 LR 2.02e-04
	 Magnitude of data 1.298e+06 output 1.170e+02 target 1.298e+06
Train Epoch: 4 [71680/81276 (88%)]	Loss: 10.744034 LR 2.02e-04
	 Magnitude of data 1.285e+06 output 1.170e+02 target 1.285e+06
Train Epoch: 4 [72320/81276 (89%)]	Loss: 10.746927 LR 2.01e-04
	 Magnitude of data 1.372e+06 output 1.170e+02 target 1.372e+06
Train Epoch: 4 [72960/81276 (90%)]	Loss: 10.744514 LR 2.01e-04
	 Magnitude of data 1.268e+06 output 1.170e+02 target 1.268e+06
Train Epoch: 4 [73600/81276 (91%)]	Loss: 10.740597 LR 2.00e-04
	 Magnitude of data 1.248e+06 output 1.169e+02 target 1.248e+06
Train Epoch: 4 [74240/81276 (91%)]	Loss: 10.746574 LR 2.00e-04
	 Magnitude of data 1.344e+06 output 1.169e+02 target 1.344e+06
Train Epoch: 4 [74880/81276 (92%)]	Loss: 10.744019 LR 2.00e-04
	 Magnitude of data 1.405e+06 output 1.168e+02 target 1.405e+06
Train Epoch: 4 [75520/81276 (93%)]	Loss: 10.741957 LR 1.99e-04
	 Magnitude of data 1.326e+06 output 1.168e+02 target 1.326e+06
Train Epoch: 4 [76160/81276 (94%)]	Loss: 10.741847 LR 1.99e-04
	 Magnitude of data 1.291e+06 output 1.168e+02 target 1.291e+06
Train Epoch: 4 [76800/81276 (95%)]	Loss: 10.736558 LR 1.99e-04
	 Magnitude of data 1.338e+06 output 1.167e+02 target 1.338e+06
Train Epoch: 4 [77440/81276 (95%)]	Loss: 10.744784 LR 1.98e-04
	 Magnitude of data 1.279e+06 output 1.166e+02 target 1.279e+06
Train Epoch: 4 [78080/81276 (96%)]	Loss: 10.742292 LR 1.98e-04
	 Magnitude of data 1.287e+06 output 1.165e+02 target 1.287e+06
Train Epoch: 4 [78720/81276 (97%)]	Loss: 10.739705 LR 1.98e-04
	 Magnitude of data 1.253e+06 output 1.164e+02 target 1.253e+06
Train Epoch: 4 [79360/81276 (98%)]	Loss: 10.745988 LR 1.97e-04
	 Magnitude of data 1.327e+06 output 1.164e+02 target 1.327e+06
Train Epoch: 4 [80000/81276 (99%)]	Loss: 10.745421 LR 1.97e-04
	 Magnitude of data 1.478e+06 output 1.163e+02 target 1.478e+06
Train Epoch: 4 [80640/81276 (99%)]	Loss: 10.738977 LR 1.97e-04
	 Magnitude of data 1.218e+06 output 1.162e+02 target 1.218e+06
Train Epoch: 4 [81216/81276 (100%)]	Loss: 10.740879 LR 1.96e-04
Test set: Average loss: 10.74267263

Using GPU Device
Run info rank: 0: Torch version: 2.1.2+cu121 | Device: cuda:0 | Host: cpu
Loading dataset; args.percent_data=0.2
Loaded tensor from ../data/wikipedia.data
1.4 Splitting data into training and validation data
len(train_data)=104035585, len(val_data)=11559510 percent_data=0.2
len(train_data)=20807117, len(val_data)=2311902
-- procs    = 1
-- Tf       = 1.0
-- steps    = 64
-- max_levels     = 1
-- max_bwd_iters  = 1
-- max_fwd_iters  = 3
-- cfactor        = 4
-- fine fcf       = False
-- skip down      = True

args.model_dimension=384 args.num_heads=6 args.batch_size=64
rank 0: len(list(model.parameters())) 1798
rank 0: 152238673
Train Epoch: 1 [0/81276 (0%)]	Loss: 11.000297 LR 6.00e-07
	 Magnitude of data 1.348e+06 output 1.659e+04 target 1.348e+06
Train Epoch: 1 [640/81276 (1%)]	Loss: 11.001570 LR 6.60e-06
	 Magnitude of data 1.314e+06 output 1.659e+04 target 1.314e+06
Train Epoch: 1 [1280/81276 (2%)]	Loss: 10.958560 LR 1.26e-05
	 Magnitude of data 1.495e+06 output 1.658e+04 target 1.495e+06
Train Epoch: 1 [1920/81276 (2%)]	Loss: 10.908924 LR 1.86e-05
	 Magnitude of data 1.218e+06 output 1.656e+04 target 1.218e+06
Train Epoch: 1 [2560/81276 (3%)]	Loss: 10.837632 LR 2.46e-05
	 Magnitude of data 1.281e+06 output 1.654e+04 target 1.281e+06
Train Epoch: 1 [3200/81276 (4%)]	Loss: 10.765270 LR 3.06e-05
	 Magnitude of data 1.317e+06 output 1.653e+04 target 1.317e+06
Train Epoch: 1 [3840/81276 (5%)]	Loss: 10.610252 LR 3.66e-05
	 Magnitude of data 1.281e+06 output 1.657e+04 target 1.281e+06
Train Epoch: 1 [4480/81276 (6%)]	Loss: 10.398030 LR 4.26e-05
	 Magnitude of data 1.306e+06 output 1.685e+04 target 1.306e+06
Train Epoch: 1 [5120/81276 (6%)]	Loss: 10.071461 LR 4.86e-05
	 Magnitude of data 1.360e+06 output 1.800e+04 target 1.360e+06
Train Epoch: 1 [5760/81276 (7%)]	Loss: 9.624011 LR 5.46e-05
	 Magnitude of data 1.349e+06 output 2.108e+04 target 1.350e+06
Train Epoch: 1 [6400/81276 (8%)]	Loss: 9.222480 LR 6.06e-05
	 Magnitude of data 1.285e+06 output 2.562e+04 target 1.286e+06
Train Epoch: 1 [7040/81276 (9%)]	Loss: 8.899377 LR 6.66e-05
	 Magnitude of data 1.278e+06 output 3.061e+04 target 1.278e+06
Train Epoch: 1 [7680/81276 (9%)]	Loss: 8.672702 LR 7.26e-05
	 Magnitude of data 1.419e+06 output 3.573e+04 target 1.419e+06
Train Epoch: 1 [8320/81276 (10%)]	Loss: 8.336191 LR 7.86e-05
	 Magnitude of data 1.234e+06 output 4.103e+04 target 1.234e+06
Train Epoch: 1 [8960/81276 (11%)]	Loss: 8.139885 LR 8.46e-05
	 Magnitude of data 1.348e+06 output 4.645e+04 target 1.348e+06
Train Epoch: 1 [9600/81276 (12%)]	Loss: 7.915929 LR 9.06e-05
	 Magnitude of data 1.364e+06 output 5.180e+04 target 1.364e+06
Train Epoch: 1 [10240/81276 (13%)]	Loss: 7.731067 LR 9.66e-05
	 Magnitude of data 1.276e+06 output 5.683e+04 target 1.276e+06
Train Epoch: 1 [10880/81276 (13%)]	Loss: 7.621864 LR 1.03e-04
	 Magnitude of data 1.240e+06 output 6.166e+04 target 1.240e+06
Train Epoch: 1 [11520/81276 (14%)]	Loss: 7.611521 LR 1.09e-04
	 Magnitude of data 1.342e+06 output 6.610e+04 target 1.342e+06
Train Epoch: 1 [12160/81276 (15%)]	Loss: 7.559079 LR 1.15e-04
	 Magnitude of data 1.359e+06 output 7.012e+04 target 1.359e+06
Train Epoch: 1 [12800/81276 (16%)]	Loss: 7.591040 LR 1.21e-04
	 Magnitude of data 1.366e+06 output 7.381e+04 target 1.366e+06
Train Epoch: 1 [13440/81276 (17%)]	Loss: 7.381582 LR 1.27e-04
	 Magnitude of data 1.241e+06 output 7.704e+04 target 1.241e+06
Train Epoch: 1 [14080/81276 (17%)]	Loss: 7.491861 LR 1.33e-04
	 Magnitude of data 1.396e+06 output 8.003e+04 target 1.396e+06
Train Epoch: 1 [14720/81276 (18%)]	Loss: 7.553064 LR 1.38e-04
	 Magnitude of data 1.450e+06 output 8.212e+04 target 1.450e+06
Train Epoch: 1 [15360/81276 (19%)]	Loss: 7.580011 LR 1.44e-04
	 Magnitude of data 1.387e+06 output 8.338e+04 target 1.387e+06
Train Epoch: 1 [16000/81276 (20%)]	Loss: 7.386733 LR 1.50e-04
	 Magnitude of data 1.371e+06 output 8.208e+04 target 1.371e+06
Train Epoch: 1 [16640/81276 (20%)]	Loss: 7.209365 LR 1.56e-04
	 Magnitude of data 1.274e+06 output 8.378e+04 target 1.274e+06
Train Epoch: 1 [17280/81276 (21%)]	Loss: 7.442654 LR 1.62e-04
	 Magnitude of data 1.443e+06 output 8.565e+04 target 1.442e+06
Train Epoch: 1 [17920/81276 (22%)]	Loss: 7.196042 LR 1.68e-04
	 Magnitude of data 1.267e+06 output 8.648e+04 target 1.266e+06
Train Epoch: 1 [18560/81276 (23%)]	Loss: 6.955260 LR 1.74e-04
	 Magnitude of data 1.246e+06 output 8.823e+04 target 1.246e+06
Train Epoch: 1 [19200/81276 (24%)]	Loss: 6.984302 LR 1.80e-04
	 Magnitude of data 1.254e+06 output 8.998e+04 target 1.254e+06
Train Epoch: 1 [19840/81276 (24%)]	Loss: 7.121830 LR 1.86e-04
	 Magnitude of data 1.331e+06 output 9.254e+04 target 1.331e+06
Train Epoch: 1 [20480/81276 (25%)]	Loss: 7.015836 LR 1.92e-04
	 Magnitude of data 1.190e+06 output 9.403e+04 target 1.190e+06
Train Epoch: 1 [21120/81276 (26%)]	Loss: 7.046392 LR 1.98e-04
	 Magnitude of data 1.290e+06 output 9.339e+04 target 1.290e+06
Train Epoch: 1 [21760/81276 (27%)]	Loss: 7.065679 LR 2.04e-04
	 Magnitude of data 1.386e+06 output 9.578e+04 target 1.385e+06
Train Epoch: 1 [22400/81276 (28%)]	Loss: 6.977764 LR 2.10e-04
	 Magnitude of data 1.271e+06 output 9.765e+04 target 1.271e+06
Train Epoch: 1 [23040/81276 (28%)]	Loss: 7.136286 LR 2.16e-04
	 Magnitude of data 1.259e+06 output 9.794e+04 target 1.259e+06
Train Epoch: 1 [23680/81276 (29%)]	Loss: 6.885018 LR 2.22e-04
	 Magnitude of data 1.231e+06 output 1.020e+05 target 1.231e+06
Train Epoch: 1 [24320/81276 (30%)]	Loss: 7.034361 LR 2.28e-04
	 Magnitude of data 1.323e+06 output 1.017e+05 target 1.322e+06
Train Epoch: 1 [24960/81276 (31%)]	Loss: 6.749408 LR 2.34e-04
	 Magnitude of data 1.341e+06 output 1.013e+05 target 1.341e+06
Train Epoch: 1 [25600/81276 (32%)]	Loss: 6.882391 LR 2.40e-04
	 Magnitude of data 1.299e+06 output 1.038e+05 target 1.299e+06
Train Epoch: 1 [26240/81276 (32%)]	Loss: 6.946612 LR 2.46e-04
	 Magnitude of data 1.329e+06 output 1.053e+05 target 1.329e+06
Train Epoch: 1 [26880/81276 (33%)]	Loss: 6.648930 LR 2.52e-04
	 Magnitude of data 1.258e+06 output 1.054e+05 target 1.258e+06
Train Epoch: 1 [27520/81276 (34%)]	Loss: 6.912121 LR 2.58e-04
	 Magnitude of data 1.280e+06 output 1.078e+05 target 1.280e+06
Train Epoch: 1 [28160/81276 (35%)]	Loss: 6.854144 LR 2.64e-04
	 Magnitude of data 1.353e+06 output 1.062e+05 target 1.353e+06
Train Epoch: 1 [28800/81276 (35%)]	Loss: 6.777551 LR 2.70e-04
	 Magnitude of data 1.316e+06 output 1.096e+05 target 1.316e+06
Train Epoch: 1 [29440/81276 (36%)]	Loss: 6.855207 LR 2.76e-04
	 Magnitude of data 1.295e+06 output 1.071e+05 target 1.295e+06
Train Epoch: 1 [30080/81276 (37%)]	Loss: 6.742744 LR 2.82e-04
	 Magnitude of data 1.290e+06 output 1.117e+05 target 1.290e+06
Train Epoch: 1 [30720/81276 (38%)]	Loss: 6.738142 LR 2.88e-04
	 Magnitude of data 1.320e+06 output 1.118e+05 target 1.320e+06
Train Epoch: 1 [31360/81276 (39%)]	Loss: 6.635828 LR 2.94e-04
	 Magnitude of data 1.397e+06 output 1.124e+05 target 1.397e+06
Train Epoch: 1 [32000/81276 (39%)]	Loss: 6.754933 LR 2.99e-04
	 Magnitude of data 1.283e+06 output 1.174e+05 target 1.283e+06
Train Epoch: 1 [32640/81276 (40%)]	Loss: 6.916127 LR 2.99e-04
	 Magnitude of data 1.354e+06 output 1.123e+05 target 1.354e+06
Train Epoch: 1 [33280/81276 (41%)]	Loss: 6.802367 LR 2.99e-04
	 Magnitude of data 1.271e+06 output 1.154e+05 target 1.271e+06
Train Epoch: 1 [33920/81276 (42%)]	Loss: 6.770691 LR 2.99e-04
	 Magnitude of data 1.296e+06 output 1.211e+05 target 1.296e+06
Train Epoch: 1 [34560/81276 (43%)]	Loss: 6.781398 LR 2.99e-04
	 Magnitude of data 1.312e+06 output 1.175e+05 target 1.312e+06
Train Epoch: 1 [35200/81276 (43%)]	Loss: 7.087855 LR 2.99e-04
	 Magnitude of data 1.383e+06 output 1.171e+05 target 1.383e+06
Train Epoch: 1 [35840/81276 (44%)]	Loss: 6.676589 LR 2.99e-04
	 Magnitude of data 1.314e+06 output 1.171e+05 target 1.314e+06
Train Epoch: 1 [36480/81276 (45%)]	Loss: 6.711506 LR 2.99e-04
	 Magnitude of data 1.359e+06 output 1.161e+05 target 1.359e+06
Train Epoch: 1 [37120/81276 (46%)]	Loss: 6.385591 LR 2.98e-04
	 Magnitude of data 1.273e+06 output 1.200e+05 target 1.273e+06
Train Epoch: 1 [37760/81276 (46%)]	Loss: 6.499678 LR 2.98e-04
	 Magnitude of data 1.261e+06 output 1.219e+05 target 1.261e+06
Train Epoch: 1 [38400/81276 (47%)]	Loss: 6.491542 LR 2.98e-04
	 Magnitude of data 1.358e+06 output 1.223e+05 target 1.358e+06
Train Epoch: 1 [39040/81276 (48%)]	Loss: 6.655676 LR 2.98e-04
	 Magnitude of data 1.339e+06 output 1.276e+05 target 1.339e+06
Train Epoch: 1 [39680/81276 (49%)]	Loss: 6.371920 LR 2.98e-04
	 Magnitude of data 1.233e+06 output 1.245e+05 target 1.233e+06
Train Epoch: 1 [40320/81276 (50%)]	Loss: 6.667771 LR 2.98e-04
	 Magnitude of data 1.395e+06 output 1.232e+05 target 1.395e+06
Train Epoch: 1 [40960/81276 (50%)]	Loss: 6.545071 LR 2.98e-04
	 Magnitude of data 1.324e+06 output 1.262e+05 target 1.324e+06
Train Epoch: 1 [41600/81276 (51%)]	Loss: 6.574328 LR 2.98e-04
	 Magnitude of data 1.367e+06 output 1.247e+05 target 1.367e+06
Train Epoch: 1 [42240/81276 (52%)]	Loss: 6.540384 LR 2.98e-04
	 Magnitude of data 1.301e+06 output 1.324e+05 target 1.301e+06
Train Epoch: 1 [42880/81276 (53%)]	Loss: 6.331112 LR 2.98e-04
	 Magnitude of data 1.223e+06 output 1.322e+05 target 1.223e+06
Train Epoch: 1 [43520/81276 (54%)]	Loss: 6.476568 LR 2.98e-04
	 Magnitude of data 1.285e+06 output 1.313e+05 target 1.285e+06
Train Epoch: 1 [44160/81276 (54%)]	Loss: 6.432666 LR 2.98e-04
	 Magnitude of data 1.281e+06 output 1.345e+05 target 1.281e+06
Train Epoch: 1 [44800/81276 (55%)]	Loss: 6.495416 LR 2.98e-04
	 Magnitude of data 1.413e+06 output 1.324e+05 target 1.413e+06
Train Epoch: 1 [45440/81276 (56%)]	Loss: 6.555288 LR 2.98e-04
	 Magnitude of data 1.310e+06 output 1.353e+05 target 1.310e+06
Train Epoch: 1 [46080/81276 (57%)]	Loss: 6.593937 LR 2.98e-04
	 Magnitude of data 1.308e+06 output 1.371e+05 target 1.308e+06
Train Epoch: 1 [46720/81276 (58%)]	Loss: 6.598519 LR 2.98e-04
	 Magnitude of data 1.370e+06 output 1.382e+05 target 1.371e+06
Train Epoch: 1 [47360/81276 (58%)]	Loss: 6.277420 LR 2.97e-04
	 Magnitude of data 1.361e+06 output 1.343e+05 target 1.361e+06
Train Epoch: 1 [48000/81276 (59%)]	Loss: 6.554468 LR 2.97e-04
	 Magnitude of data 1.285e+06 output 1.427e+05 target 1.286e+06
Train Epoch: 1 [48640/81276 (60%)]	Loss: 6.253662 LR 2.97e-04
	 Magnitude of data 1.249e+06 output 1.379e+05 target 1.249e+06
Train Epoch: 1 [49280/81276 (61%)]	Loss: 6.305235 LR 2.97e-04
	 Magnitude of data 1.305e+06 output 1.358e+05 target 1.305e+06
Train Epoch: 1 [49920/81276 (61%)]	Loss: 6.429410 LR 2.97e-04
	 Magnitude of data 1.259e+06 output 1.372e+05 target 1.259e+06
Train Epoch: 1 [50560/81276 (62%)]	Loss: 6.400743 LR 2.97e-04
	 Magnitude of data 1.274e+06 output 1.428e+05 target 1.273e+06
Train Epoch: 1 [51200/81276 (63%)]	Loss: 6.212516 LR 2.97e-04
	 Magnitude of data 1.319e+06 output 1.388e+05 target 1.319e+06
Train Epoch: 1 [51840/81276 (64%)]	Loss: 6.474098 LR 2.97e-04
	 Magnitude of data 1.351e+06 output 1.482e+05 target 1.351e+06
Train Epoch: 1 [52480/81276 (65%)]	Loss: 6.203918 LR 2.97e-04
	 Magnitude of data 1.318e+06 output 1.472e+05 target 1.318e+06
Train Epoch: 1 [53120/81276 (65%)]	Loss: 6.182240 LR 2.97e-04
	 Magnitude of data 1.274e+06 output 1.403e+05 target 1.274e+06
Train Epoch: 1 [53760/81276 (66%)]	Loss: 6.464972 LR 2.97e-04
	 Magnitude of data 1.363e+06 output 1.422e+05 target 1.363e+06
Train Epoch: 1 [54400/81276 (67%)]	Loss: 6.316763 LR 2.97e-04
	 Magnitude of data 1.305e+06 output 1.491e+05 target 1.305e+06
Train Epoch: 1 [55040/81276 (68%)]	Loss: 6.346484 LR 2.97e-04
	 Magnitude of data 1.319e+06 output 1.447e+05 target 1.318e+06
Train Epoch: 1 [55680/81276 (69%)]	Loss: 6.405077 LR 2.97e-04
	 Magnitude of data 1.197e+06 output 1.486e+05 target 1.197e+06
Train Epoch: 1 [56320/81276 (69%)]	Loss: 6.335690 LR 2.96e-04
	 Magnitude of data 1.373e+06 output 1.477e+05 target 1.373e+06
Train Epoch: 1 [56960/81276 (70%)]	Loss: 6.357270 LR 2.96e-04
	 Magnitude of data 1.323e+06 output 1.466e+05 target 1.323e+06
Train Epoch: 1 [57600/81276 (71%)]	Loss: 6.218350 LR 2.96e-04
	 Magnitude of data 1.223e+06 output 1.508e+05 target 1.223e+06
Train Epoch: 1 [58240/81276 (72%)]	Loss: 6.549314 LR 2.96e-04
	 Magnitude of data 1.344e+06 output 1.477e+05 target 1.344e+06
Train Epoch: 1 [58880/81276 (72%)]	Loss: 6.472033 LR 2.96e-04
	 Magnitude of data 1.282e+06 output 1.523e+05 target 1.282e+06
Train Epoch: 1 [59520/81276 (73%)]	Loss: 6.097585 LR 2.96e-04
	 Magnitude of data 1.214e+06 output 1.507e+05 target 1.214e+06
Train Epoch: 1 [60160/81276 (74%)]	Loss: 6.303273 LR 2.96e-04
	 Magnitude of data 1.322e+06 output 1.553e+05 target 1.323e+06
Train Epoch: 1 [60800/81276 (75%)]	Loss: 6.271457 LR 2.96e-04
	 Magnitude of data 1.290e+06 output 1.571e+05 target 1.290e+06
Train Epoch: 1 [61440/81276 (76%)]	Loss: 6.210306 LR 2.96e-04
	 Magnitude of data 1.354e+06 output 1.537e+05 target 1.354e+06
Train Epoch: 1 [62080/81276 (76%)]	Loss: 6.173406 LR 2.96e-04
	 Magnitude of data 1.348e+06 output 1.546e+05 target 1.348e+06
Train Epoch: 1 [62720/81276 (77%)]	Loss: 6.244112 LR 2.96e-04
	 Magnitude of data 1.358e+06 output 1.548e+05 target 1.358e+06
Train Epoch: 1 [63360/81276 (78%)]	Loss: 6.405899 LR 2.96e-04
	 Magnitude of data 1.367e+06 output 1.520e+05 target 1.367e+06
Train Epoch: 1 [64000/81276 (79%)]	Loss: 6.200529 LR 2.95e-04
	 Magnitude of data 1.341e+06 output 1.535e+05 target 1.341e+06
Train Epoch: 1 [64640/81276 (80%)]	Loss: 6.246120 LR 2.95e-04
	 Magnitude of data 1.274e+06 output 1.575e+05 target 1.274e+06
Train Epoch: 1 [65280/81276 (80%)]	Loss: 6.250388 LR 2.95e-04
	 Magnitude of data 1.638e+06 output 1.538e+05 target 1.638e+06
Train Epoch: 1 [65920/81276 (81%)]	Loss: 6.097524 LR 2.95e-04
	 Magnitude of data 1.178e+06 output 1.589e+05 target 1.178e+06
Train Epoch: 1 [66560/81276 (82%)]	Loss: 6.390790 LR 2.95e-04
	 Magnitude of data 1.313e+06 output 1.607e+05 target 1.313e+06
Train Epoch: 1 [67200/81276 (83%)]	Loss: 6.182854 LR 2.95e-04
	 Magnitude of data 1.305e+06 output 1.565e+05 target 1.305e+06
Train Epoch: 1 [67840/81276 (84%)]	Loss: 5.964142 LR 2.95e-04
	 Magnitude of data 1.243e+06 output 1.564e+05 target 1.243e+06
Train Epoch: 1 [68480/81276 (84%)]	Loss: 6.231231 LR 2.95e-04
	 Magnitude of data 1.389e+06 output 1.589e+05 target 1.389e+06
Train Epoch: 1 [69120/81276 (85%)]	Loss: 6.235589 LR 2.95e-04
	 Magnitude of data 1.368e+06 output 1.621e+05 target 1.368e+06
Train Epoch: 1 [69760/81276 (86%)]	Loss: 6.312523 LR 2.95e-04
	 Magnitude of data 1.272e+06 output 1.695e+05 target 1.272e+06
Train Epoch: 1 [70400/81276 (87%)]	Loss: 6.325824 LR 2.94e-04
	 Magnitude of data 1.307e+06 output 1.609e+05 target 1.307e+06
Train Epoch: 1 [71040/81276 (87%)]	Loss: 6.429801 LR 2.94e-04
	 Magnitude of data 1.298e+06 output 1.596e+05 target 1.298e+06
Train Epoch: 1 [71680/81276 (88%)]	Loss: 6.220290 LR 2.94e-04
	 Magnitude of data 1.285e+06 output 1.597e+05 target 1.285e+06
Train Epoch: 1 [72320/81276 (89%)]	Loss: 6.126511 LR 2.94e-04
	 Magnitude of data 1.372e+06 output 1.585e+05 target 1.372e+06
Train Epoch: 1 [72960/81276 (90%)]	Loss: 6.178488 LR 2.94e-04
	 Magnitude of data 1.268e+06 output 1.596e+05 target 1.268e+06
Train Epoch: 1 [73600/81276 (91%)]	Loss: 6.005323 LR 2.94e-04
	 Magnitude of data 1.248e+06 output 1.643e+05 target 1.248e+06
Train Epoch: 1 [74240/81276 (91%)]	Loss: 6.271489 LR 2.94e-04
	 Magnitude of data 1.344e+06 output 1.643e+05 target 1.344e+06
Train Epoch: 1 [74880/81276 (92%)]	Loss: 6.413559 LR 2.94e-04
	 Magnitude of data 1.405e+06 output 1.625e+05 target 1.405e+06
Train Epoch: 1 [75520/81276 (93%)]	Loss: 6.112968 LR 2.94e-04
	 Magnitude of data 1.326e+06 output 1.633e+05 target 1.326e+06
Train Epoch: 1 [76160/81276 (94%)]	Loss: 6.154326 LR 2.94e-04
	 Magnitude of data 1.291e+06 output 1.644e+05 target 1.291e+06
Train Epoch: 1 [76800/81276 (95%)]	Loss: 6.221911 LR 2.93e-04
	 Magnitude of data 1.338e+06 output 1.607e+05 target 1.338e+06
Train Epoch: 1 [77440/81276 (95%)]	Loss: 6.097938 LR 2.93e-04
	 Magnitude of data 1.279e+06 output 1.684e+05 target 1.279e+06
Train Epoch: 1 [78080/81276 (96%)]	Loss: 6.076981 LR 2.93e-04
	 Magnitude of data 1.287e+06 output 1.646e+05 target 1.287e+06
Train Epoch: 1 [78720/81276 (97%)]	Loss: 6.244526 LR 2.93e-04
	 Magnitude of data 1.253e+06 output 1.629e+05 target 1.253e+06
Train Epoch: 1 [79360/81276 (98%)]	Loss: 6.373504 LR 2.93e-04
	 Magnitude of data 1.327e+06 output 1.619e+05 target 1.327e+06
Train Epoch: 1 [80000/81276 (99%)]	Loss: 6.298745 LR 2.93e-04
	 Magnitude of data 1.478e+06 output 1.639e+05 target 1.478e+06
Train Epoch: 1 [80640/81276 (99%)]	Loss: 6.154070 LR 2.93e-04
	 Magnitude of data 1.218e+06 output 1.690e+05 target 1.218e+06
Train Epoch: 1 [81216/81276 (100%)]	Loss: 5.991057 LR 2.93e-04
Test set: Average loss: 6.13836892
Train Epoch: 2 [0/81276 (0%)]	Loss: 6.229350 LR 2.93e-04
	 Magnitude of data 1.348e+06 output 1.684e+05 target 1.348e+06
Train Epoch: 2 [640/81276 (1%)]	Loss: 6.136390 LR 2.93e-04
	 Magnitude of data 1.314e+06 output 1.715e+05 target 1.314e+06
Train Epoch: 2 [1280/81276 (2%)]	Loss: 6.335653 LR 2.92e-04
	 Magnitude of data 1.495e+06 output 1.674e+05 target 1.495e+06
Train Epoch: 2 [1920/81276 (2%)]	Loss: 6.114331 LR 2.92e-04
	 Magnitude of data 1.218e+06 output 1.691e+05 target 1.218e+06
Train Epoch: 2 [2560/81276 (3%)]	Loss: 5.890012 LR 2.92e-04
	 Magnitude of data 1.281e+06 output 1.636e+05 target 1.281e+06
Train Epoch: 2 [3200/81276 (4%)]	Loss: 5.859919 LR 2.92e-04
	 Magnitude of data 1.317e+06 output 1.691e+05 target 1.317e+06
Train Epoch: 2 [3840/81276 (5%)]	Loss: 5.939348 LR 2.92e-04
	 Magnitude of data 1.281e+06 output 1.707e+05 target 1.281e+06
Train Epoch: 2 [4480/81276 (6%)]	Loss: 5.949585 LR 2.92e-04
	 Magnitude of data 1.306e+06 output 1.749e+05 target 1.306e+06
Train Epoch: 2 [5120/81276 (6%)]	Loss: 6.025861 LR 2.92e-04
	 Magnitude of data 1.360e+06 output 1.771e+05 target 1.360e+06
Train Epoch: 2 [5760/81276 (7%)]	Loss: 6.121513 LR 2.92e-04
	 Magnitude of data 1.349e+06 output 1.683e+05 target 1.350e+06
Train Epoch: 2 [6400/81276 (8%)]	Loss: 6.227272 LR 2.91e-04
	 Magnitude of data 1.285e+06 output 1.667e+05 target 1.286e+06
Train Epoch: 2 [7040/81276 (9%)]	Loss: 6.057205 LR 2.91e-04
	 Magnitude of data 1.278e+06 output 1.657e+05 target 1.278e+06
Train Epoch: 2 [7680/81276 (9%)]	Loss: 6.248921 LR 2.91e-04
	 Magnitude of data 1.419e+06 output 1.566e+05 target 1.419e+06
Train Epoch: 2 [8320/81276 (10%)]	Loss: 6.195685 LR 2.91e-04
	 Magnitude of data 1.234e+06 output 1.615e+05 target 1.234e+06
Train Epoch: 2 [8960/81276 (11%)]	Loss: 6.240075 LR 2.91e-04
	 Magnitude of data 1.348e+06 output 1.663e+05 target 1.348e+06
Train Epoch: 2 [9600/81276 (12%)]	Loss: 6.045743 LR 2.91e-04
	 Magnitude of data 1.364e+06 output 1.645e+05 target 1.364e+06
Train Epoch: 2 [10240/81276 (13%)]	Loss: 6.021912 LR 2.91e-04
	 Magnitude of data 1.276e+06 output 1.687e+05 target 1.276e+06
Train Epoch: 2 [10880/81276 (13%)]	Loss: 5.953364 LR 2.91e-04
	 Magnitude of data 1.240e+06 output 1.790e+05 target 1.240e+06
Train Epoch: 2 [11520/81276 (14%)]	Loss: 6.023431 LR 2.90e-04
	 Magnitude of data 1.342e+06 output 1.651e+05 target 1.342e+06
Train Epoch: 2 [12160/81276 (15%)]	Loss: 6.010510 LR 2.90e-04
	 Magnitude of data 1.359e+06 output 1.737e+05 target 1.359e+06
Train Epoch: 2 [12800/81276 (16%)]	Loss: 6.053351 LR 2.90e-04
	 Magnitude of data 1.366e+06 output 1.732e+05 target 1.366e+06
Train Epoch: 2 [13440/81276 (17%)]	Loss: 5.836605 LR 2.90e-04
	 Magnitude of data 1.241e+06 output 1.764e+05 target 1.241e+06
Train Epoch: 2 [14080/81276 (17%)]	Loss: 6.119021 LR 2.90e-04
	 Magnitude of data 1.396e+06 output 1.749e+05 target 1.396e+06
Train Epoch: 2 [14720/81276 (18%)]	Loss: 6.226210 LR 2.90e-04
	 Magnitude of data 1.450e+06 output 1.712e+05 target 1.450e+06
Train Epoch: 2 [15360/81276 (19%)]	Loss: 6.264869 LR 2.90e-04
	 Magnitude of data 1.387e+06 output 1.729e+05 target 1.387e+06
Train Epoch: 2 [16000/81276 (20%)]	Loss: 6.036662 LR 2.90e-04
	 Magnitude of data 1.371e+06 output 1.709e+05 target 1.371e+06
Train Epoch: 2 [16640/81276 (20%)]	Loss: 5.902967 LR 2.89e-04
	 Magnitude of data 1.274e+06 output 1.783e+05 target 1.274e+06
Train Epoch: 2 [17280/81276 (21%)]	Loss: 6.256012 LR 2.89e-04
	 Magnitude of data 1.443e+06 output 1.724e+05 target 1.442e+06
Train Epoch: 2 [17920/81276 (22%)]	Loss: 6.045478 LR 2.89e-04
	 Magnitude of data 1.267e+06 output 1.722e+05 target 1.266e+06
Train Epoch: 2 [18560/81276 (23%)]	Loss: 5.874504 LR 2.89e-04
	 Magnitude of data 1.246e+06 output 1.789e+05 target 1.246e+06
Train Epoch: 2 [19200/81276 (24%)]	Loss: 5.890590 LR 2.89e-04
	 Magnitude of data 1.254e+06 output 1.814e+05 target 1.254e+06
Train Epoch: 2 [19840/81276 (24%)]	Loss: 5.994924 LR 2.89e-04
	 Magnitude of data 1.331e+06 output 1.762e+05 target 1.331e+06
Train Epoch: 2 [20480/81276 (25%)]	Loss: 5.935919 LR 2.89e-04
	 Magnitude of data 1.190e+06 output 1.727e+05 target 1.190e+06
Train Epoch: 2 [21120/81276 (26%)]	Loss: 6.035060 LR 2.88e-04
	 Magnitude of data 1.290e+06 output 1.710e+05 target 1.290e+06
Train Epoch: 2 [21760/81276 (27%)]	Loss: 5.987401 LR 2.88e-04
	 Magnitude of data 1.386e+06 output 1.694e+05 target 1.385e+06
Train Epoch: 2 [22400/81276 (28%)]	Loss: 5.835855 LR 2.88e-04
	 Magnitude of data 1.271e+06 output 1.771e+05 target 1.271e+06
Train Epoch: 2 [23040/81276 (28%)]	Loss: 6.187941 LR 2.88e-04
	 Magnitude of data 1.259e+06 output 1.687e+05 target 1.259e+06
Train Epoch: 2 [23680/81276 (29%)]	Loss: 5.903300 LR 2.88e-04
	 Magnitude of data 1.231e+06 output 1.826e+05 target 1.231e+06
Train Epoch: 2 [24320/81276 (30%)]	Loss: 6.089054 LR 2.88e-04
	 Magnitude of data 1.323e+06 output 1.810e+05 target 1.322e+06
Train Epoch: 2 [24960/81276 (31%)]	Loss: 5.750144 LR 2.88e-04
	 Magnitude of data 1.341e+06 output 1.746e+05 target 1.341e+06
Train Epoch: 2 [25600/81276 (32%)]	Loss: 5.777354 LR 2.87e-04
	 Magnitude of data 1.299e+06 output 1.762e+05 target 1.299e+06
Train Epoch: 2 [26240/81276 (32%)]	Loss: 6.068061 LR 2.87e-04
	 Magnitude of data 1.329e+06 output 1.788e+05 target 1.329e+06
Train Epoch: 2 [26880/81276 (33%)]	Loss: 5.626262 LR 2.87e-04
	 Magnitude of data 1.258e+06 output 1.781e+05 target 1.258e+06
Train Epoch: 2 [27520/81276 (34%)]	Loss: 5.981132 LR 2.87e-04
	 Magnitude of data 1.280e+06 output 1.784e+05 target 1.280e+06
Train Epoch: 2 [28160/81276 (35%)]	Loss: 5.920585 LR 2.87e-04
	 Magnitude of data 1.353e+06 output 1.745e+05 target 1.353e+06
Train Epoch: 2 [28800/81276 (35%)]	Loss: 5.593237 LR 2.87e-04
	 Magnitude of data 1.316e+06 output 1.798e+05 target 1.316e+06
Train Epoch: 2 [29440/81276 (36%)]	Loss: 5.942052 LR 2.86e-04
	 Magnitude of data 1.295e+06 output 1.727e+05 target 1.295e+06
Train Epoch: 2 [30080/81276 (37%)]	Loss: 5.826237 LR 2.86e-04
	 Magnitude of data 1.290e+06 output 1.784e+05 target 1.290e+06
Train Epoch: 2 [30720/81276 (38%)]	Loss: 5.733945 LR 2.86e-04
	 Magnitude of data 1.320e+06 output 1.749e+05 target 1.320e+06
Train Epoch: 2 [31360/81276 (39%)]	Loss: 5.840178 LR 2.86e-04
	 Magnitude of data 1.397e+06 output 1.730e+05 target 1.397e+06
Train Epoch: 2 [32000/81276 (39%)]	Loss: 5.898362 LR 2.86e-04
	 Magnitude of data 1.283e+06 output 1.765e+05 target 1.283e+06
Train Epoch: 2 [32640/81276 (40%)]	Loss: 6.203885 LR 2.86e-04
	 Magnitude of data 1.354e+06 output 1.709e+05 target 1.354e+06
Train Epoch: 2 [33280/81276 (41%)]	Loss: 5.959819 LR 2.86e-04
	 Magnitude of data 1.271e+06 output 1.775e+05 target 1.271e+06
Train Epoch: 2 [33920/81276 (42%)]	Loss: 5.919775 LR 2.85e-04
	 Magnitude of data 1.296e+06 output 1.787e+05 target 1.296e+06
Train Epoch: 2 [34560/81276 (43%)]	Loss: 5.983925 LR 2.85e-04
	 Magnitude of data 1.312e+06 output 1.775e+05 target 1.312e+06
Train Epoch: 2 [35200/81276 (43%)]	Loss: 6.339251 LR 2.85e-04
	 Magnitude of data 1.383e+06 output 1.674e+05 target 1.383e+06
Train Epoch: 2 [35840/81276 (44%)]	Loss: 5.881566 LR 2.85e-04
	 Magnitude of data 1.314e+06 output 1.796e+05 target 1.314e+06
Train Epoch: 2 [36480/81276 (45%)]	Loss: 5.961956 LR 2.85e-04
	 Magnitude of data 1.359e+06 output 1.768e+05 target 1.359e+06
Train Epoch: 2 [37120/81276 (46%)]	Loss: 5.486843 LR 2.85e-04
	 Magnitude of data 1.273e+06 output 1.788e+05 target 1.273e+06
Train Epoch: 2 [37760/81276 (46%)]	Loss: 5.681805 LR 2.84e-04
	 Magnitude of data 1.261e+06 output 1.746e+05 target 1.261e+06
Train Epoch: 2 [38400/81276 (47%)]	Loss: 5.564705 LR 2.84e-04
	 Magnitude of data 1.358e+06 output 1.777e+05 target 1.358e+06
Train Epoch: 2 [39040/81276 (48%)]	Loss: 5.865942 LR 2.84e-04
	 Magnitude of data 1.339e+06 output 1.845e+05 target 1.339e+06
Train Epoch: 2 [39680/81276 (49%)]	Loss: 5.630411 LR 2.84e-04
	 Magnitude of data 1.233e+06 output 1.823e+05 target 1.233e+06
Train Epoch: 2 [40320/81276 (50%)]	Loss: 5.828959 LR 2.84e-04
	 Magnitude of data 1.395e+06 output 1.731e+05 target 1.395e+06
Train Epoch: 2 [40960/81276 (50%)]	Loss: 5.749835 LR 2.84e-04
	 Magnitude of data 1.324e+06 output 1.781e+05 target 1.324e+06
Train Epoch: 2 [41600/81276 (51%)]	Loss: 5.809244 LR 2.83e-04
	 Magnitude of data 1.367e+06 output 1.675e+05 target 1.367e+06
Train Epoch: 2 [42240/81276 (52%)]	Loss: 5.815694 LR 2.83e-04
	 Magnitude of data 1.301e+06 output 1.748e+05 target 1.301e+06
Train Epoch: 2 [42880/81276 (53%)]	Loss: 5.482779 LR 2.83e-04
	 Magnitude of data 1.223e+06 output 1.781e+05 target 1.223e+06
Train Epoch: 2 [43520/81276 (54%)]	Loss: 5.780790 LR 2.83e-04
	 Magnitude of data 1.285e+06 output 1.670e+05 target 1.285e+06
Train Epoch: 2 [44160/81276 (54%)]	Loss: 5.711448 LR 2.83e-04
	 Magnitude of data 1.281e+06 output 1.813e+05 target 1.281e+06
Train Epoch: 2 [44800/81276 (55%)]	Loss: 5.663077 LR 2.83e-04
	 Magnitude of data 1.413e+06 output 1.784e+05 target 1.413e+06
Train Epoch: 2 [45440/81276 (56%)]	Loss: 5.821320 LR 2.82e-04
	 Magnitude of data 1.310e+06 output 1.764e+05 target 1.310e+06
Train Epoch: 2 [46080/81276 (57%)]	Loss: 5.941608 LR 2.82e-04
	 Magnitude of data 1.308e+06 output 1.805e+05 target 1.308e+06
Train Epoch: 2 [46720/81276 (58%)]	Loss: 5.907357 LR 2.82e-04
	 Magnitude of data 1.370e+06 output 1.801e+05 target 1.371e+06
Train Epoch: 2 [47360/81276 (58%)]	Loss: 5.575760 LR 2.82e-04
	 Magnitude of data 1.361e+06 output 1.784e+05 target 1.361e+06
Train Epoch: 2 [48000/81276 (59%)]	Loss: 5.886695 LR 2.82e-04
	 Magnitude of data 1.285e+06 output 1.751e+05 target 1.286e+06
Train Epoch: 2 [48640/81276 (60%)]	Loss: 5.556528 LR 2.81e-04
	 Magnitude of data 1.249e+06 output 1.797e+05 target 1.249e+06
Train Epoch: 2 [49280/81276 (61%)]	Loss: 5.672276 LR 2.81e-04
	 Magnitude of data 1.305e+06 output 1.776e+05 target 1.305e+06
Train Epoch: 2 [49920/81276 (61%)]	Loss: 5.678793 LR 2.81e-04
	 Magnitude of data 1.259e+06 output 1.721e+05 target 1.259e+06
Train Epoch: 2 [50560/81276 (62%)]	Loss: 5.760123 LR 2.81e-04
	 Magnitude of data 1.274e+06 output 1.784e+05 target 1.273e+06
Train Epoch: 2 [51200/81276 (63%)]	Loss: 5.529813 LR 2.81e-04
	 Magnitude of data 1.319e+06 output 1.859e+05 target 1.319e+06
Train Epoch: 2 [51840/81276 (64%)]	Loss: 5.768664 LR 2.81e-04
	 Magnitude of data 1.351e+06 output 1.832e+05 target 1.351e+06
Train Epoch: 2 [52480/81276 (65%)]	Loss: 5.494857 LR 2.80e-04
	 Magnitude of data 1.318e+06 output 1.823e+05 target 1.318e+06
Train Epoch: 2 [53120/81276 (65%)]	Loss: 5.496064 LR 2.80e-04
	 Magnitude of data 1.274e+06 output 1.810e+05 target 1.274e+06
Train Epoch: 2 [53760/81276 (66%)]	Loss: 5.810441 LR 2.80e-04
	 Magnitude of data 1.363e+06 output 1.758e+05 target 1.363e+06
Train Epoch: 2 [54400/81276 (67%)]	Loss: 5.655042 LR 2.80e-04
	 Magnitude of data 1.305e+06 output 1.769e+05 target 1.305e+06
Train Epoch: 2 [55040/81276 (68%)]	Loss: 5.697689 LR 2.80e-04
	 Magnitude of data 1.319e+06 output 1.841e+05 target 1.318e+06
Train Epoch: 2 [55680/81276 (69%)]	Loss: 5.823499 LR 2.79e-04
	 Magnitude of data 1.197e+06 output 1.807e+05 target 1.197e+06
Train Epoch: 2 [56320/81276 (69%)]	Loss: 5.640737 LR 2.79e-04
	 Magnitude of data 1.373e+06 output 1.784e+05 target 1.373e+06
Train Epoch: 2 [56960/81276 (70%)]	Loss: 5.711598 LR 2.79e-04
	 Magnitude of data 1.323e+06 output 1.749e+05 target 1.323e+06
Train Epoch: 2 [57600/81276 (71%)]	Loss: 5.556742 LR 2.79e-04
	 Magnitude of data 1.223e+06 output 1.798e+05 target 1.223e+06
Train Epoch: 2 [58240/81276 (72%)]	Loss: 5.895230 LR 2.79e-04
	 Magnitude of data 1.344e+06 output 1.692e+05 target 1.344e+06
Train Epoch: 2 [58880/81276 (72%)]	Loss: 5.816491 LR 2.78e-04
	 Magnitude of data 1.282e+06 output 1.691e+05 target 1.282e+06
Train Epoch: 2 [59520/81276 (73%)]	Loss: 5.482045 LR 2.78e-04
	 Magnitude of data 1.214e+06 output 1.844e+05 target 1.214e+06
Train Epoch: 2 [60160/81276 (74%)]	Loss: 5.720106 LR 2.78e-04
	 Magnitude of data 1.322e+06 output 1.837e+05 target 1.323e+06
Train Epoch: 2 [60800/81276 (75%)]	Loss: 5.661491 LR 2.78e-04
	 Magnitude of data 1.290e+06 output 1.808e+05 target 1.290e+06
Train Epoch: 2 [61440/81276 (76%)]	Loss: 5.524546 LR 2.78e-04
	 Magnitude of data 1.354e+06 output 1.750e+05 target 1.354e+06
Train Epoch: 2 [62080/81276 (76%)]	Loss: 5.495194 LR 2.78e-04
	 Magnitude of data 1.348e+06 output 1.856e+05 target 1.348e+06
Train Epoch: 2 [62720/81276 (77%)]	Loss: 5.653668 LR 2.77e-04
	 Magnitude of data 1.358e+06 output 1.807e+05 target 1.358e+06
Train Epoch: 2 [63360/81276 (78%)]	Loss: 5.781325 LR 2.77e-04
	 Magnitude of data 1.367e+06 output 1.710e+05 target 1.367e+06
Train Epoch: 2 [64000/81276 (79%)]	Loss: 5.482401 LR 2.77e-04
	 Magnitude of data 1.341e+06 output 1.713e+05 target 1.341e+06
Train Epoch: 2 [64640/81276 (80%)]	Loss: 5.754410 LR 2.77e-04
	 Magnitude of data 1.274e+06 output 1.759e+05 target 1.274e+06
Train Epoch: 2 [65280/81276 (80%)]	Loss: 5.486739 LR 2.77e-04
	 Magnitude of data 1.638e+06 output 1.833e+05 target 1.638e+06
Train Epoch: 2 [65920/81276 (81%)]	Loss: 5.486912 LR 2.76e-04
	 Magnitude of data 1.178e+06 output 1.846e+05 target 1.178e+06
Train Epoch: 2 [66560/81276 (82%)]	Loss: 5.800543 LR 2.76e-04
	 Magnitude of data 1.313e+06 output 1.761e+05 target 1.313e+06
Train Epoch: 2 [67200/81276 (83%)]	Loss: 5.619900 LR 2.76e-04
	 Magnitude of data 1.305e+06 output 1.799e+05 target 1.305e+06
Train Epoch: 2 [67840/81276 (84%)]	Loss: 5.373331 LR 2.76e-04
	 Magnitude of data 1.243e+06 output 1.740e+05 target 1.243e+06
Train Epoch: 2 [68480/81276 (84%)]	Loss: 5.605277 LR 2.76e-04
	 Magnitude of data 1.389e+06 output 1.801e+05 target 1.389e+06
Train Epoch: 2 [69120/81276 (85%)]	Loss: 5.661912 LR 2.75e-04
	 Magnitude of data 1.368e+06 output 1.817e+05 target 1.368e+06
Train Epoch: 2 [69760/81276 (86%)]	Loss: 5.766491 LR 2.75e-04
	 Magnitude of data 1.272e+06 output 1.811e+05 target 1.272e+06
Train Epoch: 2 [70400/81276 (87%)]	Loss: 5.783925 LR 2.75e-04
	 Magnitude of data 1.307e+06 output 1.759e+05 target 1.307e+06
Train Epoch: 2 [71040/81276 (87%)]	Loss: 5.863088 LR 2.75e-04
	 Magnitude of data 1.298e+06 output 1.724e+05 target 1.298e+06
Train Epoch: 2 [71680/81276 (88%)]	Loss: 5.663259 LR 2.75e-04
	 Magnitude of data 1.285e+06 output 1.773e+05 target 1.285e+06
Train Epoch: 2 [72320/81276 (89%)]	Loss: 5.520210 LR 2.74e-04
	 Magnitude of data 1.372e+06 output 1.768e+05 target 1.372e+06
Train Epoch: 2 [72960/81276 (90%)]	Loss: 5.656121 LR 2.74e-04
	 Magnitude of data 1.268e+06 output 1.777e+05 target 1.268e+06
Train Epoch: 2 [73600/81276 (91%)]	Loss: 5.451934 LR 2.74e-04
	 Magnitude of data 1.248e+06 output 1.781e+05 target 1.248e+06
Train Epoch: 2 [74240/81276 (91%)]	Loss: 5.734164 LR 2.74e-04
	 Magnitude of data 1.344e+06 output 1.762e+05 target 1.344e+06
Train Epoch: 2 [74880/81276 (92%)]	Loss: 5.880718 LR 2.73e-04
	 Magnitude of data 1.405e+06 output 1.767e+05 target 1.405e+06
Train Epoch: 2 [75520/81276 (93%)]	Loss: 5.568239 LR 2.73e-04
	 Magnitude of data 1.326e+06 output 1.746e+05 target 1.326e+06
Train Epoch: 2 [76160/81276 (94%)]	Loss: 5.600364 LR 2.73e-04
	 Magnitude of data 1.291e+06 output 1.763e+05 target 1.291e+06
Train Epoch: 2 [76800/81276 (95%)]	Loss: 5.654350 LR 2.73e-04
	 Magnitude of data 1.338e+06 output 1.703e+05 target 1.338e+06
Train Epoch: 2 [77440/81276 (95%)]	Loss: 5.540039 LR 2.73e-04
	 Magnitude of data 1.279e+06 output 1.792e+05 target 1.279e+06
Train Epoch: 2 [78080/81276 (96%)]	Loss: 5.493296 LR 2.72e-04
	 Magnitude of data 1.287e+06 output 1.760e+05 target 1.287e+06
Train Epoch: 2 [78720/81276 (97%)]	Loss: 5.648314 LR 2.72e-04
	 Magnitude of data 1.253e+06 output 1.810e+05 target 1.253e+06
Train Epoch: 2 [79360/81276 (98%)]	Loss: 5.866598 LR 2.72e-04
	 Magnitude of data 1.327e+06 output 1.756e+05 target 1.327e+06
Train Epoch: 2 [80000/81276 (99%)]	Loss: 5.701921 LR 2.72e-04
	 Magnitude of data 1.478e+06 output 1.766e+05 target 1.478e+06
Train Epoch: 2 [80640/81276 (99%)]	Loss: 5.613349 LR 2.72e-04
	 Magnitude of data 1.218e+06 output 1.802e+05 target 1.218e+06
Train Epoch: 2 [81216/81276 (100%)]	Loss: 5.393001 LR 2.71e-04
Test set: Average loss: 5.65370664
Train Epoch: 3 [0/81276 (0%)]	Loss: 5.713299 LR 2.71e-04
	 Magnitude of data 1.348e+06 output 1.774e+05 target 1.348e+06
Train Epoch: 3 [640/81276 (1%)]	Loss: 5.597513 LR 2.71e-04
	 Magnitude of data 1.314e+06 output 1.832e+05 target 1.314e+06
Train Epoch: 3 [1280/81276 (2%)]	Loss: 5.828338 LR 2.71e-04
	 Magnitude of data 1.495e+06 output 1.761e+05 target 1.495e+06
Train Epoch: 3 [1920/81276 (2%)]	Loss: 5.618739 LR 2.71e-04
	 Magnitude of data 1.218e+06 output 1.852e+05 target 1.218e+06
Train Epoch: 3 [2560/81276 (3%)]	Loss: 5.327096 LR 2.70e-04
	 Magnitude of data 1.281e+06 output 1.770e+05 target 1.281e+06
Train Epoch: 3 [3200/81276 (4%)]	Loss: 5.294137 LR 2.70e-04
	 Magnitude of data 1.317e+06 output 1.812e+05 target 1.317e+06
Train Epoch: 3 [3840/81276 (5%)]	Loss: 5.373596 LR 2.70e-04
	 Magnitude of data 1.281e+06 output 1.823e+05 target 1.281e+06
Train Epoch: 3 [4480/81276 (6%)]	Loss: 5.425183 LR 2.70e-04
	 Magnitude of data 1.306e+06 output 1.863e+05 target 1.306e+06
Train Epoch: 3 [5120/81276 (6%)]	Loss: 5.480812 LR 2.70e-04
	 Magnitude of data 1.360e+06 output 1.835e+05 target 1.360e+06
Train Epoch: 3 [5760/81276 (7%)]	Loss: 5.651468 LR 2.69e-04
	 Magnitude of data 1.349e+06 output 1.809e+05 target 1.350e+06
Train Epoch: 3 [6400/81276 (8%)]	Loss: 5.687157 LR 2.69e-04
	 Magnitude of data 1.285e+06 output 1.816e+05 target 1.286e+06
Train Epoch: 3 [7040/81276 (9%)]	Loss: 5.549905 LR 2.69e-04
	 Magnitude of data 1.278e+06 output 1.778e+05 target 1.278e+06
Train Epoch: 3 [7680/81276 (9%)]	Loss: 5.691303 LR 2.69e-04
	 Magnitude of data 1.419e+06 output 1.681e+05 target 1.419e+06
Train Epoch: 3 [8320/81276 (10%)]	Loss: 5.740237 LR 2.68e-04
	 Magnitude of data 1.234e+06 output 1.662e+05 target 1.234e+06
Train Epoch: 3 [8960/81276 (11%)]	Loss: 5.765171 LR 2.68e-04
	 Magnitude of data 1.348e+06 output 1.751e+05 target 1.348e+06
Train Epoch: 3 [9600/81276 (12%)]	Loss: 5.567267 LR 2.68e-04
	 Magnitude of data 1.364e+06 output 1.744e+05 target 1.364e+06
Train Epoch: 3 [10240/81276 (13%)]	Loss: 5.525222 LR 2.68e-04
	 Magnitude of data 1.276e+06 output 1.760e+05 target 1.276e+06
Train Epoch: 3 [10880/81276 (13%)]	Loss: 5.417128 LR 2.68e-04
	 Magnitude of data 1.240e+06 output 1.837e+05 target 1.240e+06
Train Epoch: 3 [11520/81276 (14%)]	Loss: 5.519400 LR 2.67e-04
	 Magnitude of data 1.342e+06 output 1.747e+05 target 1.342e+06
Train Epoch: 3 [12160/81276 (15%)]	Loss: 5.457578 LR 2.67e-04
	 Magnitude of data 1.359e+06 output 1.816e+05 target 1.359e+06
Train Epoch: 3 [12800/81276 (16%)]	Loss: 5.563138 LR 2.67e-04
	 Magnitude of data 1.366e+06 output 1.834e+05 target 1.366e+06
Train Epoch: 3 [13440/81276 (17%)]	Loss: 5.315308 LR 2.67e-04
	 Magnitude of data 1.241e+06 output 1.851e+05 target 1.241e+06
Train Epoch: 3 [14080/81276 (17%)]	Loss: 5.653251 LR 2.66e-04
	 Magnitude of data 1.396e+06 output 1.823e+05 target 1.396e+06
Train Epoch: 3 [14720/81276 (18%)]	Loss: 5.745442 LR 2.66e-04
	 Magnitude of data 1.450e+06 output 1.810e+05 target 1.450e+06
Train Epoch: 3 [15360/81276 (19%)]	Loss: 5.752574 LR 2.66e-04
	 Magnitude of data 1.387e+06 output 1.783e+05 target 1.387e+06
Train Epoch: 3 [16000/81276 (20%)]	Loss: 5.515956 LR 2.66e-04
	 Magnitude of data 1.371e+06 output 1.794e+05 target 1.371e+06
Train Epoch: 3 [16640/81276 (20%)]	Loss: 5.431105 LR 2.65e-04
	 Magnitude of data 1.274e+06 output 1.811e+05 target 1.274e+06
Train Epoch: 3 [17280/81276 (21%)]	Loss: 5.731315 LR 2.65e-04
	 Magnitude of data 1.443e+06 output 1.757e+05 target 1.442e+06
Train Epoch: 3 [17920/81276 (22%)]	Loss: 5.581306 LR 2.65e-04
	 Magnitude of data 1.267e+06 output 1.792e+05 target 1.266e+06
Train Epoch: 3 [18560/81276 (23%)]	Loss: 5.488863 LR 2.65e-04
	 Magnitude of data 1.246e+06 output 1.875e+05 target 1.246e+06
Train Epoch: 3 [19200/81276 (24%)]	Loss: 5.365416 LR 2.64e-04
	 Magnitude of data 1.254e+06 output 1.861e+05 target 1.254e+06
Train Epoch: 3 [19840/81276 (24%)]	Loss: 5.463918 LR 2.64e-04
	 Magnitude of data 1.331e+06 output 1.826e+05 target 1.331e+06
Train Epoch: 3 [20480/81276 (25%)]	Loss: 5.362364 LR 2.64e-04
	 Magnitude of data 1.190e+06 output 1.764e+05 target 1.190e+06
Train Epoch: 3 [21120/81276 (26%)]	Loss: 5.627553 LR 2.64e-04
	 Magnitude of data 1.290e+06 output 1.758e+05 target 1.290e+06
Train Epoch: 3 [21760/81276 (27%)]	Loss: 5.484382 LR 2.63e-04
	 Magnitude of data 1.386e+06 output 1.762e+05 target 1.385e+06
Train Epoch: 3 [22400/81276 (28%)]	Loss: 5.333141 LR 2.63e-04
	 Magnitude of data 1.271e+06 output 1.898e+05 target 1.271e+06
Train Epoch: 3 [23040/81276 (28%)]	Loss: 5.774202 LR 2.63e-04
	 Magnitude of data 1.259e+06 output 1.743e+05 target 1.259e+06
Train Epoch: 3 [23680/81276 (29%)]	Loss: 5.433028 LR 2.63e-04
	 Magnitude of data 1.231e+06 output 1.858e+05 target 1.231e+06
Train Epoch: 3 [24320/81276 (30%)]	Loss: 5.671783 LR 2.63e-04
	 Magnitude of data 1.323e+06 output 1.885e+05 target 1.322e+06
Train Epoch: 3 [24960/81276 (31%)]	Loss: 5.330178 LR 2.62e-04
	 Magnitude of data 1.341e+06 output 1.860e+05 target 1.341e+06
Train Epoch: 3 [25600/81276 (32%)]	Loss: 5.309593 LR 2.62e-04
	 Magnitude of data 1.299e+06 output 1.853e+05 target 1.299e+06
Train Epoch: 3 [26240/81276 (32%)]	Loss: 5.666090 LR 2.62e-04
	 Magnitude of data 1.329e+06 output 1.876e+05 target 1.329e+06
Train Epoch: 3 [26880/81276 (33%)]	Loss: 5.144105 LR 2.62e-04
	 Magnitude of data 1.258e+06 output 1.834e+05 target 1.258e+06
Train Epoch: 3 [27520/81276 (34%)]	Loss: 5.533903 LR 2.61e-04
	 Magnitude of data 1.280e+06 output 1.867e+05 target 1.280e+06
Train Epoch: 3 [28160/81276 (35%)]	Loss: 5.454961 LR 2.61e-04
	 Magnitude of data 1.353e+06 output 1.822e+05 target 1.353e+06
Train Epoch: 3 [28800/81276 (35%)]	Loss: 5.004562 LR 2.61e-04
	 Magnitude of data 1.316e+06 output 1.865e+05 target 1.316e+06
Train Epoch: 3 [29440/81276 (36%)]	Loss: 5.525171 LR 2.61e-04
	 Magnitude of data 1.295e+06 output 1.771e+05 target 1.295e+06
Train Epoch: 3 [30080/81276 (37%)]	Loss: 5.340756 LR 2.60e-04
	 Magnitude of data 1.290e+06 output 1.828e+05 target 1.290e+06
Train Epoch: 3 [30720/81276 (38%)]	Loss: 5.272707 LR 2.60e-04
	 Magnitude of data 1.320e+06 output 1.838e+05 target 1.320e+06
Train Epoch: 3 [31360/81276 (39%)]	Loss: 5.443530 LR 2.60e-04
	 Magnitude of data 1.397e+06 output 1.807e+05 target 1.397e+06
Train Epoch: 3 [32000/81276 (39%)]	Loss: 5.461943 LR 2.60e-04
	 Magnitude of data 1.283e+06 output 1.784e+05 target 1.283e+06
Train Epoch: 3 [32640/81276 (40%)]	Loss: 5.802177 LR 2.59e-04
	 Magnitude of data 1.354e+06 output 1.743e+05 target 1.354e+06
Train Epoch: 3 [33280/81276 (41%)]	Loss: 5.546624 LR 2.59e-04
	 Magnitude of data 1.271e+06 output 1.804e+05 target 1.271e+06
Train Epoch: 3 [33920/81276 (42%)]	Loss: 5.487724 LR 2.59e-04
	 Magnitude of data 1.296e+06 output 1.835e+05 target 1.296e+06
Train Epoch: 3 [34560/81276 (43%)]	Loss: 5.567575 LR 2.58e-04
	 Magnitude of data 1.312e+06 output 1.822e+05 target 1.312e+06
Train Epoch: 3 [35200/81276 (43%)]	Loss: 5.951675 LR 2.58e-04
	 Magnitude of data 1.383e+06 output 1.711e+05 target 1.383e+06
Train Epoch: 3 [35840/81276 (44%)]	Loss: 5.503350 LR 2.58e-04
	 Magnitude of data 1.314e+06 output 1.833e+05 target 1.314e+06
Train Epoch: 3 [36480/81276 (45%)]	Loss: 5.541425 LR 2.58e-04
	 Magnitude of data 1.359e+06 output 1.832e+05 target 1.359e+06
Train Epoch: 3 [37120/81276 (46%)]	Loss: 5.054106 LR 2.57e-04
	 Magnitude of data 1.273e+06 output 1.901e+05 target 1.273e+06
Train Epoch: 3 [37760/81276 (46%)]	Loss: 5.252465 LR 2.57e-04
	 Magnitude of data 1.261e+06 output 1.817e+05 target 1.261e+06
Train Epoch: 3 [38400/81276 (47%)]	Loss: 5.151810 LR 2.57e-04
	 Magnitude of data 1.358e+06 output 1.858e+05 target 1.358e+06
Train Epoch: 3 [39040/81276 (48%)]	Loss: 5.421840 LR 2.57e-04
	 Magnitude of data 1.339e+06 output 1.850e+05 target 1.339e+06
Train Epoch: 3 [39680/81276 (49%)]	Loss: 5.181236 LR 2.56e-04
	 Magnitude of data 1.233e+06 output 1.855e+05 target 1.233e+06
Train Epoch: 3 [40320/81276 (50%)]	Loss: 5.384218 LR 2.56e-04
	 Magnitude of data 1.395e+06 output 1.823e+05 target 1.395e+06
Train Epoch: 3 [40960/81276 (50%)]	Loss: 5.314686 LR 2.56e-04
	 Magnitude of data 1.324e+06 output 1.836e+05 target 1.324e+06
Train Epoch: 3 [41600/81276 (51%)]	Loss: 5.421593 LR 2.56e-04
	 Magnitude of data 1.367e+06 output 1.760e+05 target 1.367e+06
Train Epoch: 3 [42240/81276 (52%)]	Loss: 5.414898 LR 2.55e-04
	 Magnitude of data 1.301e+06 output 1.815e+05 target 1.301e+06
Train Epoch: 3 [42880/81276 (53%)]	Loss: 5.021812 LR 2.55e-04
	 Magnitude of data 1.223e+06 output 1.819e+05 target 1.223e+06
Train Epoch: 3 [43520/81276 (54%)]	Loss: 5.406670 LR 2.55e-04
	 Magnitude of data 1.285e+06 output 1.749e+05 target 1.285e+06
Train Epoch: 3 [44160/81276 (54%)]	Loss: 5.321601 LR 2.55e-04
	 Magnitude of data 1.281e+06 output 1.886e+05 target 1.281e+06
Train Epoch: 3 [44800/81276 (55%)]	Loss: 5.203362 LR 2.54e-04
	 Magnitude of data 1.413e+06 output 1.916e+05 target 1.413e+06
Train Epoch: 3 [45440/81276 (56%)]	Loss: 5.421552 LR 2.54e-04
	 Magnitude of data 1.310e+06 output 1.825e+05 target 1.310e+06
Train Epoch: 3 [46080/81276 (57%)]	Loss: 5.564295 LR 2.54e-04
	 Magnitude of data 1.308e+06 output 1.840e+05 target 1.308e+06
Train Epoch: 3 [46720/81276 (58%)]	Loss: 5.528451 LR 2.54e-04
	 Magnitude of data 1.370e+06 output 1.867e+05 target 1.371e+06
Train Epoch: 3 [47360/81276 (58%)]	Loss: 5.211691 LR 2.53e-04
	 Magnitude of data 1.361e+06 output 1.886e+05 target 1.361e+06
Train Epoch: 3 [48000/81276 (59%)]	Loss: 5.543903 LR 2.53e-04
	 Magnitude of data 1.285e+06 output 1.785e+05 target 1.286e+06
Train Epoch: 3 [48640/81276 (60%)]	Loss: 5.174584 LR 2.53e-04
	 Magnitude of data 1.249e+06 output 1.879e+05 target 1.249e+06
Train Epoch: 3 [49280/81276 (61%)]	Loss: 5.298722 LR 2.52e-04
	 Magnitude of data 1.305e+06 output 1.880e+05 target 1.305e+06
Train Epoch: 3 [49920/81276 (61%)]	Loss: 5.267150 LR 2.52e-04
	 Magnitude of data 1.259e+06 output 1.784e+05 target 1.259e+06
Train Epoch: 3 [50560/81276 (62%)]	Loss: 5.371320 LR 2.52e-04
	 Magnitude of data 1.274e+06 output 1.837e+05 target 1.273e+06
Train Epoch: 3 [51200/81276 (63%)]	Loss: 5.171575 LR 2.52e-04
	 Magnitude of data 1.319e+06 output 1.952e+05 target 1.319e+06
Train Epoch: 3 [51840/81276 (64%)]	Loss: 5.349884 LR 2.51e-04
	 Magnitude of data 1.351e+06 output 1.895e+05 target 1.351e+06
Train Epoch: 3 [52480/81276 (65%)]	Loss: 5.085929 LR 2.51e-04
	 Magnitude of data 1.318e+06 output 1.881e+05 target 1.318e+06
Train Epoch: 3 [53120/81276 (65%)]	Loss: 5.112071 LR 2.51e-04
	 Magnitude of data 1.274e+06 output 1.860e+05 target 1.274e+06
Train Epoch: 3 [53760/81276 (66%)]	Loss: 5.410474 LR 2.51e-04
	 Magnitude of data 1.363e+06 output 1.812e+05 target 1.363e+06
Train Epoch: 3 [54400/81276 (67%)]	Loss: 5.263713 LR 2.50e-04
	 Magnitude of data 1.305e+06 output 1.843e+05 target 1.305e+06
Train Epoch: 3 [55040/81276 (68%)]	Loss: 5.316851 LR 2.50e-04
	 Magnitude of data 1.319e+06 output 1.865e+05 target 1.318e+06
Train Epoch: 3 [55680/81276 (69%)]	Loss: 5.459761 LR 2.50e-04
	 Magnitude of data 1.197e+06 output 1.857e+05 target 1.197e+06
Train Epoch: 3 [56320/81276 (69%)]	Loss: 5.256989 LR 2.49e-04
	 Magnitude of data 1.373e+06 output 1.821e+05 target 1.373e+06
Train Epoch: 3 [56960/81276 (70%)]	Loss: 5.358816 LR 2.49e-04
	 Magnitude of data 1.323e+06 output 1.793e+05 target 1.323e+06
Train Epoch: 3 [57600/81276 (71%)]	Loss: 5.166475 LR 2.49e-04
	 Magnitude of data 1.223e+06 output 1.866e+05 target 1.223e+06
Train Epoch: 3 [58240/81276 (72%)]	Loss: 5.555822 LR 2.49e-04
	 Magnitude of data 1.344e+06 output 1.745e+05 target 1.344e+06
Train Epoch: 3 [58880/81276 (72%)]	Loss: 5.482473 LR 2.48e-04
	 Magnitude of data 1.282e+06 output 1.715e+05 target 1.282e+06
Train Epoch: 3 [59520/81276 (73%)]	Loss: 5.121099 LR 2.48e-04
	 Magnitude of data 1.214e+06 output 1.877e+05 target 1.214e+06
Train Epoch: 3 [60160/81276 (74%)]	Loss: 5.374128 LR 2.48e-04
	 Magnitude of data 1.322e+06 output 1.864e+05 target 1.323e+06
Train Epoch: 3 [60800/81276 (75%)]	Loss: 5.293240 LR 2.47e-04
	 Magnitude of data 1.290e+06 output 1.851e+05 target 1.290e+06
Train Epoch: 3 [61440/81276 (76%)]	Loss: 5.125257 LR 2.47e-04
	 Magnitude of data 1.354e+06 output 1.819e+05 target 1.354e+06
Train Epoch: 3 [62080/81276 (76%)]	Loss: 5.077406 LR 2.47e-04
	 Magnitude of data 1.348e+06 output 1.834e+05 target 1.348e+06
Train Epoch: 3 [62720/81276 (77%)]	Loss: 5.289835 LR 2.47e-04
	 Magnitude of data 1.358e+06 output 1.831e+05 target 1.358e+06
Train Epoch: 3 [63360/81276 (78%)]	Loss: 5.415605 LR 2.46e-04
	 Magnitude of data 1.367e+06 output 1.736e+05 target 1.367e+06
Train Epoch: 3 [64000/81276 (79%)]	Loss: 5.091153 LR 2.46e-04
	 Magnitude of data 1.341e+06 output 1.768e+05 target 1.341e+06
Train Epoch: 3 [64640/81276 (80%)]	Loss: 5.438972 LR 2.46e-04
	 Magnitude of data 1.274e+06 output 1.861e+05 target 1.274e+06
Train Epoch: 3 [65280/81276 (80%)]	Loss: 5.028312 LR 2.45e-04
	 Magnitude of data 1.638e+06 output 1.912e+05 target 1.638e+06
Train Epoch: 3 [65920/81276 (81%)]	Loss: 5.083565 LR 2.45e-04
	 Magnitude of data 1.178e+06 output 1.882e+05 target 1.178e+06
Train Epoch: 3 [66560/81276 (82%)]	Loss: 5.431524 LR 2.45e-04
	 Magnitude of data 1.313e+06 output 1.864e+05 target 1.313e+06
Train Epoch: 3 [67200/81276 (83%)]	Loss: 5.248509 LR 2.45e-04
	 Magnitude of data 1.305e+06 output 1.845e+05 target 1.305e+06
Train Epoch: 3 [67840/81276 (84%)]	Loss: 5.014728 LR 2.44e-04
	 Magnitude of data 1.243e+06 output 1.798e+05 target 1.243e+06
Train Epoch: 3 [68480/81276 (84%)]	Loss: 5.240264 LR 2.44e-04
	 Magnitude of data 1.389e+06 output 1.837e+05 target 1.389e+06
Train Epoch: 3 [69120/81276 (85%)]	Loss: 5.305853 LR 2.44e-04
	 Magnitude of data 1.368e+06 output 1.887e+05 target 1.368e+06
Train Epoch: 3 [69760/81276 (86%)]	Loss: 5.436767 LR 2.43e-04
	 Magnitude of data 1.272e+06 output 1.840e+05 target 1.272e+06
Train Epoch: 3 [70400/81276 (87%)]	Loss: 5.446896 LR 2.43e-04
	 Magnitude of data 1.307e+06 output 1.804e+05 target 1.307e+06
Train Epoch: 3 [71040/81276 (87%)]	Loss: 5.530498 LR 2.43e-04
	 Magnitude of data 1.298e+06 output 1.763e+05 target 1.298e+06
Train Epoch: 3 [71680/81276 (88%)]	Loss: 5.324361 LR 2.43e-04
	 Magnitude of data 1.285e+06 output 1.825e+05 target 1.285e+06
Train Epoch: 3 [72320/81276 (89%)]	Loss: 5.155510 LR 2.42e-04
	 Magnitude of data 1.372e+06 output 1.825e+05 target 1.372e+06
Train Epoch: 3 [72960/81276 (90%)]	Loss: 5.344532 LR 2.42e-04
	 Magnitude of data 1.268e+06 output 1.838e+05 target 1.268e+06
Train Epoch: 3 [73600/81276 (91%)]	Loss: 5.113621 LR 2.42e-04
	 Magnitude of data 1.248e+06 output 1.861e+05 target 1.248e+06
Train Epoch: 3 [74240/81276 (91%)]	Loss: 5.401701 LR 2.41e-04
	 Magnitude of data 1.344e+06 output 1.815e+05 target 1.344e+06
Train Epoch: 3 [74880/81276 (92%)]	Loss: 5.544683 LR 2.41e-04
	 Magnitude of data 1.405e+06 output 1.821e+05 target 1.405e+06
Train Epoch: 3 [75520/81276 (93%)]	Loss: 5.230868 LR 2.41e-04
	 Magnitude of data 1.326e+06 output 1.800e+05 target 1.326e+06
Train Epoch: 3 [76160/81276 (94%)]	Loss: 5.264014 LR 2.40e-04
	 Magnitude of data 1.291e+06 output 1.760e+05 target 1.291e+06
Train Epoch: 3 [76800/81276 (95%)]	Loss: 5.308874 LR 2.40e-04
	 Magnitude of data 1.338e+06 output 1.737e+05 target 1.338e+06
Train Epoch: 3 [77440/81276 (95%)]	Loss: 5.189355 LR 2.40e-04
	 Magnitude of data 1.279e+06 output 1.797e+05 target 1.279e+06
Train Epoch: 3 [78080/81276 (96%)]	Loss: 5.138579 LR 2.40e-04
	 Magnitude of data 1.287e+06 output 1.782e+05 target 1.287e+06
Train Epoch: 3 [78720/81276 (97%)]	Loss: 5.229551 LR 2.39e-04
	 Magnitude of data 1.253e+06 output 1.836e+05 target 1.253e+06
Train Epoch: 3 [79360/81276 (98%)]	Loss: 5.570031 LR 2.39e-04
	 Magnitude of data 1.327e+06 output 1.831e+05 target 1.327e+06
Train Epoch: 3 [80000/81276 (99%)]	Loss: 5.334867 LR 2.39e-04
	 Magnitude of data 1.478e+06 output 1.789e+05 target 1.478e+06
Train Epoch: 3 [80640/81276 (99%)]	Loss: 5.290236 LR 2.38e-04
	 Magnitude of data 1.218e+06 output 1.820e+05 target 1.218e+06
Train Epoch: 3 [81216/81276 (100%)]	Loss: 5.038476 LR 2.38e-04
Test set: Average loss: 5.38133929
Train Epoch: 4 [0/81276 (0%)]	Loss: 5.394480 LR 2.38e-04
	 Magnitude of data 1.348e+06 output 1.804e+05 target 1.348e+06
Train Epoch: 4 [640/81276 (1%)]	Loss: 5.277213 LR 2.38e-04
	 Magnitude of data 1.314e+06 output 1.850e+05 target 1.314e+06
Train Epoch: 4 [1280/81276 (2%)]	Loss: 5.531078 LR 2.38e-04
	 Magnitude of data 1.495e+06 output 1.798e+05 target 1.495e+06
Train Epoch: 4 [1920/81276 (2%)]	Loss: 5.311481 LR 2.37e-04
	 Magnitude of data 1.218e+06 output 1.843e+05 target 1.218e+06
Train Epoch: 4 [2560/81276 (3%)]	Loss: 4.993332 LR 2.37e-04
	 Magnitude of data 1.281e+06 output 1.814e+05 target 1.281e+06
Train Epoch: 4 [3200/81276 (4%)]	Loss: 4.976139 LR 2.37e-04
	 Magnitude of data 1.317e+06 output 1.871e+05 target 1.317e+06
Train Epoch: 4 [3840/81276 (5%)]	Loss: 5.035879 LR 2.36e-04
	 Magnitude of data 1.281e+06 output 1.885e+05 target 1.281e+06
Train Epoch: 4 [4480/81276 (6%)]	Loss: 5.094513 LR 2.36e-04
	 Magnitude of data 1.306e+06 output 1.925e+05 target 1.306e+06
Train Epoch: 4 [5120/81276 (6%)]	Loss: 5.158041 LR 2.36e-04
	 Magnitude of data 1.360e+06 output 1.861e+05 target 1.360e+06
Train Epoch: 4 [5760/81276 (7%)]	Loss: 5.340595 LR 2.35e-04
	 Magnitude of data 1.349e+06 output 1.843e+05 target 1.350e+06
Train Epoch: 4 [6400/81276 (8%)]	Loss: 5.368324 LR 2.35e-04
	 Magnitude of data 1.285e+06 output 1.895e+05 target 1.286e+06
Train Epoch: 4 [7040/81276 (9%)]	Loss: 5.240044 LR 2.35e-04
	 Magnitude of data 1.278e+06 output 1.815e+05 target 1.278e+06
Train Epoch: 4 [7680/81276 (9%)]	Loss: 5.390452 LR 2.34e-04
	 Magnitude of data 1.419e+06 output 1.741e+05 target 1.419e+06
Train Epoch: 4 [8320/81276 (10%)]	Loss: 5.427245 LR 2.34e-04
	 Magnitude of data 1.234e+06 output 1.737e+05 target 1.234e+06
Train Epoch: 4 [8960/81276 (11%)]	Loss: 5.468522 LR 2.34e-04
	 Magnitude of data 1.348e+06 output 1.791e+05 target 1.348e+06
Train Epoch: 4 [9600/81276 (12%)]	Loss: 5.257199 LR 2.34e-04
	 Magnitude of data 1.364e+06 output 1.805e+05 target 1.364e+06
Train Epoch: 4 [10240/81276 (13%)]	Loss: 5.223452 LR 2.33e-04
	 Magnitude of data 1.276e+06 output 1.784e+05 target 1.276e+06
Train Epoch: 4 [10880/81276 (13%)]	Loss: 5.093682 LR 2.33e-04
	 Magnitude of data 1.240e+06 output 1.824e+05 target 1.240e+06
Train Epoch: 4 [11520/81276 (14%)]	Loss: 5.190014 LR 2.33e-04
	 Magnitude of data 1.342e+06 output 1.811e+05 target 1.342e+06
Train Epoch: 4 [12160/81276 (15%)]	Loss: 5.141655 LR 2.32e-04
	 Magnitude of data 1.359e+06 output 1.878e+05 target 1.359e+06
Train Epoch: 4 [12800/81276 (16%)]	Loss: 5.268782 LR 2.32e-04
	 Magnitude of data 1.366e+06 output 1.917e+05 target 1.366e+06
Train Epoch: 4 [13440/81276 (17%)]	Loss: 4.982983 LR 2.32e-04
	 Magnitude of data 1.241e+06 output 1.913e+05 target 1.241e+06
Train Epoch: 4 [14080/81276 (17%)]	Loss: 5.360669 LR 2.31e-04
	 Magnitude of data 1.396e+06 output 1.854e+05 target 1.396e+06
Train Epoch: 4 [14720/81276 (18%)]	Loss: 5.429512 LR 2.31e-04
	 Magnitude of data 1.450e+06 output 1.865e+05 target 1.450e+06
Train Epoch: 4 [15360/81276 (19%)]	Loss: 5.447960 LR 2.31e-04
	 Magnitude of data 1.387e+06 output 1.824e+05 target 1.387e+06
Train Epoch: 4 [16000/81276 (20%)]	Loss: 5.194957 LR 2.30e-04
	 Magnitude of data 1.371e+06 output 1.836e+05 target 1.371e+06
Train Epoch: 4 [16640/81276 (20%)]	Loss: 5.158741 LR 2.30e-04
	 Magnitude of data 1.274e+06 output 1.865e+05 target 1.274e+06
Train Epoch: 4 [17280/81276 (21%)]	Loss: 5.420341 LR 2.30e-04
	 Magnitude of data 1.443e+06 output 1.793e+05 target 1.442e+06
Train Epoch: 4 [17920/81276 (22%)]	Loss: 5.285368 LR 2.30e-04
	 Magnitude of data 1.267e+06 output 1.816e+05 target 1.266e+06
Train Epoch: 4 [18560/81276 (23%)]	Loss: 5.231374 LR 2.29e-04
	 Magnitude of data 1.246e+06 output 1.872e+05 target 1.246e+06
Train Epoch: 4 [19200/81276 (24%)]	Loss: 5.044935 LR 2.29e-04
	 Magnitude of data 1.254e+06 output 1.908e+05 target 1.254e+06
Train Epoch: 4 [19840/81276 (24%)]	Loss: 5.129555 LR 2.29e-04
	 Magnitude of data 1.331e+06 output 1.894e+05 target 1.331e+06
Train Epoch: 4 [20480/81276 (25%)]	Loss: 5.041466 LR 2.28e-04
	 Magnitude of data 1.190e+06 output 1.826e+05 target 1.190e+06
Train Epoch: 4 [21120/81276 (26%)]	Loss: 5.345483 LR 2.28e-04
	 Magnitude of data 1.290e+06 output 1.804e+05 target 1.290e+06
Train Epoch: 4 [21760/81276 (27%)]	Loss: 5.179020 LR 2.28e-04
	 Magnitude of data 1.386e+06 output 1.806e+05 target 1.385e+06
Train Epoch: 4 [22400/81276 (28%)]	Loss: 5.020927 LR 2.27e-04
	 Magnitude of data 1.271e+06 output 1.914e+05 target 1.271e+06
Train Epoch: 4 [23040/81276 (28%)]	Loss: 5.513266 LR 2.27e-04
	 Magnitude of data 1.259e+06 output 1.791e+05 target 1.259e+06
Train Epoch: 4 [23680/81276 (29%)]	Loss: 5.150132 LR 2.27e-04
	 Magnitude of data 1.231e+06 output 1.880e+05 target 1.231e+06
Train Epoch: 4 [24320/81276 (30%)]	Loss: 5.385727 LR 2.26e-04
	 Magnitude of data 1.323e+06 output 1.915e+05 target 1.322e+06
Train Epoch: 4 [24960/81276 (31%)]	Loss: 5.062175 LR 2.26e-04
	 Magnitude of data 1.341e+06 output 1.902e+05 target 1.341e+06
Train Epoch: 4 [25600/81276 (32%)]	Loss: 5.004904 LR 2.26e-04
	 Magnitude of data 1.299e+06 output 1.866e+05 target 1.299e+06
Train Epoch: 4 [26240/81276 (32%)]	Loss: 5.399704 LR 2.25e-04
	 Magnitude of data 1.329e+06 output 1.944e+05 target 1.329e+06
Train Epoch: 4 [26880/81276 (33%)]	Loss: 4.867069 LR 2.25e-04
	 Magnitude of data 1.258e+06 output 1.873e+05 target 1.258e+06
Train Epoch: 4 [27520/81276 (34%)]	Loss: 5.242002 LR 2.25e-04
	 Magnitude of data 1.280e+06 output 1.925e+05 target 1.280e+06
Train Epoch: 4 [28160/81276 (35%)]	Loss: 5.161239 LR 2.24e-04
	 Magnitude of data 1.353e+06 output 1.868e+05 target 1.353e+06
Train Epoch: 4 [28800/81276 (35%)]	Loss: 4.667632 LR 2.24e-04
	 Magnitude of data 1.316e+06 output 1.917e+05 target 1.316e+06
Train Epoch: 4 [29440/81276 (36%)]	Loss: 5.252853 LR 2.24e-04
	 Magnitude of data 1.295e+06 output 1.789e+05 target 1.295e+06
Train Epoch: 4 [30080/81276 (37%)]	Loss: 5.048008 LR 2.23e-04
	 Magnitude of data 1.290e+06 output 1.873e+05 target 1.290e+06
Train Epoch: 4 [30720/81276 (38%)]	Loss: 4.968152 LR 2.23e-04
	 Magnitude of data 1.320e+06 output 1.882e+05 target 1.320e+06
Train Epoch: 4 [31360/81276 (39%)]	Loss: 5.179437 LR 2.23e-04
	 Magnitude of data 1.397e+06 output 1.857e+05 target 1.397e+06
Train Epoch: 4 [32000/81276 (39%)]	Loss: 5.194474 LR 2.22e-04
	 Magnitude of data 1.283e+06 output 1.837e+05 target 1.283e+06
Train Epoch: 4 [32640/81276 (40%)]	Loss: 5.541944 LR 2.22e-04
	 Magnitude of data 1.354e+06 output 1.782e+05 target 1.354e+06
Train Epoch: 4 [33280/81276 (41%)]	Loss: 5.275249 LR 2.22e-04
	 Magnitude of data 1.271e+06 output 1.831e+05 target 1.271e+06
Train Epoch: 4 [33920/81276 (42%)]	Loss: 5.209501 LR 2.22e-04
	 Magnitude of data 1.296e+06 output 1.871e+05 target 1.296e+06
Train Epoch: 4 [34560/81276 (43%)]	Loss: 5.287807 LR 2.21e-04
	 Magnitude of data 1.312e+06 output 1.855e+05 target 1.312e+06
Train Epoch: 4 [35200/81276 (43%)]	Loss: 5.684526 LR 2.21e-04
	 Magnitude of data 1.383e+06 output 1.772e+05 target 1.383e+06
Train Epoch: 4 [35840/81276 (44%)]	Loss: 5.251471 LR 2.21e-04
	 Magnitude of data 1.314e+06 output 1.850e+05 target 1.314e+06
Train Epoch: 4 [36480/81276 (45%)]	Loss: 5.278337 LR 2.20e-04
	 Magnitude of data 1.359e+06 output 1.884e+05 target 1.359e+06
Train Epoch: 4 [37120/81276 (46%)]	Loss: 4.784127 LR 2.20e-04
	 Magnitude of data 1.273e+06 output 1.965e+05 target 1.273e+06
Train Epoch: 4 [37760/81276 (46%)]	Loss: 4.985771 LR 2.20e-04
	 Magnitude of data 1.261e+06 output 1.901e+05 target 1.261e+06
Train Epoch: 4 [38400/81276 (47%)]	Loss: 4.877141 LR 2.19e-04
	 Magnitude of data 1.358e+06 output 1.915e+05 target 1.358e+06
Train Epoch: 4 [39040/81276 (48%)]	Loss: 5.138397 LR 2.19e-04
	 Magnitude of data 1.339e+06 output 1.885e+05 target 1.339e+06
Train Epoch: 4 [39680/81276 (49%)]	Loss: 4.916629 LR 2.19e-04
	 Magnitude of data 1.233e+06 output 1.920e+05 target 1.233e+06
Train Epoch: 4 [40320/81276 (50%)]	Loss: 5.070823 LR 2.18e-04
	 Magnitude of data 1.395e+06 output 1.883e+05 target 1.395e+06
Train Epoch: 4 [40960/81276 (50%)]	Loss: 5.016058 LR 2.18e-04
	 Magnitude of data 1.324e+06 output 1.878e+05 target 1.324e+06
Train Epoch: 4 [41600/81276 (51%)]	Loss: 5.171594 LR 2.18e-04
	 Magnitude of data 1.367e+06 output 1.794e+05 target 1.367e+06
Train Epoch: 4 [42240/81276 (52%)]	Loss: 5.141300 LR 2.17e-04
	 Magnitude of data 1.301e+06 output 1.879e+05 target 1.301e+06
Train Epoch: 4 [42880/81276 (53%)]	Loss: 4.754444 LR 2.17e-04
	 Magnitude of data 1.223e+06 output 1.841e+05 target 1.223e+06
Train Epoch: 4 [43520/81276 (54%)]	Loss: 5.150867 LR 2.17e-04
	 Magnitude of data 1.285e+06 output 1.791e+05 target 1.285e+06
Train Epoch: 4 [44160/81276 (54%)]	Loss: 5.073079 LR 2.16e-04
	 Magnitude of data 1.281e+06 output 1.886e+05 target 1.281e+06
Train Epoch: 4 [44800/81276 (55%)]	Loss: 4.921135 LR 2.16e-04
	 Magnitude of data 1.413e+06 output 1.995e+05 target 1.413e+06
Train Epoch: 4 [45440/81276 (56%)]	Loss: 5.163181 LR 2.16e-04
	 Magnitude of data 1.310e+06 output 1.842e+05 target 1.310e+06
Train Epoch: 4 [46080/81276 (57%)]	Loss: 5.317582 LR 2.15e-04
	 Magnitude of data 1.308e+06 output 1.882e+05 target 1.308e+06
Train Epoch: 4 [46720/81276 (58%)]	Loss: 5.277657 LR 2.15e-04
	 Magnitude of data 1.370e+06 output 1.887e+05 target 1.371e+06
Train Epoch: 4 [47360/81276 (58%)]	Loss: 4.976570 LR 2.15e-04
	 Magnitude of data 1.361e+06 output 1.920e+05 target 1.361e+06
Train Epoch: 4 [48000/81276 (59%)]	Loss: 5.307048 LR 2.14e-04
	 Magnitude of data 1.285e+06 output 1.823e+05 target 1.286e+06
Train Epoch: 4 [48640/81276 (60%)]	Loss: 4.914762 LR 2.14e-04
	 Magnitude of data 1.249e+06 output 1.893e+05 target 1.249e+06
Train Epoch: 4 [49280/81276 (61%)]	Loss: 5.052623 LR 2.14e-04
	 Magnitude of data 1.305e+06 output 1.926e+05 target 1.305e+06
Train Epoch: 4 [49920/81276 (61%)]	Loss: 5.006885 LR 2.13e-04
	 Magnitude of data 1.259e+06 output 1.841e+05 target 1.259e+06
Train Epoch: 4 [50560/81276 (62%)]	Loss: 5.097287 LR 2.13e-04
	 Magnitude of data 1.274e+06 output 1.838e+05 target 1.273e+06
Train Epoch: 4 [51200/81276 (63%)]	Loss: 4.930565 LR 2.13e-04
	 Magnitude of data 1.319e+06 output 1.963e+05 target 1.319e+06
Train Epoch: 4 [51840/81276 (64%)]	Loss: 5.076937 LR 2.12e-04
	 Magnitude of data 1.351e+06 output 1.915e+05 target 1.351e+06
Train Epoch: 4 [52480/81276 (65%)]	Loss: 4.816089 LR 2.12e-04
	 Magnitude of data 1.318e+06 output 1.912e+05 target 1.318e+06
Train Epoch: 4 [53120/81276 (65%)]	Loss: 4.871161 LR 2.12e-04
	 Magnitude of data 1.274e+06 output 1.900e+05 target 1.274e+06
Train Epoch: 4 [53760/81276 (66%)]	Loss: 5.139284 LR 2.11e-04
	 Magnitude of data 1.363e+06 output 1.882e+05 target 1.363e+06
Train Epoch: 4 [54400/81276 (67%)]	Loss: 5.009376 LR 2.11e-04
	 Magnitude of data 1.305e+06 output 1.886e+05 target 1.305e+06
Train Epoch: 4 [55040/81276 (68%)]	Loss: 5.056163 LR 2.11e-04
	 Magnitude of data 1.319e+06 output 1.887e+05 target 1.318e+06
Train Epoch: 4 [55680/81276 (69%)]	Loss: 5.218370 LR 2.10e-04
	 Magnitude of data 1.197e+06 output 1.913e+05 target 1.197e+06
Train Epoch: 4 [56320/81276 (69%)]	Loss: 4.999609 LR 2.10e-04
	 Magnitude of data 1.373e+06 output 1.880e+05 target 1.373e+06
Train Epoch: 4 [56960/81276 (70%)]	Loss: 5.121515 LR 2.09e-04
	 Magnitude of data 1.323e+06 output 1.855e+05 target 1.323e+06
Train Epoch: 4 [57600/81276 (71%)]	Loss: 4.916227 LR 2.09e-04
	 Magnitude of data 1.223e+06 output 1.920e+05 target 1.223e+06
Train Epoch: 4 [58240/81276 (72%)]	Loss: 5.329540 LR 2.09e-04
	 Magnitude of data 1.344e+06 output 1.779e+05 target 1.344e+06
Train Epoch: 4 [58880/81276 (72%)]	Loss: 5.257684 LR 2.08e-04
	 Magnitude of data 1.282e+06 output 1.764e+05 target 1.282e+06
Train Epoch: 4 [59520/81276 (73%)]	Loss: 4.863999 LR 2.08e-04
	 Magnitude of data 1.214e+06 output 1.909e+05 target 1.214e+06
Train Epoch: 4 [60160/81276 (74%)]	Loss: 5.147182 LR 2.08e-04
	 Magnitude of data 1.322e+06 output 1.900e+05 target 1.323e+06
Train Epoch: 4 [60800/81276 (75%)]	Loss: 5.030627 LR 2.07e-04
	 Magnitude of data 1.290e+06 output 1.888e+05 target 1.290e+06
Train Epoch: 4 [61440/81276 (76%)]	Loss: 4.861065 LR 2.07e-04
	 Magnitude of data 1.354e+06 output 1.868e+05 target 1.354e+06
Train Epoch: 4 [62080/81276 (76%)]	Loss: 4.814401 LR 2.07e-04
	 Magnitude of data 1.348e+06 output 1.854e+05 target 1.348e+06
Train Epoch: 4 [62720/81276 (77%)]	Loss: 5.031225 LR 2.06e-04
	 Magnitude of data 1.358e+06 output 1.865e+05 target 1.358e+06
Train Epoch: 4 [63360/81276 (78%)]	Loss: 5.175458 LR 2.06e-04
	 Magnitude of data 1.367e+06 output 1.775e+05 target 1.367e+06
Train Epoch: 4 [64000/81276 (79%)]	Loss: 4.825569 LR 2.06e-04
	 Magnitude of data 1.341e+06 output 1.852e+05 target 1.341e+06
Train Epoch: 4 [64640/81276 (80%)]	Loss: 5.217976 LR 2.05e-04
	 Magnitude of data 1.274e+06 output 1.897e+05 target 1.274e+06
Train Epoch: 4 [65280/81276 (80%)]	Loss: 4.753351 LR 2.05e-04
	 Magnitude of data 1.638e+06 output 1.974e+05 target 1.638e+06
Train Epoch: 4 [65920/81276 (81%)]	Loss: 4.847301 LR 2.05e-04
	 Magnitude of data 1.178e+06 output 1.928e+05 target 1.178e+06
Train Epoch: 4 [66560/81276 (82%)]	Loss: 5.172886 LR 2.04e-04
	 Magnitude of data 1.313e+06 output 1.898e+05 target 1.313e+06
Train Epoch: 4 [67200/81276 (83%)]	Loss: 5.008526 LR 2.04e-04
	 Magnitude of data 1.305e+06 output 1.900e+05 target 1.305e+06
Train Epoch: 4 [67840/81276 (84%)]	Loss: 4.771925 LR 2.04e-04
	 Magnitude of data 1.243e+06 output 1.845e+05 target 1.243e+06
Train Epoch: 4 [68480/81276 (84%)]	Loss: 5.002736 LR 2.03e-04
	 Magnitude of data 1.389e+06 output 1.886e+05 target 1.389e+06
Train Epoch: 4 [69120/81276 (85%)]	Loss: 5.066281 LR 2.03e-04
	 Magnitude of data 1.368e+06 output 1.920e+05 target 1.368e+06
Train Epoch: 4 [69760/81276 (86%)]	Loss: 5.201067 LR 2.03e-04
	 Magnitude of data 1.272e+06 output 1.837e+05 target 1.272e+06
Train Epoch: 4 [70400/81276 (87%)]	Loss: 5.197814 LR 2.02e-04
	 Magnitude of data 1.307e+06 output 1.849e+05 target 1.307e+06
Train Epoch: 4 [71040/81276 (87%)]	Loss: 5.287286 LR 2.02e-04
	 Magnitude of data 1.298e+06 output 1.795e+05 target 1.298e+06
Train Epoch: 4 [71680/81276 (88%)]	Loss: 5.097113 LR 2.02e-04
	 Magnitude of data 1.285e+06 output 1.843e+05 target 1.285e+06
Train Epoch: 4 [72320/81276 (89%)]	Loss: 4.906121 LR 2.01e-04
	 Magnitude of data 1.372e+06 output 1.853e+05 target 1.372e+06
Train Epoch: 4 [72960/81276 (90%)]	Loss: 5.118196 LR 2.01e-04
	 Magnitude of data 1.268e+06 output 1.864e+05 target 1.268e+06
Train Epoch: 4 [73600/81276 (91%)]	Loss: 4.893392 LR 2.00e-04
	 Magnitude of data 1.248e+06 output 1.911e+05 target 1.248e+06
Train Epoch: 4 [74240/81276 (91%)]	Loss: 5.165177 LR 2.00e-04
	 Magnitude of data 1.344e+06 output 1.828e+05 target 1.344e+06
Train Epoch: 4 [74880/81276 (92%)]	Loss: 5.313815 LR 2.00e-04
	 Magnitude of data 1.405e+06 output 1.870e+05 target 1.405e+06
Train Epoch: 4 [75520/81276 (93%)]	Loss: 5.000893 LR 1.99e-04
	 Magnitude of data 1.326e+06 output 1.811e+05 target 1.326e+06
Train Epoch: 4 [76160/81276 (94%)]	Loss: 5.024710 LR 1.99e-04
	 Magnitude of data 1.291e+06 output 1.760e+05 target 1.291e+06
Train Epoch: 4 [76800/81276 (95%)]	Loss: 5.077257 LR 1.99e-04
	 Magnitude of data 1.338e+06 output 1.793e+05 target 1.338e+06
Train Epoch: 4 [77440/81276 (95%)]	Loss: 4.933682 LR 1.98e-04
	 Magnitude of data 1.279e+06 output 1.827e+05 target 1.279e+06
Train Epoch: 4 [78080/81276 (96%)]	Loss: 4.903180 LR 1.98e-04
	 Magnitude of data 1.287e+06 output 1.821e+05 target 1.287e+06
Train Epoch: 4 [78720/81276 (97%)]	Loss: 4.971624 LR 1.98e-04
	 Magnitude of data 1.253e+06 output 1.836e+05 target 1.253e+06
Train Epoch: 4 [79360/81276 (98%)]	Loss: 5.347548 LR 1.97e-04
	 Magnitude of data 1.327e+06 output 1.852e+05 target 1.327e+06
Train Epoch: 4 [80000/81276 (99%)]	Loss: 5.103347 LR 1.97e-04
	 Magnitude of data 1.478e+06 output 1.823e+05 target 1.478e+06
Train Epoch: 4 [80640/81276 (99%)]	Loss: 5.075114 LR 1.97e-04
	 Magnitude of data 1.218e+06 output 1.843e+05 target 1.218e+06
Train Epoch: 4 [81216/81276 (100%)]	Loss: 4.807632 LR 1.96e-04
Test set: Average loss: 5.21541754

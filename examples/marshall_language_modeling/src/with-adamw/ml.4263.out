Using GPU Device
Run info rank: 0: Torch version: 2.1.2+cu121 | Device: cuda:0 | Host: cpu
Loading dataset; args.percent_data=0.2
Loaded tensor from ../data/wikipedia.data
1.4 Splitting data into training and validation data
len(train_data)=104035585, len(val_data)=11559510 percent_data=0.2
len(train_data)=20807117, len(val_data)=2311902
-- procs    = 1
-- Tf       = 1.0
-- steps    = 64
-- max_levels     = 1
-- max_bwd_iters  = 1
-- max_fwd_iters  = 3
-- cfactor        = 4
-- fine fcf       = False
-- skip down      = True

args.model_dimension=384 args.num_heads=6 args.batch_size=64
rank 0: len(list(model.parameters())) 1798
rank 0: 152238673
Train Epoch: 1 [0/81276 (0%)]	Loss: 11.000297 LR 6.00e-07
	 Magnitude of data 1.348e+06 output 1.659e+04 target 1.348e+06
Train Epoch: 1 [640/81276 (1%)]	Loss: 11.001568 LR 6.60e-06
	 Magnitude of data 1.314e+06 output 1.659e+04 target 1.314e+06
Train Epoch: 1 [1280/81276 (2%)]	Loss: 10.958558 LR 1.26e-05
	 Magnitude of data 1.495e+06 output 1.658e+04 target 1.495e+06
Train Epoch: 1 [1920/81276 (2%)]	Loss: 10.908924 LR 1.86e-05
	 Magnitude of data 1.218e+06 output 1.656e+04 target 1.218e+06
Train Epoch: 1 [2560/81276 (3%)]	Loss: 10.837632 LR 2.46e-05
	 Magnitude of data 1.281e+06 output 1.654e+04 target 1.281e+06
Train Epoch: 1 [3200/81276 (4%)]	Loss: 10.765272 LR 3.06e-05
	 Magnitude of data 1.317e+06 output 1.653e+04 target 1.317e+06
Train Epoch: 1 [3840/81276 (5%)]	Loss: 10.610262 LR 3.66e-05
	 Magnitude of data 1.281e+06 output 1.657e+04 target 1.281e+06
Train Epoch: 1 [4480/81276 (6%)]	Loss: 10.398053 LR 4.26e-05
	 Magnitude of data 1.306e+06 output 1.685e+04 target 1.306e+06
Train Epoch: 1 [5120/81276 (6%)]	Loss: 10.071507 LR 4.86e-05
	 Magnitude of data 1.360e+06 output 1.800e+04 target 1.360e+06
Train Epoch: 1 [5760/81276 (7%)]	Loss: 9.624080 LR 5.46e-05
	 Magnitude of data 1.349e+06 output 2.108e+04 target 1.350e+06
Train Epoch: 1 [6400/81276 (8%)]	Loss: 9.222560 LR 6.06e-05
	 Magnitude of data 1.285e+06 output 2.562e+04 target 1.286e+06
Train Epoch: 1 [7040/81276 (9%)]	Loss: 8.899477 LR 6.66e-05
	 Magnitude of data 1.278e+06 output 3.061e+04 target 1.278e+06
Train Epoch: 1 [7680/81276 (9%)]	Loss: 8.672814 LR 7.26e-05
	 Magnitude of data 1.419e+06 output 3.573e+04 target 1.419e+06
Train Epoch: 1 [8320/81276 (10%)]	Loss: 8.336322 LR 7.86e-05
	 Magnitude of data 1.234e+06 output 4.103e+04 target 1.234e+06
Train Epoch: 1 [8960/81276 (11%)]	Loss: 8.140023 LR 8.46e-05
	 Magnitude of data 1.348e+06 output 4.644e+04 target 1.348e+06
Train Epoch: 1 [9600/81276 (12%)]	Loss: 7.916073 LR 9.06e-05
	 Magnitude of data 1.364e+06 output 5.179e+04 target 1.364e+06
Train Epoch: 1 [10240/81276 (13%)]	Loss: 7.731206 LR 9.66e-05
	 Magnitude of data 1.276e+06 output 5.682e+04 target 1.276e+06
Train Epoch: 1 [10880/81276 (13%)]	Loss: 7.621994 LR 1.03e-04
	 Magnitude of data 1.240e+06 output 6.165e+04 target 1.240e+06
Train Epoch: 1 [11520/81276 (14%)]	Loss: 7.611633 LR 1.09e-04
	 Magnitude of data 1.342e+06 output 6.609e+04 target 1.342e+06
Train Epoch: 1 [12160/81276 (15%)]	Loss: 7.559145 LR 1.15e-04
	 Magnitude of data 1.359e+06 output 7.011e+04 target 1.359e+06
Train Epoch: 1 [12800/81276 (16%)]	Loss: 7.591101 LR 1.21e-04
	 Magnitude of data 1.366e+06 output 7.380e+04 target 1.366e+06
Train Epoch: 1 [13440/81276 (17%)]	Loss: 7.381635 LR 1.27e-04
	 Magnitude of data 1.241e+06 output 7.703e+04 target 1.241e+06
Train Epoch: 1 [14080/81276 (17%)]	Loss: 7.491913 LR 1.33e-04
	 Magnitude of data 1.396e+06 output 8.002e+04 target 1.396e+06
Train Epoch: 1 [14720/81276 (18%)]	Loss: 7.553121 LR 1.38e-04
	 Magnitude of data 1.450e+06 output 8.211e+04 target 1.450e+06
Train Epoch: 1 [15360/81276 (19%)]	Loss: 7.580106 LR 1.44e-04
	 Magnitude of data 1.387e+06 output 8.337e+04 target 1.387e+06
Train Epoch: 1 [16000/81276 (20%)]	Loss: 7.386881 LR 1.50e-04
	 Magnitude of data 1.371e+06 output 8.208e+04 target 1.371e+06
Train Epoch: 1 [16640/81276 (20%)]	Loss: 7.209527 LR 1.56e-04
	 Magnitude of data 1.274e+06 output 8.377e+04 target 1.274e+06
Train Epoch: 1 [17280/81276 (21%)]	Loss: 7.442774 LR 1.62e-04
	 Magnitude of data 1.443e+06 output 8.563e+04 target 1.442e+06
Train Epoch: 1 [17920/81276 (22%)]	Loss: 7.196156 LR 1.68e-04
	 Magnitude of data 1.267e+06 output 8.647e+04 target 1.266e+06
Train Epoch: 1 [18560/81276 (23%)]	Loss: 6.955406 LR 1.74e-04
	 Magnitude of data 1.246e+06 output 8.822e+04 target 1.246e+06
Train Epoch: 1 [19200/81276 (24%)]	Loss: 6.984404 LR 1.80e-04
	 Magnitude of data 1.254e+06 output 8.997e+04 target 1.254e+06
Train Epoch: 1 [19840/81276 (24%)]	Loss: 7.121913 LR 1.86e-04
	 Magnitude of data 1.331e+06 output 9.253e+04 target 1.331e+06
Train Epoch: 1 [20480/81276 (25%)]	Loss: 7.015927 LR 1.92e-04
	 Magnitude of data 1.190e+06 output 9.402e+04 target 1.190e+06
Train Epoch: 1 [21120/81276 (26%)]	Loss: 7.046474 LR 1.98e-04
	 Magnitude of data 1.290e+06 output 9.338e+04 target 1.290e+06
Train Epoch: 1 [21760/81276 (27%)]	Loss: 7.065756 LR 2.04e-04
	 Magnitude of data 1.386e+06 output 9.577e+04 target 1.385e+06
Train Epoch: 1 [22400/81276 (28%)]	Loss: 6.977850 LR 2.10e-04
	 Magnitude of data 1.271e+06 output 9.763e+04 target 1.271e+06
Train Epoch: 1 [23040/81276 (28%)]	Loss: 7.136346 LR 2.16e-04
	 Magnitude of data 1.259e+06 output 9.793e+04 target 1.259e+06
Train Epoch: 1 [23680/81276 (29%)]	Loss: 6.885110 LR 2.22e-04
	 Magnitude of data 1.231e+06 output 1.020e+05 target 1.231e+06
Train Epoch: 1 [24320/81276 (30%)]	Loss: 7.034447 LR 2.28e-04
	 Magnitude of data 1.323e+06 output 1.017e+05 target 1.322e+06
Train Epoch: 1 [24960/81276 (31%)]	Loss: 6.749527 LR 2.34e-04
	 Magnitude of data 1.341e+06 output 1.013e+05 target 1.341e+06
Train Epoch: 1 [25600/81276 (32%)]	Loss: 6.882524 LR 2.40e-04
	 Magnitude of data 1.299e+06 output 1.038e+05 target 1.299e+06
Train Epoch: 1 [26240/81276 (32%)]	Loss: 6.946693 LR 2.46e-04
	 Magnitude of data 1.329e+06 output 1.053e+05 target 1.329e+06
Train Epoch: 1 [26880/81276 (33%)]	Loss: 6.649076 LR 2.52e-04
	 Magnitude of data 1.258e+06 output 1.054e+05 target 1.258e+06
Train Epoch: 1 [27520/81276 (34%)]	Loss: 6.912211 LR 2.58e-04
	 Magnitude of data 1.280e+06 output 1.078e+05 target 1.280e+06
Train Epoch: 1 [28160/81276 (35%)]	Loss: 6.854218 LR 2.64e-04
	 Magnitude of data 1.353e+06 output 1.062e+05 target 1.353e+06
Train Epoch: 1 [28800/81276 (35%)]	Loss: 6.777700 LR 2.70e-04
	 Magnitude of data 1.316e+06 output 1.096e+05 target 1.316e+06
Train Epoch: 1 [29440/81276 (36%)]	Loss: 6.855315 LR 2.76e-04
	 Magnitude of data 1.295e+06 output 1.071e+05 target 1.295e+06
Train Epoch: 1 [30080/81276 (37%)]	Loss: 6.742882 LR 2.82e-04
	 Magnitude of data 1.290e+06 output 1.117e+05 target 1.290e+06
Train Epoch: 1 [30720/81276 (38%)]	Loss: 6.738301 LR 2.88e-04
	 Magnitude of data 1.320e+06 output 1.118e+05 target 1.320e+06
Train Epoch: 1 [31360/81276 (39%)]	Loss: 6.635946 LR 2.94e-04
	 Magnitude of data 1.397e+06 output 1.124e+05 target 1.397e+06
Train Epoch: 1 [32000/81276 (39%)]	Loss: 6.755082 LR 2.99e-04
	 Magnitude of data 1.283e+06 output 1.173e+05 target 1.283e+06
Train Epoch: 1 [32640/81276 (40%)]	Loss: 6.916168 LR 2.99e-04
	 Magnitude of data 1.354e+06 output 1.123e+05 target 1.354e+06
Train Epoch: 1 [33280/81276 (41%)]	Loss: 6.802453 LR 2.99e-04
	 Magnitude of data 1.271e+06 output 1.154e+05 target 1.271e+06
Train Epoch: 1 [33920/81276 (42%)]	Loss: 6.770851 LR 2.99e-04
	 Magnitude of data 1.296e+06 output 1.211e+05 target 1.296e+06
Train Epoch: 1 [34560/81276 (43%)]	Loss: 6.781442 LR 2.99e-04
	 Magnitude of data 1.312e+06 output 1.175e+05 target 1.312e+06
Train Epoch: 1 [35200/81276 (43%)]	Loss: 7.087838 LR 2.99e-04
	 Magnitude of data 1.383e+06 output 1.171e+05 target 1.383e+06
Train Epoch: 1 [35840/81276 (44%)]	Loss: 6.676775 LR 2.99e-04
	 Magnitude of data 1.314e+06 output 1.171e+05 target 1.314e+06
Train Epoch: 1 [36480/81276 (45%)]	Loss: 6.711614 LR 2.99e-04
	 Magnitude of data 1.359e+06 output 1.161e+05 target 1.359e+06
Train Epoch: 1 [37120/81276 (46%)]	Loss: 6.385633 LR 2.98e-04
	 Magnitude of data 1.273e+06 output 1.200e+05 target 1.273e+06
Train Epoch: 1 [37760/81276 (46%)]	Loss: 6.499872 LR 2.98e-04
	 Magnitude of data 1.261e+06 output 1.219e+05 target 1.261e+06
Train Epoch: 1 [38400/81276 (47%)]	Loss: 6.491748 LR 2.98e-04
	 Magnitude of data 1.358e+06 output 1.223e+05 target 1.358e+06
Train Epoch: 1 [39040/81276 (48%)]	Loss: 6.655869 LR 2.98e-04
	 Magnitude of data 1.339e+06 output 1.276e+05 target 1.339e+06
Train Epoch: 1 [39680/81276 (49%)]	Loss: 6.371765 LR 2.98e-04
	 Magnitude of data 1.233e+06 output 1.245e+05 target 1.233e+06
Train Epoch: 1 [40320/81276 (50%)]	Loss: 6.668091 LR 2.98e-04
	 Magnitude of data 1.395e+06 output 1.232e+05 target 1.395e+06
Train Epoch: 1 [40960/81276 (50%)]	Loss: 6.544606 LR 2.98e-04
	 Magnitude of data 1.324e+06 output 1.262e+05 target 1.324e+06
Train Epoch: 1 [41600/81276 (51%)]	Loss: 6.574194 LR 2.98e-04
	 Magnitude of data 1.367e+06 output 1.246e+05 target 1.367e+06
Train Epoch: 1 [42240/81276 (52%)]	Loss: 6.540280 LR 2.98e-04
	 Magnitude of data 1.301e+06 output 1.325e+05 target 1.301e+06
Train Epoch: 1 [42880/81276 (53%)]	Loss: 6.331502 LR 2.98e-04
	 Magnitude of data 1.223e+06 output 1.323e+05 target 1.223e+06
Train Epoch: 1 [43520/81276 (54%)]	Loss: 6.477328 LR 2.98e-04
	 Magnitude of data 1.285e+06 output 1.313e+05 target 1.285e+06
Train Epoch: 1 [44160/81276 (54%)]	Loss: 6.432322 LR 2.98e-04
	 Magnitude of data 1.281e+06 output 1.345e+05 target 1.281e+06
Train Epoch: 1 [44800/81276 (55%)]	Loss: 6.494858 LR 2.98e-04
	 Magnitude of data 1.413e+06 output 1.324e+05 target 1.413e+06
Train Epoch: 1 [45440/81276 (56%)]	Loss: 6.554396 LR 2.98e-04
	 Magnitude of data 1.310e+06 output 1.351e+05 target 1.310e+06
Train Epoch: 1 [46080/81276 (57%)]	Loss: 6.593224 LR 2.98e-04
	 Magnitude of data 1.308e+06 output 1.367e+05 target 1.308e+06
Train Epoch: 1 [46720/81276 (58%)]	Loss: 6.596675 LR 2.98e-04
	 Magnitude of data 1.370e+06 output 1.377e+05 target 1.371e+06
Train Epoch: 1 [47360/81276 (58%)]	Loss: 6.279075 LR 2.97e-04
	 Magnitude of data 1.361e+06 output 1.335e+05 target 1.361e+06
Train Epoch: 1 [48000/81276 (59%)]	Loss: 6.553170 LR 2.97e-04
	 Magnitude of data 1.285e+06 output 1.423e+05 target 1.286e+06
Train Epoch: 1 [48640/81276 (60%)]	Loss: 6.253328 LR 2.97e-04
	 Magnitude of data 1.249e+06 output 1.378e+05 target 1.249e+06
Train Epoch: 1 [49280/81276 (61%)]	Loss: 6.303865 LR 2.97e-04
	 Magnitude of data 1.305e+06 output 1.359e+05 target 1.305e+06
Train Epoch: 1 [49920/81276 (61%)]	Loss: 6.428576 LR 2.97e-04
	 Magnitude of data 1.259e+06 output 1.373e+05 target 1.259e+06
Train Epoch: 1 [50560/81276 (62%)]	Loss: 6.400823 LR 2.97e-04
	 Magnitude of data 1.274e+06 output 1.427e+05 target 1.273e+06
Train Epoch: 1 [51200/81276 (63%)]	Loss: 6.212583 LR 2.97e-04
	 Magnitude of data 1.319e+06 output 1.385e+05 target 1.319e+06
Train Epoch: 1 [51840/81276 (64%)]	Loss: 6.473154 LR 2.97e-04
	 Magnitude of data 1.351e+06 output 1.482e+05 target 1.351e+06
Train Epoch: 1 [52480/81276 (65%)]	Loss: 6.203046 LR 2.97e-04
	 Magnitude of data 1.318e+06 output 1.470e+05 target 1.318e+06
Train Epoch: 1 [53120/81276 (65%)]	Loss: 6.181433 LR 2.97e-04
	 Magnitude of data 1.274e+06 output 1.403e+05 target 1.274e+06
Train Epoch: 1 [53760/81276 (66%)]	Loss: 6.463933 LR 2.97e-04
	 Magnitude of data 1.363e+06 output 1.424e+05 target 1.363e+06
Train Epoch: 1 [54400/81276 (67%)]	Loss: 6.315665 LR 2.97e-04
	 Magnitude of data 1.305e+06 output 1.489e+05 target 1.305e+06
Train Epoch: 1 [55040/81276 (68%)]	Loss: 6.346851 LR 2.97e-04
	 Magnitude of data 1.319e+06 output 1.444e+05 target 1.318e+06
Train Epoch: 1 [55680/81276 (69%)]	Loss: 6.405082 LR 2.97e-04
	 Magnitude of data 1.197e+06 output 1.486e+05 target 1.197e+06
Train Epoch: 1 [56320/81276 (69%)]	Loss: 6.335707 LR 2.96e-04
	 Magnitude of data 1.373e+06 output 1.476e+05 target 1.373e+06
Train Epoch: 1 [56960/81276 (70%)]	Loss: 6.358271 LR 2.96e-04
	 Magnitude of data 1.323e+06 output 1.466e+05 target 1.323e+06
Train Epoch: 1 [57600/81276 (71%)]	Loss: 6.218871 LR 2.96e-04
	 Magnitude of data 1.223e+06 output 1.513e+05 target 1.223e+06
Train Epoch: 1 [58240/81276 (72%)]	Loss: 6.549133 LR 2.96e-04
	 Magnitude of data 1.344e+06 output 1.474e+05 target 1.344e+06
Train Epoch: 1 [58880/81276 (72%)]	Loss: 6.471629 LR 2.96e-04
	 Magnitude of data 1.282e+06 output 1.520e+05 target 1.282e+06
Train Epoch: 1 [59520/81276 (73%)]	Loss: 6.097555 LR 2.96e-04
	 Magnitude of data 1.214e+06 output 1.510e+05 target 1.214e+06
Train Epoch: 1 [60160/81276 (74%)]	Loss: 6.303419 LR 2.96e-04
	 Magnitude of data 1.322e+06 output 1.556e+05 target 1.323e+06
Train Epoch: 1 [60800/81276 (75%)]	Loss: 6.271915 LR 2.96e-04
	 Magnitude of data 1.290e+06 output 1.571e+05 target 1.290e+06
Train Epoch: 1 [61440/81276 (76%)]	Loss: 6.208782 LR 2.96e-04
	 Magnitude of data 1.354e+06 output 1.539e+05 target 1.354e+06
Train Epoch: 1 [62080/81276 (76%)]	Loss: 6.174984 LR 2.96e-04
	 Magnitude of data 1.348e+06 output 1.543e+05 target 1.348e+06
Train Epoch: 1 [62720/81276 (77%)]	Loss: 6.242458 LR 2.96e-04
	 Magnitude of data 1.358e+06 output 1.548e+05 target 1.358e+06
Train Epoch: 1 [63360/81276 (78%)]	Loss: 6.404829 LR 2.96e-04
	 Magnitude of data 1.367e+06 output 1.520e+05 target 1.367e+06
Train Epoch: 1 [64000/81276 (79%)]	Loss: 6.199787 LR 2.95e-04
	 Magnitude of data 1.341e+06 output 1.533e+05 target 1.341e+06
Train Epoch: 1 [64640/81276 (80%)]	Loss: 6.244597 LR 2.95e-04
	 Magnitude of data 1.274e+06 output 1.574e+05 target 1.274e+06
Train Epoch: 1 [65280/81276 (80%)]	Loss: 6.249807 LR 2.95e-04
	 Magnitude of data 1.638e+06 output 1.538e+05 target 1.638e+06
Train Epoch: 1 [65920/81276 (81%)]	Loss: 6.096895 LR 2.95e-04
	 Magnitude of data 1.178e+06 output 1.591e+05 target 1.178e+06
Train Epoch: 1 [66560/81276 (82%)]	Loss: 6.390738 LR 2.95e-04
	 Magnitude of data 1.313e+06 output 1.606e+05 target 1.313e+06
Train Epoch: 1 [67200/81276 (83%)]	Loss: 6.181807 LR 2.95e-04
	 Magnitude of data 1.305e+06 output 1.567e+05 target 1.305e+06
Train Epoch: 1 [67840/81276 (84%)]	Loss: 5.964233 LR 2.95e-04
	 Magnitude of data 1.243e+06 output 1.566e+05 target 1.243e+06
Train Epoch: 1 [68480/81276 (84%)]	Loss: 6.231211 LR 2.95e-04
	 Magnitude of data 1.389e+06 output 1.587e+05 target 1.389e+06
Train Epoch: 1 [69120/81276 (85%)]	Loss: 6.236985 LR 2.95e-04
	 Magnitude of data 1.368e+06 output 1.619e+05 target 1.368e+06
Train Epoch: 1 [69760/81276 (86%)]	Loss: 6.314003 LR 2.95e-04
	 Magnitude of data 1.272e+06 output 1.698e+05 target 1.272e+06
Train Epoch: 1 [70400/81276 (87%)]	Loss: 6.326423 LR 2.94e-04
	 Magnitude of data 1.307e+06 output 1.611e+05 target 1.307e+06
Train Epoch: 1 [71040/81276 (87%)]	Loss: 6.429712 LR 2.94e-04
	 Magnitude of data 1.298e+06 output 1.600e+05 target 1.298e+06
Train Epoch: 1 [71680/81276 (88%)]	Loss: 6.219453 LR 2.94e-04
	 Magnitude of data 1.285e+06 output 1.598e+05 target 1.285e+06
Train Epoch: 1 [72320/81276 (89%)]	Loss: 6.126281 LR 2.94e-04
	 Magnitude of data 1.372e+06 output 1.585e+05 target 1.372e+06
Train Epoch: 1 [72960/81276 (90%)]	Loss: 6.179017 LR 2.94e-04
	 Magnitude of data 1.268e+06 output 1.595e+05 target 1.268e+06
Train Epoch: 1 [73600/81276 (91%)]	Loss: 6.005855 LR 2.94e-04
	 Magnitude of data 1.248e+06 output 1.646e+05 target 1.248e+06
Train Epoch: 1 [74240/81276 (91%)]	Loss: 6.274126 LR 2.94e-04
	 Magnitude of data 1.344e+06 output 1.645e+05 target 1.344e+06
Train Epoch: 1 [74880/81276 (92%)]	Loss: 6.414359 LR 2.94e-04
	 Magnitude of data 1.405e+06 output 1.629e+05 target 1.405e+06
Train Epoch: 1 [75520/81276 (93%)]	Loss: 6.114018 LR 2.94e-04
	 Magnitude of data 1.326e+06 output 1.634e+05 target 1.326e+06
Train Epoch: 1 [76160/81276 (94%)]	Loss: 6.154764 LR 2.94e-04
	 Magnitude of data 1.291e+06 output 1.642e+05 target 1.291e+06
Train Epoch: 1 [76800/81276 (95%)]	Loss: 6.220542 LR 2.93e-04
	 Magnitude of data 1.338e+06 output 1.603e+05 target 1.338e+06
Train Epoch: 1 [77440/81276 (95%)]	Loss: 6.097989 LR 2.93e-04
	 Magnitude of data 1.279e+06 output 1.684e+05 target 1.279e+06
Train Epoch: 1 [78080/81276 (96%)]	Loss: 6.077695 LR 2.93e-04
	 Magnitude of data 1.287e+06 output 1.646e+05 target 1.287e+06
Train Epoch: 1 [78720/81276 (97%)]	Loss: 6.246394 LR 2.93e-04
	 Magnitude of data 1.253e+06 output 1.625e+05 target 1.253e+06
Train Epoch: 1 [79360/81276 (98%)]	Loss: 6.373340 LR 2.93e-04
	 Magnitude of data 1.327e+06 output 1.620e+05 target 1.327e+06
Train Epoch: 1 [80000/81276 (99%)]	Loss: 6.300158 LR 2.93e-04
	 Magnitude of data 1.478e+06 output 1.640e+05 target 1.478e+06
Train Epoch: 1 [80640/81276 (99%)]	Loss: 6.153925 LR 2.93e-04
	 Magnitude of data 1.218e+06 output 1.691e+05 target 1.218e+06
Train Epoch: 1 [81216/81276 (100%)]	Loss: 5.991578 LR 2.93e-04
Test set: Average loss: 6.13874545
Train Epoch: 2 [0/81276 (0%)]	Loss: 6.229196 LR 2.93e-04
	 Magnitude of data 1.348e+06 output 1.684e+05 target 1.348e+06
Train Epoch: 2 [640/81276 (1%)]	Loss: 6.136870 LR 2.93e-04
	 Magnitude of data 1.314e+06 output 1.713e+05 target 1.314e+06
Train Epoch: 2 [1280/81276 (2%)]	Loss: 6.335991 LR 2.92e-04
	 Magnitude of data 1.495e+06 output 1.674e+05 target 1.495e+06
Train Epoch: 2 [1920/81276 (2%)]	Loss: 6.115485 LR 2.92e-04
	 Magnitude of data 1.218e+06 output 1.693e+05 target 1.218e+06
Train Epoch: 2 [2560/81276 (3%)]	Loss: 5.889680 LR 2.92e-04
	 Magnitude of data 1.281e+06 output 1.641e+05 target 1.281e+06
Train Epoch: 2 [3200/81276 (4%)]	Loss: 5.859994 LR 2.92e-04
	 Magnitude of data 1.317e+06 output 1.694e+05 target 1.317e+06
Train Epoch: 2 [3840/81276 (5%)]	Loss: 5.939661 LR 2.92e-04
	 Magnitude of data 1.281e+06 output 1.705e+05 target 1.281e+06
Train Epoch: 2 [4480/81276 (6%)]	Loss: 5.951853 LR 2.92e-04
	 Magnitude of data 1.306e+06 output 1.747e+05 target 1.306e+06
Train Epoch: 2 [5120/81276 (6%)]	Loss: 6.026340 LR 2.92e-04
	 Magnitude of data 1.360e+06 output 1.763e+05 target 1.360e+06
Train Epoch: 2 [5760/81276 (7%)]	Loss: 6.121489 LR 2.92e-04
	 Magnitude of data 1.349e+06 output 1.681e+05 target 1.350e+06
Train Epoch: 2 [6400/81276 (8%)]	Loss: 6.228902 LR 2.91e-04
	 Magnitude of data 1.285e+06 output 1.670e+05 target 1.286e+06
Train Epoch: 2 [7040/81276 (9%)]	Loss: 6.056899 LR 2.91e-04
	 Magnitude of data 1.278e+06 output 1.658e+05 target 1.278e+06
Train Epoch: 2 [7680/81276 (9%)]	Loss: 6.247286 LR 2.91e-04
	 Magnitude of data 1.419e+06 output 1.572e+05 target 1.419e+06
Train Epoch: 2 [8320/81276 (10%)]	Loss: 6.195965 LR 2.91e-04
	 Magnitude of data 1.234e+06 output 1.607e+05 target 1.234e+06
Train Epoch: 2 [8960/81276 (11%)]	Loss: 6.240677 LR 2.91e-04
	 Magnitude of data 1.348e+06 output 1.665e+05 target 1.348e+06
Train Epoch: 2 [9600/81276 (12%)]	Loss: 6.044107 LR 2.91e-04
	 Magnitude of data 1.364e+06 output 1.641e+05 target 1.364e+06
Train Epoch: 2 [10240/81276 (13%)]	Loss: 6.023543 LR 2.91e-04
	 Magnitude of data 1.276e+06 output 1.684e+05 target 1.276e+06
Train Epoch: 2 [10880/81276 (13%)]	Loss: 5.955532 LR 2.91e-04
	 Magnitude of data 1.240e+06 output 1.794e+05 target 1.240e+06
Train Epoch: 2 [11520/81276 (14%)]	Loss: 6.024307 LR 2.90e-04
	 Magnitude of data 1.342e+06 output 1.652e+05 target 1.342e+06
Train Epoch: 2 [12160/81276 (15%)]	Loss: 6.010030 LR 2.90e-04
	 Magnitude of data 1.359e+06 output 1.738e+05 target 1.359e+06
Train Epoch: 2 [12800/81276 (16%)]	Loss: 6.053604 LR 2.90e-04
	 Magnitude of data 1.366e+06 output 1.730e+05 target 1.366e+06
Train Epoch: 2 [13440/81276 (17%)]	Loss: 5.838719 LR 2.90e-04
	 Magnitude of data 1.241e+06 output 1.759e+05 target 1.241e+06
Train Epoch: 2 [14080/81276 (17%)]	Loss: 6.120467 LR 2.90e-04
	 Magnitude of data 1.396e+06 output 1.752e+05 target 1.396e+06
Train Epoch: 2 [14720/81276 (18%)]	Loss: 6.226982 LR 2.90e-04
	 Magnitude of data 1.450e+06 output 1.709e+05 target 1.450e+06
Train Epoch: 2 [15360/81276 (19%)]	Loss: 6.263256 LR 2.90e-04
	 Magnitude of data 1.387e+06 output 1.737e+05 target 1.387e+06
Train Epoch: 2 [16000/81276 (20%)]	Loss: 6.034574 LR 2.90e-04
	 Magnitude of data 1.371e+06 output 1.710e+05 target 1.371e+06
Train Epoch: 2 [16640/81276 (20%)]	Loss: 5.902626 LR 2.89e-04
	 Magnitude of data 1.274e+06 output 1.785e+05 target 1.274e+06
Train Epoch: 2 [17280/81276 (21%)]	Loss: 6.258998 LR 2.89e-04
	 Magnitude of data 1.443e+06 output 1.727e+05 target 1.442e+06
Train Epoch: 2 [17920/81276 (22%)]	Loss: 6.046280 LR 2.89e-04
	 Magnitude of data 1.267e+06 output 1.725e+05 target 1.266e+06
Train Epoch: 2 [18560/81276 (23%)]	Loss: 5.876020 LR 2.89e-04
	 Magnitude of data 1.246e+06 output 1.789e+05 target 1.246e+06
Train Epoch: 2 [19200/81276 (24%)]	Loss: 5.891969 LR 2.89e-04
	 Magnitude of data 1.254e+06 output 1.812e+05 target 1.254e+06
Train Epoch: 2 [19840/81276 (24%)]	Loss: 5.995107 LR 2.89e-04
	 Magnitude of data 1.331e+06 output 1.761e+05 target 1.331e+06
Train Epoch: 2 [20480/81276 (25%)]	Loss: 5.936477 LR 2.89e-04
	 Magnitude of data 1.190e+06 output 1.726e+05 target 1.190e+06
Train Epoch: 2 [21120/81276 (26%)]	Loss: 6.036624 LR 2.88e-04
	 Magnitude of data 1.290e+06 output 1.704e+05 target 1.290e+06
Train Epoch: 2 [21760/81276 (27%)]	Loss: 5.989456 LR 2.88e-04
	 Magnitude of data 1.386e+06 output 1.701e+05 target 1.385e+06
Train Epoch: 2 [22400/81276 (28%)]	Loss: 5.835526 LR 2.88e-04
	 Magnitude of data 1.271e+06 output 1.776e+05 target 1.271e+06
Train Epoch: 2 [23040/81276 (28%)]	Loss: 6.187915 LR 2.88e-04
	 Magnitude of data 1.259e+06 output 1.680e+05 target 1.259e+06
Train Epoch: 2 [23680/81276 (29%)]	Loss: 5.903207 LR 2.88e-04
	 Magnitude of data 1.231e+06 output 1.824e+05 target 1.231e+06
Train Epoch: 2 [24320/81276 (30%)]	Loss: 6.090552 LR 2.88e-04
	 Magnitude of data 1.323e+06 output 1.807e+05 target 1.322e+06
Train Epoch: 2 [24960/81276 (31%)]	Loss: 5.747993 LR 2.88e-04
	 Magnitude of data 1.341e+06 output 1.738e+05 target 1.341e+06
Train Epoch: 2 [25600/81276 (32%)]	Loss: 5.778668 LR 2.87e-04
	 Magnitude of data 1.299e+06 output 1.760e+05 target 1.299e+06
Train Epoch: 2 [26240/81276 (32%)]	Loss: 6.069662 LR 2.87e-04
	 Magnitude of data 1.329e+06 output 1.791e+05 target 1.329e+06
Train Epoch: 2 [26880/81276 (33%)]	Loss: 5.627655 LR 2.87e-04
	 Magnitude of data 1.258e+06 output 1.780e+05 target 1.258e+06
Train Epoch: 2 [27520/81276 (34%)]	Loss: 5.979400 LR 2.87e-04
	 Magnitude of data 1.280e+06 output 1.786e+05 target 1.280e+06
Train Epoch: 2 [28160/81276 (35%)]	Loss: 5.922868 LR 2.87e-04
	 Magnitude of data 1.353e+06 output 1.748e+05 target 1.353e+06
Train Epoch: 2 [28800/81276 (35%)]	Loss: 5.598196 LR 2.87e-04
	 Magnitude of data 1.316e+06 output 1.796e+05 target 1.316e+06
Train Epoch: 2 [29440/81276 (36%)]	Loss: 5.941666 LR 2.86e-04
	 Magnitude of data 1.295e+06 output 1.720e+05 target 1.295e+06
Train Epoch: 2 [30080/81276 (37%)]	Loss: 5.828807 LR 2.86e-04
	 Magnitude of data 1.290e+06 output 1.775e+05 target 1.290e+06
Train Epoch: 2 [30720/81276 (38%)]	Loss: 5.735894 LR 2.86e-04
	 Magnitude of data 1.320e+06 output 1.743e+05 target 1.320e+06
Train Epoch: 2 [31360/81276 (39%)]	Loss: 5.840978 LR 2.86e-04
	 Magnitude of data 1.397e+06 output 1.727e+05 target 1.397e+06
Train Epoch: 2 [32000/81276 (39%)]	Loss: 5.900521 LR 2.86e-04
	 Magnitude of data 1.283e+06 output 1.765e+05 target 1.283e+06
Train Epoch: 2 [32640/81276 (40%)]	Loss: 6.204292 LR 2.86e-04
	 Magnitude of data 1.354e+06 output 1.715e+05 target 1.354e+06
Train Epoch: 2 [33280/81276 (41%)]	Loss: 5.962975 LR 2.86e-04
	 Magnitude of data 1.271e+06 output 1.781e+05 target 1.271e+06
Train Epoch: 2 [33920/81276 (42%)]	Loss: 5.922783 LR 2.85e-04
	 Magnitude of data 1.296e+06 output 1.795e+05 target 1.296e+06
Train Epoch: 2 [34560/81276 (43%)]	Loss: 5.984522 LR 2.85e-04
	 Magnitude of data 1.312e+06 output 1.771e+05 target 1.312e+06
Train Epoch: 2 [35200/81276 (43%)]	Loss: 6.345074 LR 2.85e-04
	 Magnitude of data 1.383e+06 output 1.674e+05 target 1.383e+06
Train Epoch: 2 [35840/81276 (44%)]	Loss: 5.880538 LR 2.85e-04
	 Magnitude of data 1.314e+06 output 1.796e+05 target 1.314e+06
Train Epoch: 2 [36480/81276 (45%)]	Loss: 5.961661 LR 2.85e-04
	 Magnitude of data 1.359e+06 output 1.764e+05 target 1.359e+06
Train Epoch: 2 [37120/81276 (46%)]	Loss: 5.487500 LR 2.85e-04
	 Magnitude of data 1.273e+06 output 1.792e+05 target 1.273e+06
Train Epoch: 2 [37760/81276 (46%)]	Loss: 5.683892 LR 2.84e-04
	 Magnitude of data 1.261e+06 output 1.742e+05 target 1.261e+06
Train Epoch: 2 [38400/81276 (47%)]	Loss: 5.565697 LR 2.84e-04
	 Magnitude of data 1.358e+06 output 1.781e+05 target 1.358e+06
Train Epoch: 2 [39040/81276 (48%)]	Loss: 5.867039 LR 2.84e-04
	 Magnitude of data 1.339e+06 output 1.837e+05 target 1.339e+06
Train Epoch: 2 [39680/81276 (49%)]	Loss: 5.629828 LR 2.84e-04
	 Magnitude of data 1.233e+06 output 1.815e+05 target 1.233e+06
Train Epoch: 2 [40320/81276 (50%)]	Loss: 5.828883 LR 2.84e-04
	 Magnitude of data 1.395e+06 output 1.738e+05 target 1.395e+06
Train Epoch: 2 [40960/81276 (50%)]	Loss: 5.751840 LR 2.84e-04
	 Magnitude of data 1.324e+06 output 1.781e+05 target 1.324e+06
Train Epoch: 2 [41600/81276 (51%)]	Loss: 5.811887 LR 2.83e-04
	 Magnitude of data 1.367e+06 output 1.671e+05 target 1.367e+06
Train Epoch: 2 [42240/81276 (52%)]	Loss: 5.808342 LR 2.83e-04
	 Magnitude of data 1.301e+06 output 1.759e+05 target 1.301e+06
Train Epoch: 2 [42880/81276 (53%)]	Loss: 5.482203 LR 2.83e-04
	 Magnitude of data 1.223e+06 output 1.778e+05 target 1.223e+06
Train Epoch: 2 [43520/81276 (54%)]	Loss: 5.778110 LR 2.83e-04
	 Magnitude of data 1.285e+06 output 1.667e+05 target 1.285e+06
Train Epoch: 2 [44160/81276 (54%)]	Loss: 5.708258 LR 2.83e-04
	 Magnitude of data 1.281e+06 output 1.806e+05 target 1.281e+06
Train Epoch: 2 [44800/81276 (55%)]	Loss: 5.661579 LR 2.83e-04
	 Magnitude of data 1.413e+06 output 1.783e+05 target 1.413e+06
Train Epoch: 2 [45440/81276 (56%)]	Loss: 5.822836 LR 2.82e-04
	 Magnitude of data 1.310e+06 output 1.770e+05 target 1.310e+06
Train Epoch: 2 [46080/81276 (57%)]	Loss: 5.940837 LR 2.82e-04
	 Magnitude of data 1.308e+06 output 1.795e+05 target 1.308e+06
Train Epoch: 2 [46720/81276 (58%)]	Loss: 5.909489 LR 2.82e-04
	 Magnitude of data 1.370e+06 output 1.806e+05 target 1.371e+06
Train Epoch: 2 [47360/81276 (58%)]	Loss: 5.577816 LR 2.82e-04
	 Magnitude of data 1.361e+06 output 1.777e+05 target 1.361e+06
Train Epoch: 2 [48000/81276 (59%)]	Loss: 5.884056 LR 2.82e-04
	 Magnitude of data 1.285e+06 output 1.756e+05 target 1.286e+06
Train Epoch: 2 [48640/81276 (60%)]	Loss: 5.553785 LR 2.81e-04
	 Magnitude of data 1.249e+06 output 1.797e+05 target 1.249e+06
Train Epoch: 2 [49280/81276 (61%)]	Loss: 5.670034 LR 2.81e-04
	 Magnitude of data 1.305e+06 output 1.777e+05 target 1.305e+06
Train Epoch: 2 [49920/81276 (61%)]	Loss: 5.676087 LR 2.81e-04
	 Magnitude of data 1.259e+06 output 1.722e+05 target 1.259e+06
Train Epoch: 2 [50560/81276 (62%)]	Loss: 5.765787 LR 2.81e-04
	 Magnitude of data 1.274e+06 output 1.787e+05 target 1.273e+06
Train Epoch: 2 [51200/81276 (63%)]	Loss: 5.528906 LR 2.81e-04
	 Magnitude of data 1.319e+06 output 1.861e+05 target 1.319e+06
Train Epoch: 2 [51840/81276 (64%)]	Loss: 5.765652 LR 2.81e-04
	 Magnitude of data 1.351e+06 output 1.829e+05 target 1.351e+06
Train Epoch: 2 [52480/81276 (65%)]	Loss: 5.497930 LR 2.80e-04
	 Magnitude of data 1.318e+06 output 1.816e+05 target 1.318e+06
Train Epoch: 2 [53120/81276 (65%)]	Loss: 5.493537 LR 2.80e-04
	 Magnitude of data 1.274e+06 output 1.817e+05 target 1.274e+06
Train Epoch: 2 [53760/81276 (66%)]	Loss: 5.810682 LR 2.80e-04
	 Magnitude of data 1.363e+06 output 1.753e+05 target 1.363e+06
Train Epoch: 2 [54400/81276 (67%)]	Loss: 5.656594 LR 2.80e-04
	 Magnitude of data 1.305e+06 output 1.767e+05 target 1.305e+06
Train Epoch: 2 [55040/81276 (68%)]	Loss: 5.698214 LR 2.80e-04
	 Magnitude of data 1.319e+06 output 1.831e+05 target 1.318e+06
Train Epoch: 2 [55680/81276 (69%)]	Loss: 5.824199 LR 2.79e-04
	 Magnitude of data 1.197e+06 output 1.811e+05 target 1.197e+06
Train Epoch: 2 [56320/81276 (69%)]	Loss: 5.641410 LR 2.79e-04
	 Magnitude of data 1.373e+06 output 1.779e+05 target 1.373e+06
Train Epoch: 2 [56960/81276 (70%)]	Loss: 5.711908 LR 2.79e-04
	 Magnitude of data 1.323e+06 output 1.749e+05 target 1.323e+06
Train Epoch: 2 [57600/81276 (71%)]	Loss: 5.559011 LR 2.79e-04
	 Magnitude of data 1.223e+06 output 1.802e+05 target 1.223e+06
Train Epoch: 2 [58240/81276 (72%)]	Loss: 5.897416 LR 2.79e-04
	 Magnitude of data 1.344e+06 output 1.681e+05 target 1.344e+06
Train Epoch: 2 [58880/81276 (72%)]	Loss: 5.815943 LR 2.78e-04
	 Magnitude of data 1.282e+06 output 1.702e+05 target 1.282e+06
Train Epoch: 2 [59520/81276 (73%)]	Loss: 5.480831 LR 2.78e-04
	 Magnitude of data 1.214e+06 output 1.842e+05 target 1.214e+06
Train Epoch: 2 [60160/81276 (74%)]	Loss: 5.722168 LR 2.78e-04
	 Magnitude of data 1.322e+06 output 1.836e+05 target 1.323e+06
Train Epoch: 2 [60800/81276 (75%)]	Loss: 5.661348 LR 2.78e-04
	 Magnitude of data 1.290e+06 output 1.813e+05 target 1.290e+06
Train Epoch: 2 [61440/81276 (76%)]	Loss: 5.526550 LR 2.78e-04
	 Magnitude of data 1.354e+06 output 1.746e+05 target 1.354e+06
Train Epoch: 2 [62080/81276 (76%)]	Loss: 5.494892 LR 2.78e-04
	 Magnitude of data 1.348e+06 output 1.853e+05 target 1.348e+06
Train Epoch: 2 [62720/81276 (77%)]	Loss: 5.655753 LR 2.77e-04
	 Magnitude of data 1.358e+06 output 1.800e+05 target 1.358e+06
Train Epoch: 2 [63360/81276 (78%)]	Loss: 5.780716 LR 2.77e-04
	 Magnitude of data 1.367e+06 output 1.707e+05 target 1.367e+06
Train Epoch: 2 [64000/81276 (79%)]	Loss: 5.483820 LR 2.77e-04
	 Magnitude of data 1.341e+06 output 1.710e+05 target 1.341e+06
Train Epoch: 2 [64640/81276 (80%)]	Loss: 5.756748 LR 2.77e-04
	 Magnitude of data 1.274e+06 output 1.758e+05 target 1.274e+06
Train Epoch: 2 [65280/81276 (80%)]	Loss: 5.487464 LR 2.77e-04
	 Magnitude of data 1.638e+06 output 1.834e+05 target 1.638e+06
Train Epoch: 2 [65920/81276 (81%)]	Loss: 5.488626 LR 2.76e-04
	 Magnitude of data 1.178e+06 output 1.850e+05 target 1.178e+06
Train Epoch: 2 [66560/81276 (82%)]	Loss: 5.797720 LR 2.76e-04
	 Magnitude of data 1.313e+06 output 1.760e+05 target 1.313e+06
Train Epoch: 2 [67200/81276 (83%)]	Loss: 5.619603 LR 2.76e-04
	 Magnitude of data 1.305e+06 output 1.792e+05 target 1.305e+06
Train Epoch: 2 [67840/81276 (84%)]	Loss: 5.371480 LR 2.76e-04
	 Magnitude of data 1.243e+06 output 1.749e+05 target 1.243e+06
Train Epoch: 2 [68480/81276 (84%)]	Loss: 5.604660 LR 2.76e-04
	 Magnitude of data 1.389e+06 output 1.805e+05 target 1.389e+06
Train Epoch: 2 [69120/81276 (85%)]	Loss: 5.660609 LR 2.75e-04
	 Magnitude of data 1.368e+06 output 1.810e+05 target 1.368e+06
Train Epoch: 2 [69760/81276 (86%)]	Loss: 5.765265 LR 2.75e-04
	 Magnitude of data 1.272e+06 output 1.820e+05 target 1.272e+06
Train Epoch: 2 [70400/81276 (87%)]	Loss: 5.786864 LR 2.75e-04
	 Magnitude of data 1.307e+06 output 1.762e+05 target 1.307e+06
Train Epoch: 2 [71040/81276 (87%)]	Loss: 5.865081 LR 2.75e-04
	 Magnitude of data 1.298e+06 output 1.721e+05 target 1.298e+06
Train Epoch: 2 [71680/81276 (88%)]	Loss: 5.665123 LR 2.75e-04
	 Magnitude of data 1.285e+06 output 1.774e+05 target 1.285e+06
Train Epoch: 2 [72320/81276 (89%)]	Loss: 5.518636 LR 2.74e-04
	 Magnitude of data 1.372e+06 output 1.771e+05 target 1.372e+06
Train Epoch: 2 [72960/81276 (90%)]	Loss: 5.654770 LR 2.74e-04
	 Magnitude of data 1.268e+06 output 1.771e+05 target 1.268e+06
Train Epoch: 2 [73600/81276 (91%)]	Loss: 5.452302 LR 2.74e-04
	 Magnitude of data 1.248e+06 output 1.771e+05 target 1.248e+06
Train Epoch: 2 [74240/81276 (91%)]	Loss: 5.734437 LR 2.74e-04
	 Magnitude of data 1.344e+06 output 1.768e+05 target 1.344e+06
Train Epoch: 2 [74880/81276 (92%)]	Loss: 5.880675 LR 2.73e-04
	 Magnitude of data 1.405e+06 output 1.767e+05 target 1.405e+06
Train Epoch: 2 [75520/81276 (93%)]	Loss: 5.567335 LR 2.73e-04
	 Magnitude of data 1.326e+06 output 1.750e+05 target 1.326e+06
Train Epoch: 2 [76160/81276 (94%)]	Loss: 5.601128 LR 2.73e-04
	 Magnitude of data 1.291e+06 output 1.764e+05 target 1.291e+06
Train Epoch: 2 [76800/81276 (95%)]	Loss: 5.658701 LR 2.73e-04
	 Magnitude of data 1.338e+06 output 1.701e+05 target 1.338e+06
Train Epoch: 2 [77440/81276 (95%)]	Loss: 5.538147 LR 2.73e-04
	 Magnitude of data 1.279e+06 output 1.786e+05 target 1.279e+06
Train Epoch: 2 [78080/81276 (96%)]	Loss: 5.494227 LR 2.72e-04
	 Magnitude of data 1.287e+06 output 1.754e+05 target 1.287e+06
Train Epoch: 2 [78720/81276 (97%)]	Loss: 5.643817 LR 2.72e-04
	 Magnitude of data 1.253e+06 output 1.809e+05 target 1.253e+06
Train Epoch: 2 [79360/81276 (98%)]	Loss: 5.866437 LR 2.72e-04
	 Magnitude of data 1.327e+06 output 1.754e+05 target 1.327e+06
Train Epoch: 2 [80000/81276 (99%)]	Loss: 5.703192 LR 2.72e-04
	 Magnitude of data 1.478e+06 output 1.771e+05 target 1.478e+06
Train Epoch: 2 [80640/81276 (99%)]	Loss: 5.612873 LR 2.72e-04
	 Magnitude of data 1.218e+06 output 1.808e+05 target 1.218e+06
Train Epoch: 2 [81216/81276 (100%)]	Loss: 5.391578 LR 2.71e-04
Test set: Average loss: 5.65136180
Train Epoch: 3 [0/81276 (0%)]	Loss: 5.712053 LR 2.71e-04
	 Magnitude of data 1.348e+06 output 1.769e+05 target 1.348e+06
Train Epoch: 3 [640/81276 (1%)]	Loss: 5.597012 LR 2.71e-04
	 Magnitude of data 1.314e+06 output 1.825e+05 target 1.314e+06
Train Epoch: 3 [1280/81276 (2%)]	Loss: 5.828501 LR 2.71e-04
	 Magnitude of data 1.495e+06 output 1.758e+05 target 1.495e+06
Train Epoch: 3 [1920/81276 (2%)]	Loss: 5.616308 LR 2.71e-04
	 Magnitude of data 1.218e+06 output 1.853e+05 target 1.218e+06
Train Epoch: 3 [2560/81276 (3%)]	Loss: 5.327038 LR 2.70e-04
	 Magnitude of data 1.281e+06 output 1.771e+05 target 1.281e+06
Train Epoch: 3 [3200/81276 (4%)]	Loss: 5.295721 LR 2.70e-04
	 Magnitude of data 1.317e+06 output 1.796e+05 target 1.317e+06
Train Epoch: 3 [3840/81276 (5%)]	Loss: 5.371956 LR 2.70e-04
	 Magnitude of data 1.281e+06 output 1.828e+05 target 1.281e+06
Train Epoch: 3 [4480/81276 (6%)]	Loss: 5.426715 LR 2.70e-04
	 Magnitude of data 1.306e+06 output 1.869e+05 target 1.306e+06
Train Epoch: 3 [5120/81276 (6%)]	Loss: 5.483860 LR 2.70e-04
	 Magnitude of data 1.360e+06 output 1.839e+05 target 1.360e+06
Train Epoch: 3 [5760/81276 (7%)]	Loss: 5.650686 LR 2.69e-04
	 Magnitude of data 1.349e+06 output 1.814e+05 target 1.350e+06
Train Epoch: 3 [6400/81276 (8%)]	Loss: 5.684842 LR 2.69e-04
	 Magnitude of data 1.285e+06 output 1.817e+05 target 1.286e+06
Train Epoch: 3 [7040/81276 (9%)]	Loss: 5.549695 LR 2.69e-04
	 Magnitude of data 1.278e+06 output 1.763e+05 target 1.278e+06
Train Epoch: 3 [7680/81276 (9%)]	Loss: 5.687433 LR 2.69e-04
	 Magnitude of data 1.419e+06 output 1.676e+05 target 1.419e+06
Train Epoch: 3 [8320/81276 (10%)]	Loss: 5.737102 LR 2.68e-04
	 Magnitude of data 1.234e+06 output 1.650e+05 target 1.234e+06
Train Epoch: 3 [8960/81276 (11%)]	Loss: 5.768610 LR 2.68e-04
	 Magnitude of data 1.348e+06 output 1.747e+05 target 1.348e+06
Train Epoch: 3 [9600/81276 (12%)]	Loss: 5.568853 LR 2.68e-04
	 Magnitude of data 1.364e+06 output 1.747e+05 target 1.364e+06
Train Epoch: 3 [10240/81276 (13%)]	Loss: 5.528077 LR 2.68e-04
	 Magnitude of data 1.276e+06 output 1.755e+05 target 1.276e+06
Train Epoch: 3 [10880/81276 (13%)]	Loss: 5.420706 LR 2.68e-04
	 Magnitude of data 1.240e+06 output 1.834e+05 target 1.240e+06
Train Epoch: 3 [11520/81276 (14%)]	Loss: 5.523213 LR 2.67e-04
	 Magnitude of data 1.342e+06 output 1.745e+05 target 1.342e+06
Train Epoch: 3 [12160/81276 (15%)]	Loss: 5.462870 LR 2.67e-04
	 Magnitude of data 1.359e+06 output 1.809e+05 target 1.359e+06
Train Epoch: 3 [12800/81276 (16%)]	Loss: 5.563722 LR 2.67e-04
	 Magnitude of data 1.366e+06 output 1.834e+05 target 1.366e+06
Train Epoch: 3 [13440/81276 (17%)]	Loss: 5.314656 LR 2.67e-04
	 Magnitude of data 1.241e+06 output 1.843e+05 target 1.241e+06
Train Epoch: 3 [14080/81276 (17%)]	Loss: 5.653009 LR 2.66e-04
	 Magnitude of data 1.396e+06 output 1.822e+05 target 1.396e+06
Train Epoch: 3 [14720/81276 (18%)]	Loss: 5.746363 LR 2.66e-04
	 Magnitude of data 1.450e+06 output 1.809e+05 target 1.450e+06
Train Epoch: 3 [15360/81276 (19%)]	Loss: 5.753610 LR 2.66e-04
	 Magnitude of data 1.387e+06 output 1.786e+05 target 1.387e+06
Train Epoch: 3 [16000/81276 (20%)]	Loss: 5.518336 LR 2.66e-04
	 Magnitude of data 1.371e+06 output 1.786e+05 target 1.371e+06
Train Epoch: 3 [16640/81276 (20%)]	Loss: 5.432237 LR 2.65e-04
	 Magnitude of data 1.274e+06 output 1.806e+05 target 1.274e+06
Train Epoch: 3 [17280/81276 (21%)]	Loss: 5.733025 LR 2.65e-04
	 Magnitude of data 1.443e+06 output 1.751e+05 target 1.442e+06
Train Epoch: 3 [17920/81276 (22%)]	Loss: 5.583586 LR 2.65e-04
	 Magnitude of data 1.267e+06 output 1.787e+05 target 1.266e+06
Train Epoch: 3 [18560/81276 (23%)]	Loss: 5.485764 LR 2.65e-04
	 Magnitude of data 1.246e+06 output 1.884e+05 target 1.246e+06
Train Epoch: 3 [19200/81276 (24%)]	Loss: 5.367533 LR 2.64e-04
	 Magnitude of data 1.254e+06 output 1.867e+05 target 1.254e+06
Train Epoch: 3 [19840/81276 (24%)]	Loss: 5.464994 LR 2.64e-04
	 Magnitude of data 1.331e+06 output 1.834e+05 target 1.331e+06
Train Epoch: 3 [20480/81276 (25%)]	Loss: 5.366897 LR 2.64e-04
	 Magnitude of data 1.190e+06 output 1.771e+05 target 1.190e+06
Train Epoch: 3 [21120/81276 (26%)]	Loss: 5.624380 LR 2.64e-04
	 Magnitude of data 1.290e+06 output 1.752e+05 target 1.290e+06
Train Epoch: 3 [21760/81276 (27%)]	Loss: 5.483502 LR 2.63e-04
	 Magnitude of data 1.386e+06 output 1.765e+05 target 1.385e+06
Train Epoch: 3 [22400/81276 (28%)]	Loss: 5.328075 LR 2.63e-04
	 Magnitude of data 1.271e+06 output 1.894e+05 target 1.271e+06
Train Epoch: 3 [23040/81276 (28%)]	Loss: 5.775491 LR 2.63e-04
	 Magnitude of data 1.259e+06 output 1.735e+05 target 1.259e+06
Train Epoch: 3 [23680/81276 (29%)]	Loss: 5.436507 LR 2.63e-04
	 Magnitude of data 1.231e+06 output 1.856e+05 target 1.231e+06
Train Epoch: 3 [24320/81276 (30%)]	Loss: 5.671325 LR 2.63e-04
	 Magnitude of data 1.323e+06 output 1.885e+05 target 1.322e+06
Train Epoch: 3 [24960/81276 (31%)]	Loss: 5.329150 LR 2.62e-04
	 Magnitude of data 1.341e+06 output 1.855e+05 target 1.341e+06
Train Epoch: 3 [25600/81276 (32%)]	Loss: 5.309764 LR 2.62e-04
	 Magnitude of data 1.299e+06 output 1.863e+05 target 1.299e+06
Train Epoch: 3 [26240/81276 (32%)]	Loss: 5.666969 LR 2.62e-04
	 Magnitude of data 1.329e+06 output 1.871e+05 target 1.329e+06
Train Epoch: 3 [26880/81276 (33%)]	Loss: 5.144211 LR 2.62e-04
	 Magnitude of data 1.258e+06 output 1.840e+05 target 1.258e+06
Train Epoch: 3 [27520/81276 (34%)]	Loss: 5.533518 LR 2.61e-04
	 Magnitude of data 1.280e+06 output 1.866e+05 target 1.280e+06
Train Epoch: 3 [28160/81276 (35%)]	Loss: 5.459860 LR 2.61e-04
	 Magnitude of data 1.353e+06 output 1.820e+05 target 1.353e+06
Train Epoch: 3 [28800/81276 (35%)]	Loss: 5.008033 LR 2.61e-04
	 Magnitude of data 1.316e+06 output 1.852e+05 target 1.316e+06
Train Epoch: 3 [29440/81276 (36%)]	Loss: 5.527964 LR 2.61e-04
	 Magnitude of data 1.295e+06 output 1.777e+05 target 1.295e+06
Train Epoch: 3 [30080/81276 (37%)]	Loss: 5.340802 LR 2.60e-04
	 Magnitude of data 1.290e+06 output 1.829e+05 target 1.290e+06
Train Epoch: 3 [30720/81276 (38%)]	Loss: 5.271649 LR 2.60e-04
	 Magnitude of data 1.320e+06 output 1.835e+05 target 1.320e+06
Train Epoch: 3 [31360/81276 (39%)]	Loss: 5.444714 LR 2.60e-04
	 Magnitude of data 1.397e+06 output 1.804e+05 target 1.397e+06
Train Epoch: 3 [32000/81276 (39%)]	Loss: 5.467542 LR 2.60e-04
	 Magnitude of data 1.283e+06 output 1.782e+05 target 1.283e+06
Train Epoch: 3 [32640/81276 (40%)]	Loss: 5.803836 LR 2.59e-04
	 Magnitude of data 1.354e+06 output 1.748e+05 target 1.354e+06
Train Epoch: 3 [33280/81276 (41%)]	Loss: 5.551270 LR 2.59e-04
	 Magnitude of data 1.271e+06 output 1.807e+05 target 1.271e+06
Train Epoch: 3 [33920/81276 (42%)]	Loss: 5.490331 LR 2.59e-04
	 Magnitude of data 1.296e+06 output 1.829e+05 target 1.296e+06
Train Epoch: 3 [34560/81276 (43%)]	Loss: 5.566961 LR 2.58e-04
	 Magnitude of data 1.312e+06 output 1.823e+05 target 1.312e+06
Train Epoch: 3 [35200/81276 (43%)]	Loss: 5.959725 LR 2.58e-04
	 Magnitude of data 1.383e+06 output 1.709e+05 target 1.383e+06
Train Epoch: 3 [35840/81276 (44%)]	Loss: 5.501928 LR 2.58e-04
	 Magnitude of data 1.314e+06 output 1.826e+05 target 1.314e+06
Train Epoch: 3 [36480/81276 (45%)]	Loss: 5.541708 LR 2.58e-04
	 Magnitude of data 1.359e+06 output 1.824e+05 target 1.359e+06
Train Epoch: 3 [37120/81276 (46%)]	Loss: 5.052761 LR 2.57e-04
	 Magnitude of data 1.273e+06 output 1.893e+05 target 1.273e+06
Train Epoch: 3 [37760/81276 (46%)]	Loss: 5.252635 LR 2.57e-04
	 Magnitude of data 1.261e+06 output 1.807e+05 target 1.261e+06
Train Epoch: 3 [38400/81276 (47%)]	Loss: 5.149476 LR 2.57e-04
	 Magnitude of data 1.358e+06 output 1.860e+05 target 1.358e+06
Train Epoch: 3 [39040/81276 (48%)]	Loss: 5.421260 LR 2.57e-04
	 Magnitude of data 1.339e+06 output 1.843e+05 target 1.339e+06
Train Epoch: 3 [39680/81276 (49%)]	Loss: 5.180973 LR 2.56e-04
	 Magnitude of data 1.233e+06 output 1.859e+05 target 1.233e+06
Train Epoch: 3 [40320/81276 (50%)]	Loss: 5.383755 LR 2.56e-04
	 Magnitude of data 1.395e+06 output 1.833e+05 target 1.395e+06
Train Epoch: 3 [40960/81276 (50%)]	Loss: 5.319035 LR 2.56e-04
	 Magnitude of data 1.324e+06 output 1.840e+05 target 1.324e+06
Train Epoch: 3 [41600/81276 (51%)]	Loss: 5.425396 LR 2.56e-04
	 Magnitude of data 1.367e+06 output 1.760e+05 target 1.367e+06
Train Epoch: 3 [42240/81276 (52%)]	Loss: 5.416621 LR 2.55e-04
	 Magnitude of data 1.301e+06 output 1.817e+05 target 1.301e+06
Train Epoch: 3 [42880/81276 (53%)]	Loss: 5.025412 LR 2.55e-04
	 Magnitude of data 1.223e+06 output 1.820e+05 target 1.223e+06
Train Epoch: 3 [43520/81276 (54%)]	Loss: 5.406514 LR 2.55e-04
	 Magnitude of data 1.285e+06 output 1.752e+05 target 1.285e+06
Train Epoch: 3 [44160/81276 (54%)]	Loss: 5.319415 LR 2.55e-04
	 Magnitude of data 1.281e+06 output 1.888e+05 target 1.281e+06
Train Epoch: 3 [44800/81276 (55%)]	Loss: 5.202284 LR 2.54e-04
	 Magnitude of data 1.413e+06 output 1.911e+05 target 1.413e+06
Train Epoch: 3 [45440/81276 (56%)]	Loss: 5.425117 LR 2.54e-04
	 Magnitude of data 1.310e+06 output 1.824e+05 target 1.310e+06
Train Epoch: 3 [46080/81276 (57%)]	Loss: 5.568587 LR 2.54e-04
	 Magnitude of data 1.308e+06 output 1.843e+05 target 1.308e+06
Train Epoch: 3 [46720/81276 (58%)]	Loss: 5.528434 LR 2.54e-04
	 Magnitude of data 1.370e+06 output 1.858e+05 target 1.371e+06
Train Epoch: 3 [47360/81276 (58%)]	Loss: 5.214349 LR 2.53e-04
	 Magnitude of data 1.361e+06 output 1.885e+05 target 1.361e+06
Train Epoch: 3 [48000/81276 (59%)]	Loss: 5.547698 LR 2.53e-04
	 Magnitude of data 1.285e+06 output 1.787e+05 target 1.286e+06
Train Epoch: 3 [48640/81276 (60%)]	Loss: 5.175827 LR 2.53e-04
	 Magnitude of data 1.249e+06 output 1.874e+05 target 1.249e+06
Train Epoch: 3 [49280/81276 (61%)]	Loss: 5.299411 LR 2.52e-04
	 Magnitude of data 1.305e+06 output 1.879e+05 target 1.305e+06
Train Epoch: 3 [49920/81276 (61%)]	Loss: 5.271627 LR 2.52e-04
	 Magnitude of data 1.259e+06 output 1.786e+05 target 1.259e+06
Train Epoch: 3 [50560/81276 (62%)]	Loss: 5.373705 LR 2.52e-04
	 Magnitude of data 1.274e+06 output 1.835e+05 target 1.273e+06
Train Epoch: 3 [51200/81276 (63%)]	Loss: 5.171220 LR 2.52e-04
	 Magnitude of data 1.319e+06 output 1.950e+05 target 1.319e+06
Train Epoch: 3 [51840/81276 (64%)]	Loss: 5.346760 LR 2.51e-04
	 Magnitude of data 1.351e+06 output 1.889e+05 target 1.351e+06
Train Epoch: 3 [52480/81276 (65%)]	Loss: 5.088737 LR 2.51e-04
	 Magnitude of data 1.318e+06 output 1.883e+05 target 1.318e+06
Train Epoch: 3 [53120/81276 (65%)]	Loss: 5.111029 LR 2.51e-04
	 Magnitude of data 1.274e+06 output 1.857e+05 target 1.274e+06
Train Epoch: 3 [53760/81276 (66%)]	Loss: 5.413383 LR 2.51e-04
	 Magnitude of data 1.363e+06 output 1.813e+05 target 1.363e+06
Train Epoch: 3 [54400/81276 (67%)]	Loss: 5.260825 LR 2.50e-04
	 Magnitude of data 1.305e+06 output 1.840e+05 target 1.305e+06
Train Epoch: 3 [55040/81276 (68%)]	Loss: 5.317498 LR 2.50e-04
	 Magnitude of data 1.319e+06 output 1.857e+05 target 1.318e+06
Train Epoch: 3 [55680/81276 (69%)]	Loss: 5.462157 LR 2.50e-04
	 Magnitude of data 1.197e+06 output 1.857e+05 target 1.197e+06
Train Epoch: 3 [56320/81276 (69%)]	Loss: 5.256371 LR 2.49e-04
	 Magnitude of data 1.373e+06 output 1.802e+05 target 1.373e+06
Train Epoch: 3 [56960/81276 (70%)]	Loss: 5.358011 LR 2.49e-04
	 Magnitude of data 1.323e+06 output 1.788e+05 target 1.323e+06
Train Epoch: 3 [57600/81276 (71%)]	Loss: 5.163548 LR 2.49e-04
	 Magnitude of data 1.223e+06 output 1.865e+05 target 1.223e+06
Train Epoch: 3 [58240/81276 (72%)]	Loss: 5.556378 LR 2.49e-04
	 Magnitude of data 1.344e+06 output 1.740e+05 target 1.344e+06
Train Epoch: 3 [58880/81276 (72%)]	Loss: 5.485744 LR 2.48e-04
	 Magnitude of data 1.282e+06 output 1.711e+05 target 1.282e+06
Train Epoch: 3 [59520/81276 (73%)]	Loss: 5.123898 LR 2.48e-04
	 Magnitude of data 1.214e+06 output 1.879e+05 target 1.214e+06
Train Epoch: 3 [60160/81276 (74%)]	Loss: 5.374303 LR 2.48e-04
	 Magnitude of data 1.322e+06 output 1.864e+05 target 1.323e+06
Train Epoch: 3 [60800/81276 (75%)]	Loss: 5.296548 LR 2.47e-04
	 Magnitude of data 1.290e+06 output 1.845e+05 target 1.290e+06
Train Epoch: 3 [61440/81276 (76%)]	Loss: 5.127989 LR 2.47e-04
	 Magnitude of data 1.354e+06 output 1.814e+05 target 1.354e+06
Train Epoch: 3 [62080/81276 (76%)]	Loss: 5.079875 LR 2.47e-04
	 Magnitude of data 1.348e+06 output 1.831e+05 target 1.348e+06
Train Epoch: 3 [62720/81276 (77%)]	Loss: 5.293425 LR 2.47e-04
	 Magnitude of data 1.358e+06 output 1.828e+05 target 1.358e+06
Train Epoch: 3 [63360/81276 (78%)]	Loss: 5.416123 LR 2.46e-04
	 Magnitude of data 1.367e+06 output 1.738e+05 target 1.367e+06
Train Epoch: 3 [64000/81276 (79%)]	Loss: 5.090827 LR 2.46e-04
	 Magnitude of data 1.341e+06 output 1.769e+05 target 1.341e+06
Train Epoch: 3 [64640/81276 (80%)]	Loss: 5.440960 LR 2.46e-04
	 Magnitude of data 1.274e+06 output 1.855e+05 target 1.274e+06
Train Epoch: 3 [65280/81276 (80%)]	Loss: 5.033540 LR 2.45e-04
	 Magnitude of data 1.638e+06 output 1.904e+05 target 1.638e+06
Train Epoch: 3 [65920/81276 (81%)]	Loss: 5.084567 LR 2.45e-04
	 Magnitude of data 1.178e+06 output 1.887e+05 target 1.178e+06
Train Epoch: 3 [66560/81276 (82%)]	Loss: 5.432681 LR 2.45e-04
	 Magnitude of data 1.313e+06 output 1.857e+05 target 1.313e+06
Train Epoch: 3 [67200/81276 (83%)]	Loss: 5.250768 LR 2.45e-04
	 Magnitude of data 1.305e+06 output 1.837e+05 target 1.305e+06
Train Epoch: 3 [67840/81276 (84%)]	Loss: 5.012749 LR 2.44e-04
	 Magnitude of data 1.243e+06 output 1.809e+05 target 1.243e+06
Train Epoch: 3 [68480/81276 (84%)]	Loss: 5.240104 LR 2.44e-04
	 Magnitude of data 1.389e+06 output 1.839e+05 target 1.389e+06
Train Epoch: 3 [69120/81276 (85%)]	Loss: 5.308238 LR 2.44e-04
	 Magnitude of data 1.368e+06 output 1.888e+05 target 1.368e+06
Train Epoch: 3 [69760/81276 (86%)]	Loss: 5.438431 LR 2.43e-04
	 Magnitude of data 1.272e+06 output 1.844e+05 target 1.272e+06
Train Epoch: 3 [70400/81276 (87%)]	Loss: 5.451358 LR 2.43e-04
	 Magnitude of data 1.307e+06 output 1.812e+05 target 1.307e+06
Train Epoch: 3 [71040/81276 (87%)]	Loss: 5.533166 LR 2.43e-04
	 Magnitude of data 1.298e+06 output 1.768e+05 target 1.298e+06
Train Epoch: 3 [71680/81276 (88%)]	Loss: 5.326963 LR 2.43e-04
	 Magnitude of data 1.285e+06 output 1.829e+05 target 1.285e+06
Train Epoch: 3 [72320/81276 (89%)]	Loss: 5.157143 LR 2.42e-04
	 Magnitude of data 1.372e+06 output 1.824e+05 target 1.372e+06
Train Epoch: 3 [72960/81276 (90%)]	Loss: 5.345250 LR 2.42e-04
	 Magnitude of data 1.268e+06 output 1.836e+05 target 1.268e+06
Train Epoch: 3 [73600/81276 (91%)]	Loss: 5.119884 LR 2.42e-04
	 Magnitude of data 1.248e+06 output 1.860e+05 target 1.248e+06
Train Epoch: 3 [74240/81276 (91%)]	Loss: 5.399598 LR 2.41e-04
	 Magnitude of data 1.344e+06 output 1.806e+05 target 1.344e+06
Train Epoch: 3 [74880/81276 (92%)]	Loss: 5.544852 LR 2.41e-04
	 Magnitude of data 1.405e+06 output 1.820e+05 target 1.405e+06
Train Epoch: 3 [75520/81276 (93%)]	Loss: 5.231670 LR 2.41e-04
	 Magnitude of data 1.326e+06 output 1.801e+05 target 1.326e+06
Train Epoch: 3 [76160/81276 (94%)]	Loss: 5.266160 LR 2.40e-04
	 Magnitude of data 1.291e+06 output 1.756e+05 target 1.291e+06
Train Epoch: 3 [76800/81276 (95%)]	Loss: 5.312003 LR 2.40e-04
	 Magnitude of data 1.338e+06 output 1.744e+05 target 1.338e+06
Train Epoch: 3 [77440/81276 (95%)]	Loss: 5.193284 LR 2.40e-04
	 Magnitude of data 1.279e+06 output 1.786e+05 target 1.279e+06
Train Epoch: 3 [78080/81276 (96%)]	Loss: 5.138659 LR 2.40e-04
	 Magnitude of data 1.287e+06 output 1.787e+05 target 1.287e+06
Train Epoch: 3 [78720/81276 (97%)]	Loss: 5.226767 LR 2.39e-04
	 Magnitude of data 1.253e+06 output 1.848e+05 target 1.253e+06
Train Epoch: 3 [79360/81276 (98%)]	Loss: 5.570474 LR 2.39e-04
	 Magnitude of data 1.327e+06 output 1.831e+05 target 1.327e+06
Train Epoch: 3 [80000/81276 (99%)]	Loss: 5.337535 LR 2.39e-04
	 Magnitude of data 1.478e+06 output 1.787e+05 target 1.478e+06
Train Epoch: 3 [80640/81276 (99%)]	Loss: 5.288405 LR 2.38e-04
	 Magnitude of data 1.218e+06 output 1.823e+05 target 1.218e+06
Train Epoch: 3 [81216/81276 (100%)]	Loss: 5.040754 LR 2.38e-04
Test set: Average loss: 5.38019592
Train Epoch: 4 [0/81276 (0%)]	Loss: 5.394182 LR 2.38e-04
	 Magnitude of data 1.348e+06 output 1.800e+05 target 1.348e+06
Train Epoch: 4 [640/81276 (1%)]	Loss: 5.276689 LR 2.38e-04
	 Magnitude of data 1.314e+06 output 1.848e+05 target 1.314e+06
Train Epoch: 4 [1280/81276 (2%)]	Loss: 5.529067 LR 2.38e-04
	 Magnitude of data 1.495e+06 output 1.796e+05 target 1.495e+06
Train Epoch: 4 [1920/81276 (2%)]	Loss: 5.309497 LR 2.37e-04
	 Magnitude of data 1.218e+06 output 1.844e+05 target 1.218e+06
Train Epoch: 4 [2560/81276 (3%)]	Loss: 4.994433 LR 2.37e-04
	 Magnitude of data 1.281e+06 output 1.815e+05 target 1.281e+06
Train Epoch: 4 [3200/81276 (4%)]	Loss: 4.978554 LR 2.37e-04
	 Magnitude of data 1.317e+06 output 1.864e+05 target 1.317e+06
Train Epoch: 4 [3840/81276 (5%)]	Loss: 5.034402 LR 2.36e-04
	 Magnitude of data 1.281e+06 output 1.886e+05 target 1.281e+06
Train Epoch: 4 [4480/81276 (6%)]	Loss: 5.093769 LR 2.36e-04
	 Magnitude of data 1.306e+06 output 1.917e+05 target 1.306e+06
Train Epoch: 4 [5120/81276 (6%)]	Loss: 5.156027 LR 2.36e-04
	 Magnitude of data 1.360e+06 output 1.861e+05 target 1.360e+06
Train Epoch: 4 [5760/81276 (7%)]	Loss: 5.340550 LR 2.35e-04
	 Magnitude of data 1.349e+06 output 1.848e+05 target 1.350e+06
Train Epoch: 4 [6400/81276 (8%)]	Loss: 5.367932 LR 2.35e-04
	 Magnitude of data 1.285e+06 output 1.891e+05 target 1.286e+06
Train Epoch: 4 [7040/81276 (9%)]	Loss: 5.245250 LR 2.35e-04
	 Magnitude of data 1.278e+06 output 1.810e+05 target 1.278e+06
Train Epoch: 4 [7680/81276 (9%)]	Loss: 5.390271 LR 2.34e-04
	 Magnitude of data 1.419e+06 output 1.743e+05 target 1.419e+06
Train Epoch: 4 [8320/81276 (10%)]	Loss: 5.429296 LR 2.34e-04
	 Magnitude of data 1.234e+06 output 1.730e+05 target 1.234e+06
Train Epoch: 4 [8960/81276 (11%)]	Loss: 5.468297 LR 2.34e-04
	 Magnitude of data 1.348e+06 output 1.786e+05 target 1.348e+06
Train Epoch: 4 [9600/81276 (12%)]	Loss: 5.260908 LR 2.34e-04
	 Magnitude of data 1.364e+06 output 1.804e+05 target 1.364e+06
Train Epoch: 4 [10240/81276 (13%)]	Loss: 5.224139 LR 2.33e-04
	 Magnitude of data 1.276e+06 output 1.782e+05 target 1.276e+06
Train Epoch: 4 [10880/81276 (13%)]	Loss: 5.096958 LR 2.33e-04
	 Magnitude of data 1.240e+06 output 1.819e+05 target 1.240e+06
Train Epoch: 4 [11520/81276 (14%)]	Loss: 5.192146 LR 2.33e-04
	 Magnitude of data 1.342e+06 output 1.805e+05 target 1.342e+06
Train Epoch: 4 [12160/81276 (15%)]	Loss: 5.144063 LR 2.32e-04
	 Magnitude of data 1.359e+06 output 1.874e+05 target 1.359e+06
Train Epoch: 4 [12800/81276 (16%)]	Loss: 5.270391 LR 2.32e-04
	 Magnitude of data 1.366e+06 output 1.912e+05 target 1.366e+06
Train Epoch: 4 [13440/81276 (17%)]	Loss: 4.978987 LR 2.32e-04
	 Magnitude of data 1.241e+06 output 1.905e+05 target 1.241e+06
Train Epoch: 4 [14080/81276 (17%)]	Loss: 5.362159 LR 2.31e-04
	 Magnitude of data 1.396e+06 output 1.849e+05 target 1.396e+06
Train Epoch: 4 [14720/81276 (18%)]	Loss: 5.428493 LR 2.31e-04
	 Magnitude of data 1.450e+06 output 1.867e+05 target 1.450e+06
Train Epoch: 4 [15360/81276 (19%)]	Loss: 5.451809 LR 2.31e-04
	 Magnitude of data 1.387e+06 output 1.821e+05 target 1.387e+06
Train Epoch: 4 [16000/81276 (20%)]	Loss: 5.196269 LR 2.30e-04
	 Magnitude of data 1.371e+06 output 1.826e+05 target 1.371e+06
Train Epoch: 4 [16640/81276 (20%)]	Loss: 5.160017 LR 2.30e-04
	 Magnitude of data 1.274e+06 output 1.858e+05 target 1.274e+06
Train Epoch: 4 [17280/81276 (21%)]	Loss: 5.416349 LR 2.30e-04
	 Magnitude of data 1.443e+06 output 1.784e+05 target 1.442e+06
Train Epoch: 4 [17920/81276 (22%)]	Loss: 5.285865 LR 2.30e-04
	 Magnitude of data 1.267e+06 output 1.804e+05 target 1.266e+06
Train Epoch: 4 [18560/81276 (23%)]	Loss: 5.234854 LR 2.29e-04
	 Magnitude of data 1.246e+06 output 1.877e+05 target 1.246e+06
Train Epoch: 4 [19200/81276 (24%)]	Loss: 5.045961 LR 2.29e-04
	 Magnitude of data 1.254e+06 output 1.902e+05 target 1.254e+06
Train Epoch: 4 [19840/81276 (24%)]	Loss: 5.128300 LR 2.29e-04
	 Magnitude of data 1.331e+06 output 1.890e+05 target 1.331e+06
Train Epoch: 4 [20480/81276 (25%)]	Loss: 5.039512 LR 2.28e-04
	 Magnitude of data 1.190e+06 output 1.820e+05 target 1.190e+06
Train Epoch: 4 [21120/81276 (26%)]	Loss: 5.346798 LR 2.28e-04
	 Magnitude of data 1.290e+06 output 1.797e+05 target 1.290e+06
Train Epoch: 4 [21760/81276 (27%)]	Loss: 5.181360 LR 2.28e-04
	 Magnitude of data 1.386e+06 output 1.810e+05 target 1.385e+06
Train Epoch: 4 [22400/81276 (28%)]	Loss: 5.019146 LR 2.27e-04
	 Magnitude of data 1.271e+06 output 1.918e+05 target 1.271e+06
Train Epoch: 4 [23040/81276 (28%)]	Loss: 5.514751 LR 2.27e-04
	 Magnitude of data 1.259e+06 output 1.782e+05 target 1.259e+06
Train Epoch: 4 [23680/81276 (29%)]	Loss: 5.155208 LR 2.27e-04
	 Magnitude of data 1.231e+06 output 1.888e+05 target 1.231e+06
Train Epoch: 4 [24320/81276 (30%)]	Loss: 5.387144 LR 2.26e-04
	 Magnitude of data 1.323e+06 output 1.916e+05 target 1.322e+06
Train Epoch: 4 [24960/81276 (31%)]	Loss: 5.059049 LR 2.26e-04
	 Magnitude of data 1.341e+06 output 1.895e+05 target 1.341e+06
Train Epoch: 4 [25600/81276 (32%)]	Loss: 5.002044 LR 2.26e-04
	 Magnitude of data 1.299e+06 output 1.867e+05 target 1.299e+06
Train Epoch: 4 [26240/81276 (32%)]	Loss: 5.398738 LR 2.25e-04
	 Magnitude of data 1.329e+06 output 1.926e+05 target 1.329e+06
Train Epoch: 4 [26880/81276 (33%)]	Loss: 4.859798 LR 2.25e-04
	 Magnitude of data 1.258e+06 output 1.870e+05 target 1.258e+06
Train Epoch: 4 [27520/81276 (34%)]	Loss: 5.241496 LR 2.25e-04
	 Magnitude of data 1.280e+06 output 1.918e+05 target 1.280e+06
Train Epoch: 4 [28160/81276 (35%)]	Loss: 5.162568 LR 2.24e-04
	 Magnitude of data 1.353e+06 output 1.865e+05 target 1.353e+06
Train Epoch: 4 [28800/81276 (35%)]	Loss: 4.666357 LR 2.24e-04
	 Magnitude of data 1.316e+06 output 1.925e+05 target 1.316e+06
Train Epoch: 4 [29440/81276 (36%)]	Loss: 5.256789 LR 2.24e-04
	 Magnitude of data 1.295e+06 output 1.795e+05 target 1.295e+06
Train Epoch: 4 [30080/81276 (37%)]	Loss: 5.051707 LR 2.23e-04
	 Magnitude of data 1.290e+06 output 1.877e+05 target 1.290e+06
Train Epoch: 4 [30720/81276 (38%)]	Loss: 4.966705 LR 2.23e-04
	 Magnitude of data 1.320e+06 output 1.872e+05 target 1.320e+06
Train Epoch: 4 [31360/81276 (39%)]	Loss: 5.179764 LR 2.23e-04
	 Magnitude of data 1.397e+06 output 1.858e+05 target 1.397e+06
Train Epoch: 4 [32000/81276 (39%)]	Loss: 5.196445 LR 2.22e-04
	 Magnitude of data 1.283e+06 output 1.838e+05 target 1.283e+06
Train Epoch: 4 [32640/81276 (40%)]	Loss: 5.542873 LR 2.22e-04
	 Magnitude of data 1.354e+06 output 1.783e+05 target 1.354e+06
Train Epoch: 4 [33280/81276 (41%)]	Loss: 5.276103 LR 2.22e-04
	 Magnitude of data 1.271e+06 output 1.834e+05 target 1.271e+06
Train Epoch: 4 [33920/81276 (42%)]	Loss: 5.214793 LR 2.22e-04
	 Magnitude of data 1.296e+06 output 1.873e+05 target 1.296e+06
Train Epoch: 4 [34560/81276 (43%)]	Loss: 5.291265 LR 2.21e-04
	 Magnitude of data 1.312e+06 output 1.849e+05 target 1.312e+06
Train Epoch: 4 [35200/81276 (43%)]	Loss: 5.688871 LR 2.21e-04
	 Magnitude of data 1.383e+06 output 1.771e+05 target 1.383e+06
Train Epoch: 4 [35840/81276 (44%)]	Loss: 5.245810 LR 2.21e-04
	 Magnitude of data 1.314e+06 output 1.854e+05 target 1.314e+06
Train Epoch: 4 [36480/81276 (45%)]	Loss: 5.272670 LR 2.20e-04
	 Magnitude of data 1.359e+06 output 1.875e+05 target 1.359e+06
Train Epoch: 4 [37120/81276 (46%)]	Loss: 4.783441 LR 2.20e-04
	 Magnitude of data 1.273e+06 output 1.965e+05 target 1.273e+06
Train Epoch: 4 [37760/81276 (46%)]	Loss: 4.985452 LR 2.20e-04
	 Magnitude of data 1.261e+06 output 1.892e+05 target 1.261e+06
Train Epoch: 4 [38400/81276 (47%)]	Loss: 4.875327 LR 2.19e-04
	 Magnitude of data 1.358e+06 output 1.922e+05 target 1.358e+06
Train Epoch: 4 [39040/81276 (48%)]	Loss: 5.135125 LR 2.19e-04
	 Magnitude of data 1.339e+06 output 1.879e+05 target 1.339e+06
Train Epoch: 4 [39680/81276 (49%)]	Loss: 4.912257 LR 2.19e-04
	 Magnitude of data 1.233e+06 output 1.908e+05 target 1.233e+06
Train Epoch: 4 [40320/81276 (50%)]	Loss: 5.070910 LR 2.18e-04
	 Magnitude of data 1.395e+06 output 1.895e+05 target 1.395e+06
Train Epoch: 4 [40960/81276 (50%)]	Loss: 5.018186 LR 2.18e-04
	 Magnitude of data 1.324e+06 output 1.885e+05 target 1.324e+06
Train Epoch: 4 [41600/81276 (51%)]	Loss: 5.173699 LR 2.18e-04
	 Magnitude of data 1.367e+06 output 1.792e+05 target 1.367e+06
Train Epoch: 4 [42240/81276 (52%)]	Loss: 5.138399 LR 2.17e-04
	 Magnitude of data 1.301e+06 output 1.870e+05 target 1.301e+06
Train Epoch: 4 [42880/81276 (53%)]	Loss: 4.753345 LR 2.17e-04
	 Magnitude of data 1.223e+06 output 1.845e+05 target 1.223e+06
Train Epoch: 4 [43520/81276 (54%)]	Loss: 5.147087 LR 2.17e-04
	 Magnitude of data 1.285e+06 output 1.795e+05 target 1.285e+06
Train Epoch: 4 [44160/81276 (54%)]	Loss: 5.070294 LR 2.16e-04
	 Magnitude of data 1.281e+06 output 1.897e+05 target 1.281e+06
Train Epoch: 4 [44800/81276 (55%)]	Loss: 4.920812 LR 2.16e-04
	 Magnitude of data 1.413e+06 output 1.997e+05 target 1.413e+06
Train Epoch: 4 [45440/81276 (56%)]	Loss: 5.164461 LR 2.16e-04
	 Magnitude of data 1.310e+06 output 1.855e+05 target 1.310e+06
Train Epoch: 4 [46080/81276 (57%)]	Loss: 5.323382 LR 2.15e-04
	 Magnitude of data 1.308e+06 output 1.887e+05 target 1.308e+06
Train Epoch: 4 [46720/81276 (58%)]	Loss: 5.277818 LR 2.15e-04
	 Magnitude of data 1.370e+06 output 1.880e+05 target 1.371e+06
Train Epoch: 4 [47360/81276 (58%)]	Loss: 4.977498 LR 2.15e-04
	 Magnitude of data 1.361e+06 output 1.924e+05 target 1.361e+06
Train Epoch: 4 [48000/81276 (59%)]	Loss: 5.306957 LR 2.14e-04
	 Magnitude of data 1.285e+06 output 1.822e+05 target 1.286e+06
Train Epoch: 4 [48640/81276 (60%)]	Loss: 4.917296 LR 2.14e-04
	 Magnitude of data 1.249e+06 output 1.890e+05 target 1.249e+06
Train Epoch: 4 [49280/81276 (61%)]	Loss: 5.050679 LR 2.14e-04
	 Magnitude of data 1.305e+06 output 1.920e+05 target 1.305e+06
Train Epoch: 4 [49920/81276 (61%)]	Loss: 5.006891 LR 2.13e-04
	 Magnitude of data 1.259e+06 output 1.849e+05 target 1.259e+06
Train Epoch: 4 [50560/81276 (62%)]	Loss: 5.096566 LR 2.13e-04
	 Magnitude of data 1.274e+06 output 1.829e+05 target 1.273e+06
Train Epoch: 4 [51200/81276 (63%)]	Loss: 4.929562 LR 2.13e-04
	 Magnitude of data 1.319e+06 output 1.955e+05 target 1.319e+06
Train Epoch: 4 [51840/81276 (64%)]	Loss: 5.076432 LR 2.12e-04
	 Magnitude of data 1.351e+06 output 1.914e+05 target 1.351e+06
Train Epoch: 4 [52480/81276 (65%)]	Loss: 4.816725 LR 2.12e-04
	 Magnitude of data 1.318e+06 output 1.919e+05 target 1.318e+06
Train Epoch: 4 [53120/81276 (65%)]	Loss: 4.869850 LR 2.12e-04
	 Magnitude of data 1.274e+06 output 1.894e+05 target 1.274e+06
Train Epoch: 4 [53760/81276 (66%)]	Loss: 5.143648 LR 2.11e-04
	 Magnitude of data 1.363e+06 output 1.880e+05 target 1.363e+06
Train Epoch: 4 [54400/81276 (67%)]	Loss: 5.004986 LR 2.11e-04
	 Magnitude of data 1.305e+06 output 1.891e+05 target 1.305e+06
Train Epoch: 4 [55040/81276 (68%)]	Loss: 5.048072 LR 2.11e-04
	 Magnitude of data 1.319e+06 output 1.893e+05 target 1.318e+06
Train Epoch: 4 [55680/81276 (69%)]	Loss: 5.218765 LR 2.10e-04
	 Magnitude of data 1.197e+06 output 1.907e+05 target 1.197e+06
Train Epoch: 4 [56320/81276 (69%)]	Loss: 5.003908 LR 2.10e-04
	 Magnitude of data 1.373e+06 output 1.866e+05 target 1.373e+06
Train Epoch: 4 [56960/81276 (70%)]	Loss: 5.120573 LR 2.09e-04
	 Magnitude of data 1.323e+06 output 1.853e+05 target 1.323e+06
Train Epoch: 4 [57600/81276 (71%)]	Loss: 4.913274 LR 2.09e-04
	 Magnitude of data 1.223e+06 output 1.914e+05 target 1.223e+06
Train Epoch: 4 [58240/81276 (72%)]	Loss: 5.330111 LR 2.09e-04
	 Magnitude of data 1.344e+06 output 1.774e+05 target 1.344e+06
Train Epoch: 4 [58880/81276 (72%)]	Loss: 5.260914 LR 2.08e-04
	 Magnitude of data 1.282e+06 output 1.764e+05 target 1.282e+06
Train Epoch: 4 [59520/81276 (73%)]	Loss: 4.869517 LR 2.08e-04
	 Magnitude of data 1.214e+06 output 1.906e+05 target 1.214e+06
Train Epoch: 4 [60160/81276 (74%)]	Loss: 5.150743 LR 2.08e-04
	 Magnitude of data 1.322e+06 output 1.900e+05 target 1.323e+06
Train Epoch: 4 [60800/81276 (75%)]	Loss: 5.036964 LR 2.07e-04
	 Magnitude of data 1.290e+06 output 1.887e+05 target 1.290e+06
Train Epoch: 4 [61440/81276 (76%)]	Loss: 4.861686 LR 2.07e-04
	 Magnitude of data 1.354e+06 output 1.862e+05 target 1.354e+06
Train Epoch: 4 [62080/81276 (76%)]	Loss: 4.817018 LR 2.07e-04
	 Magnitude of data 1.348e+06 output 1.853e+05 target 1.348e+06
Train Epoch: 4 [62720/81276 (77%)]	Loss: 5.033681 LR 2.06e-04
	 Magnitude of data 1.358e+06 output 1.869e+05 target 1.358e+06
Train Epoch: 4 [63360/81276 (78%)]	Loss: 5.171428 LR 2.06e-04
	 Magnitude of data 1.367e+06 output 1.779e+05 target 1.367e+06
Train Epoch: 4 [64000/81276 (79%)]	Loss: 4.829894 LR 2.06e-04
	 Magnitude of data 1.341e+06 output 1.847e+05 target 1.341e+06
Train Epoch: 4 [64640/81276 (80%)]	Loss: 5.220469 LR 2.05e-04
	 Magnitude of data 1.274e+06 output 1.897e+05 target 1.274e+06
Train Epoch: 4 [65280/81276 (80%)]	Loss: 4.757481 LR 2.05e-04
	 Magnitude of data 1.638e+06 output 1.965e+05 target 1.638e+06
Train Epoch: 4 [65920/81276 (81%)]	Loss: 4.847273 LR 2.05e-04
	 Magnitude of data 1.178e+06 output 1.931e+05 target 1.178e+06
Train Epoch: 4 [66560/81276 (82%)]	Loss: 5.173186 LR 2.04e-04
	 Magnitude of data 1.313e+06 output 1.901e+05 target 1.313e+06
Train Epoch: 4 [67200/81276 (83%)]	Loss: 5.010694 LR 2.04e-04
	 Magnitude of data 1.305e+06 output 1.898e+05 target 1.305e+06
Train Epoch: 4 [67840/81276 (84%)]	Loss: 4.774535 LR 2.04e-04
	 Magnitude of data 1.243e+06 output 1.847e+05 target 1.243e+06
Train Epoch: 4 [68480/81276 (84%)]	Loss: 4.998489 LR 2.03e-04
	 Magnitude of data 1.389e+06 output 1.897e+05 target 1.389e+06
Train Epoch: 4 [69120/81276 (85%)]	Loss: 5.064982 LR 2.03e-04
	 Magnitude of data 1.368e+06 output 1.917e+05 target 1.368e+06
Train Epoch: 4 [69760/81276 (86%)]	Loss: 5.200706 LR 2.03e-04
	 Magnitude of data 1.272e+06 output 1.845e+05 target 1.272e+06
Train Epoch: 4 [70400/81276 (87%)]	Loss: 5.203519 LR 2.02e-04
	 Magnitude of data 1.307e+06 output 1.847e+05 target 1.307e+06
Train Epoch: 4 [71040/81276 (87%)]	Loss: 5.288944 LR 2.02e-04
	 Magnitude of data 1.298e+06 output 1.786e+05 target 1.298e+06
Train Epoch: 4 [71680/81276 (88%)]	Loss: 5.101112 LR 2.02e-04
	 Magnitude of data 1.285e+06 output 1.845e+05 target 1.285e+06
Train Epoch: 4 [72320/81276 (89%)]	Loss: 4.911194 LR 2.01e-04
	 Magnitude of data 1.372e+06 output 1.854e+05 target 1.372e+06
Train Epoch: 4 [72960/81276 (90%)]	Loss: 5.114802 LR 2.01e-04
	 Magnitude of data 1.268e+06 output 1.857e+05 target 1.268e+06
Train Epoch: 4 [73600/81276 (91%)]	Loss: 4.894716 LR 2.00e-04
	 Magnitude of data 1.248e+06 output 1.904e+05 target 1.248e+06
Train Epoch: 4 [74240/81276 (91%)]	Loss: 5.163620 LR 2.00e-04
	 Magnitude of data 1.344e+06 output 1.818e+05 target 1.344e+06
Train Epoch: 4 [74880/81276 (92%)]	Loss: 5.314145 LR 2.00e-04
	 Magnitude of data 1.405e+06 output 1.864e+05 target 1.405e+06
Train Epoch: 4 [75520/81276 (93%)]	Loss: 5.001685 LR 1.99e-04
	 Magnitude of data 1.326e+06 output 1.816e+05 target 1.326e+06
Train Epoch: 4 [76160/81276 (94%)]	Loss: 5.026612 LR 1.99e-04
	 Magnitude of data 1.291e+06 output 1.764e+05 target 1.291e+06
Train Epoch: 4 [76800/81276 (95%)]	Loss: 5.078864 LR 1.99e-04
	 Magnitude of data 1.338e+06 output 1.799e+05 target 1.338e+06
Train Epoch: 4 [77440/81276 (95%)]	Loss: 4.940334 LR 1.98e-04
	 Magnitude of data 1.279e+06 output 1.817e+05 target 1.279e+06
Train Epoch: 4 [78080/81276 (96%)]	Loss: 4.902396 LR 1.98e-04
	 Magnitude of data 1.287e+06 output 1.828e+05 target 1.287e+06
Train Epoch: 4 [78720/81276 (97%)]	Loss: 4.972975 LR 1.98e-04
	 Magnitude of data 1.253e+06 output 1.849e+05 target 1.253e+06
Train Epoch: 4 [79360/81276 (98%)]	Loss: 5.347335 LR 1.97e-04
	 Magnitude of data 1.327e+06 output 1.847e+05 target 1.327e+06
Train Epoch: 4 [80000/81276 (99%)]	Loss: 5.104958 LR 1.97e-04
	 Magnitude of data 1.478e+06 output 1.824e+05 target 1.478e+06
Train Epoch: 4 [80640/81276 (99%)]	Loss: 5.074185 LR 1.97e-04
	 Magnitude of data 1.218e+06 output 1.836e+05 target 1.218e+06
Train Epoch: 4 [81216/81276 (100%)]	Loss: 4.807887 LR 1.96e-04
Test set: Average loss: 5.21343931
